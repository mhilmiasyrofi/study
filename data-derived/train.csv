url,method_name,category,method_content
https://github.com/apache/ant/tree/995856afcb7f8168e970e39849bdfc9264f98c84//src/main/org/apache/tools/ant/AntClassLoader.java,initializeClass,open,"public static void initializeClass(Class<?> theClass) {
        // ***HACK*** We ask the VM to create an instance
        // by voluntarily providing illegal arguments to force
        // the VM to run the class' static initializer, while
        // at the same time not running a valid constructor.

        final Constructor<?>[] cons = theClass.getDeclaredConstructors();
        //At least one constructor is guaranteed to be there, but check anyway.
        if (cons != null) {
            if (cons.length > 0 && cons[0] != null) {
                final String[] strs = new String[NUMBER_OF_STRINGS];
                try {
                    cons[0].newInstance((Object[]) strs);
                    // Expecting an exception to be thrown by this call:
                    // IllegalArgumentException: wrong number of Arguments
                } catch (Exception e) {
                    // Ignore - we are interested only in the side
                    // effect - that of getting the static initializers
                    // invoked.  As we do not want to call a valid
                    // constructor to get this side effect, an
                    // attempt is made to call a hopefully
                    // invalid constructor - come on, nobody
                    // would have a constructor that takes in
                    // 256 String arguments ;-)
                    // (In fact, they can't - according to JVM spec
                    // section 4.10, the number of method parameters is limited
                    // to 255 by the definition of a method descriptor.
                    // Constructors count as methods here.)
                }
            }
        }
    }"
https://github.com/apache/ant/tree/995856afcb7f8168e970e39849bdfc9264f98c84//src/main/org/apache/tools/ant/AntClassLoader.java,newAntClassLoader,open,"public static AntClassLoader newAntClassLoader(ClassLoader parent,
                                                   Project project,
                                                   Path path,
                                                   boolean parentFirst) {
        if (subClassToLoad != null) {
            return (AntClassLoader)
                ReflectUtil.newInstance(subClassToLoad,
                                        CONSTRUCTOR_ARGS,
                                        new Object[] {
                                            parent, project, path,
                                            Boolean.valueOf(parentFirst)
                                        });
        }
        return new AntClassLoader(parent, project, path, parentFirst);
    }"
https://github.com/apache/ant/tree/995856afcb7f8168e970e39849bdfc9264f98c84//src/main/org/apache/tools/ant/taskdefs/optional/junit/XMLJUnitResultFormatter.java,startTest,close,"public void startTest(Test t) {
        testStarts.put(t, new Long(System.currentTimeMillis()));
    }"
https://github.com/apache/ant/tree/995856afcb7f8168e970e39849bdfc9264f98c84//src/main/org/apache/tools/ant/taskdefs/optional/junit/XMLJUnitResultFormatter.java,formatError,open,"private void formatError(String type, Test test, Throwable t) {
        if (test != null) {
            endTest(test);
            failedTests.put(test, test);
        }

        Element nested = doc.createElement(type);
        Element currentTest = null;
        if (test != null) {
            currentTest = (Element) testElements.get(test);
        } else {
            currentTest = rootElement;
        }

        currentTest.appendChild(nested);

        String message = t.getMessage();
        if (message != null && message.length() > 0) {
            nested.setAttribute(ATTR_MESSAGE, t.getMessage());
        }
        nested.setAttribute(ATTR_TYPE, t.getClass().getName());

        String strace = JUnitTestRunner.getFilteredTrace(t);
        Text trace = doc.createTextNode(strace);
        nested.appendChild(trace);
    }"
https://github.com/apache/ant/tree/995856afcb7f8168e970e39849bdfc9264f98c84//src/main/org/apache/tools/ant/taskdefs/optional/junit/XMLJUnitResultFormatter.java,endTest,open,"public void endTest(Test test) {
        // Fix for bug #5637 - if a junit.extensions.TestSetup is
        // used and throws an exception during setUp then startTest
        // would never have been called
        if (!testStarts.containsKey(test)) {
            startTest(test);
        }

        Element currentTest = null;
        if (!failedTests.containsKey(test)) {
            currentTest = doc.createElement(TESTCASE);
            String n = JUnitVersionHelper.getTestCaseName(test);
            currentTest.setAttribute(ATTR_NAME,
                                     n == null ? UNKNOWN : n);
            // a TestSuite can contain Tests from multiple classes,
            // even tests with the same name - disambiguate them.
            currentTest.setAttribute(ATTR_CLASSNAME,
                    JUnitVersionHelper.getTestCaseClassName(test));
            rootElement.appendChild(currentTest);
            testElements.put(test, currentTest);
        } else {
            currentTest = (Element) testElements.get(test);
        }

        Long l = (Long) testStarts.get(test);
        currentTest.setAttribute(ATTR_TIME,
            """" + ((System.currentTimeMillis()
                   - l.longValue()) / ONE_SECOND));
    }"
https://github.com/apache/cassandra/tree/69337a43670f71ae1fc55e23d6a9031230423900//test/unit/org/apache/cassandra/io/sstable/SSTableUtils.java,write,close,"public SSTableReader write(Set<String> keys) throws IOException
        {
            Map<String, ColumnFamily> map = new HashMap<String, ColumnFamily>();
            for (String key : keys)
            {
                ColumnFamily cf = ColumnFamily.create(ksname, cfname);
                cf.addColumn(new Column(ByteBufferUtil.bytes(key), ByteBufferUtil.bytes(key), 0));
                map.put(key, cf);
            }
            return write(map);
        }"
https://github.com/apache/cassandra/tree/69337a43670f71ae1fc55e23d6a9031230423900//test/unit/org/apache/cassandra/io/util/BufferedRandomAccessFileTest.java,testReadAndWrite,open,"@Test
    public void testReadAndWrite() throws Exception
    {
        SequentialWriter w = createTempFile(""braf"");

        // writting string of data to the file
        byte[] data = ""Hello"".getBytes();
        w.write(data);
        assertEquals(data.length, w.length());
        assertEquals(data.length, w.getFilePointer());

        w.sync();

        // reading small amount of data from file, this is handled by initial buffer
        RandomAccessReader r = RandomAccessReader.open(w);

        byte[] buffer = new byte[data.length];
        assertEquals(data.length, r.read(buffer));
        assertTrue(Arrays.equals(buffer, data)); // we read exactly what we wrote
        assertEquals(r.read(), -1); // nothing more to read EOF
        assert r.bytesRemaining() == 0 && r.isEOF();

        r.close();

        // writing buffer bigger than page size, which will trigger reBuffer()
        byte[] bigData = new byte[RandomAccessReader.DEFAULT_BUFFER_SIZE + 10];

        for (int i = 0; i < bigData.length; i++)
            bigData[i] = 'd';

        long initialPosition = w.getFilePointer();
        w.write(bigData); // writing data
        assertEquals(w.getFilePointer(), initialPosition + bigData.length);
        assertEquals(w.length(), initialPosition + bigData.length); // file size should equals to last position

        w.sync();

        r = RandomAccessReader.open(w); // re-opening file in read-only mode

        // reading written buffer
        r.seek(initialPosition); // back to initial (before write) position
        data = new byte[bigData.length];
        long sizeRead = 0;
        for (int i = 0; i < data.length; i++)
        {
            data[i] = (byte) r.read();
            sizeRead++;
        }

        assertEquals(sizeRead, data.length); // read exactly data.length bytes
        assertEquals(r.getFilePointer(), initialPosition + data.length);
        assertEquals(r.length(), initialPosition + bigData.length);
        assertTrue(Arrays.equals(bigData, data));
        assertTrue(r.bytesRemaining() == 0 && r.isEOF()); // we are at the of the file

        // test readBytes(int) method
        r.seek(0);
        ByteBuffer fileContent = r.readBytes((int) w.length());
        assertEquals(fileContent.limit(), w.length());
        assert ByteBufferUtil.string(fileContent).equals(""Hello"" + new String(bigData));

        // read the same buffer but using readFully(int)
        data = new byte[bigData.length];
        r.seek(initialPosition);
        r.readFully(data);
        assert r.bytesRemaining() == 0 && r.isEOF(); // we should be at EOF
        assertTrue(Arrays.equals(bigData, data));

        // try to read past mark (all methods should return -1)
        data = new byte[10];
        assertEquals(r.read(), -1);
        assertEquals(r.read(data), -1);
        assertEquals(r.read(data, 0, data.length), -1);

        // test read(byte[], int, int)
        r.seek(0);
        data = new byte[20];
        assertEquals(15, r.read(data, 0, 15));
        assertTrue(new String(data).contains(""Hellodddddddddd""));
        for (int i = 16; i < data.length; i++)
        {
            assert data[i] == 0;
        }

        w.close();
        r.close();
    }"
https://github.com/apache/cassandra/tree/69337a43670f71ae1fc55e23d6a9031230423900//interface/thrift/gen-java/org/apache/cassandra/thrift/Cassandra.java,compareTo,close,"public int compareTo(login_args other) {
      if (!getClass().equals(other.getClass())) {
        return getClass().getName().compareTo(other.getClass().getName());
      }

      int lastComparison = 0;
      login_args typedOther = (login_args)other;

      lastComparison = Boolean.valueOf(isSetAuth_request()).compareTo(typedOther.isSetAuth_request());
      if (lastComparison != 0) {
        return lastComparison;
      }
      if (isSetAuth_request()) {
        lastComparison = org.apache.thrift.TBaseHelper.compareTo(this.auth_request, typedOther.auth_request);
        if (lastComparison != 0) {
          return lastComparison;
        }
      }
      return 0;
    }"
https://github.com/apache/cassandra/tree/69337a43670f71ae1fc55e23d6a9031230423900//interface/thrift/gen-java/org/apache/cassandra/thrift/Cassandra.java,setFieldValue,open,"public void setFieldValue(_Fields field, Object value) {
      switch (field) {
      case AUTH_REQUEST:
        if (value == null) {
          unsetAuth_request();
        } else {
          setAuth_request((AuthenticationRequest)value);
        }
        break;

      }
    }"
https://github.com/apache/cassandra/tree/69337a43670f71ae1fc55e23d6a9031230423900//interface/thrift/gen-java/org/apache/cassandra/thrift/SchemaDisagreementException.java,compareTo,close,"public int compareTo(SchemaDisagreementException other) {
    if (!getClass().equals(other.getClass())) {
      return getClass().getName().compareTo(other.getClass().getName());
    }

    int lastComparison = 0;
    SchemaDisagreementException typedOther = (SchemaDisagreementException)other;

    return 0;
  }"
https://github.com/apache/cassandra/tree/69337a43670f71ae1fc55e23d6a9031230423900//interface/thrift/gen-java/org/apache/cassandra/thrift/SchemaDisagreementException.java,setFieldValue,open,"public void setFieldValue(_Fields field, Object value) {
    switch (field) {
    }
  }"
https://github.com/apache/cassandra/tree/69337a43670f71ae1fc55e23d6a9031230423900//src/java/org/apache/cassandra/transport/ServerConnection.java,applyStateTransition,close,"public void applyStateTransition(Message.Type requestType, Message.Type responseType)
    {
        switch (state)
        {
            case UNINITIALIZED:
                if (requestType == Message.Type.STARTUP)
                {
                    if (responseType == Message.Type.AUTHENTICATE)
                        state = State.AUTHENTICATION;
                    else if (responseType == Message.Type.READY)
                        state = State.READY;
                }
                break;
            case AUTHENTICATION:
                assert requestType == Message.Type.CREDENTIALS;
                if (responseType == Message.Type.READY)
                    state = State.READY;
            case READY:
                break;
            default:
                throw new AssertionError();
        }
    }"
https://github.com/apache/cassandra/tree/69337a43670f71ae1fc55e23d6a9031230423900//src/java/org/apache/cassandra/transport/messages/ErrorMessage.java,encode,open,"public ChannelBuffer encode(ErrorMessage msg)
        {
            ChannelBuffer ccb = CBUtil.intToCB(msg.error.code().value);
            ChannelBuffer mcb = CBUtil.stringToCB(msg.error.getMessage());

            ChannelBuffer acb = ChannelBuffers.EMPTY_BUFFER;
            switch (msg.error.code())
            {
                case UNAVAILABLE:
                    UnavailableException ue = (UnavailableException)msg.error;
                    ChannelBuffer ueCl = CBUtil.consistencyLevelToCB(ue.consistency);
                    acb = ChannelBuffers.buffer(ueCl.readableBytes() + 8);
                    acb.writeBytes(ueCl);
                    acb.writeInt(ue.required);
                    acb.writeInt(ue.alive);
                    break;
                case WRITE_TIMEOUT:
                case READ_TIMEOUT:
                    RequestTimeoutException rte = (RequestTimeoutException)msg.error;
                    boolean isWrite = msg.error.code() == ExceptionCode.WRITE_TIMEOUT;

                    ChannelBuffer rteCl = CBUtil.consistencyLevelToCB(rte.consistency);
                    ByteBuffer writeType = isWrite
                                         ? ByteBufferUtil.bytes(((WriteTimeoutException)rte).writeType.toString())
                                         : null;

                    int extraSize = isWrite  ? 2 + writeType.remaining() : 1;
                    acb = ChannelBuffers.buffer(rteCl.readableBytes() + 8 + extraSize);

                    acb.writeBytes(rteCl);
                    acb.writeInt(rte.received);
                    acb.writeInt(rte.blockFor);
                    if (isWrite)
                    {
                        acb.writeShort((short)writeType.remaining());
                        acb.writeBytes(writeType);
                    }
                    else
                    {
                        acb.writeByte((byte)(((ReadTimeoutException)rte).dataPresent ? 1 : 0));
                    }
                    break;
                case UNPREPARED:
                    PreparedQueryNotFoundException pqnfe = (PreparedQueryNotFoundException)msg.error;
                    acb = CBUtil.bytesToCB(pqnfe.id.bytes);
                    break;
                case ALREADY_EXISTS:
                    AlreadyExistsException aee = (AlreadyExistsException)msg.error;
                    acb = ChannelBuffers.wrappedBuffer(CBUtil.stringToCB(aee.ksName),
                                                       CBUtil.stringToCB(aee.cfName));
                    break;
            }
            return ChannelBuffers.wrappedBuffer(ccb, mcb, acb);
        }"
https://github.com/apache/cassandra/tree/69337a43670f71ae1fc55e23d6a9031230423900//src/java/org/apache/cassandra/transport/messages/ExecuteMessage.java,execute,open,"public Message.Response execute(QueryState state)
    {
        try
        {
            CQLStatement statement = QueryProcessor.getPrepared(statementId);

            if (statement == null)
                throw new PreparedQueryNotFoundException(statementId);

            UUID tracingId = null;
            if (isTracingRequested())
            {
                tracingId = UUIDGen.getTimeUUID();
                state.prepareTracingSession(tracingId);
            }

            if (state.traceNextQuery())
            {
                state.createTracingSession();
                // TODO we don't have [typed] access to CQL bind variables here.  CASSANDRA-4560 is open to add support.
                Tracing.instance().begin(""Execute CQL3 prepared query"", Collections.<String, String>emptyMap());
            }

            Message.Response response = QueryProcessor.processPrepared(statement, consistency, state, values);

            if (tracingId != null)
                response.setTracingId(tracingId);

            return response;
        }
        catch (Exception e)
        {
            return ErrorMessage.fromException(e);
        }
        finally
        {
            Tracing.instance().stopSession();
        }
    }"
https://github.com/apache/commons-lang/tree/bc255ccf5c239666ab54e5a31720d3f482ae78eb//src/main/java/org/apache/commons/lang3/StringUtils.java,toString,close,"public static String toString(byte[] bytes, String charsetName) throws UnsupportedEncodingException {
        return charsetName == null ? new String(bytes) : new String(bytes, charsetName);
    }"
https://github.com/apache/commons-lang/tree/bc255ccf5c239666ab54e5a31720d3f482ae78eb//src/main/java/org/apache/commons/lang3/StringUtils.java,splitByCharacterType,open,"public static String[] splitByCharacterType(String str) {
        return splitByCharacterType(str, false);
    }"
https://github.com/apache/derby/tree/eea0d50c8d732cad9ba563ddfa786b7028eb092f//java/engine/org/apache/derby/catalog/types/DefaultInfoImpl.java,getReferencedColumnNames,close,"public String[] getReferencedColumnNames()
	{
		return referencedColumnNames;
	}"
https://github.com/apache/derby/tree/eea0d50c8d732cad9ba563ddfa786b7028eb092f//java/engine/org/apache/derby/catalog/types/IndexDescriptorImpl.java,baseColumnPositions,close,"public int[] baseColumnPositions()
	{
		return baseColumnPositions;
	}"
https://github.com/apache/derby/tree/eea0d50c8d732cad9ba563ddfa786b7028eb092f//java/engine/org/apache/derby/catalog/types/IndexDescriptorImpl.java,isAscending,close,"public boolean			isAscending(Integer keyColumnPosition)
	{
		int i = keyColumnPosition.intValue() - 1;
		if (i < 0 || i >= baseColumnPositions.length)
			return false;
		return isAscending[i];
	}"
https://github.com/apache/derby/tree/eea0d50c8d732cad9ba563ddfa786b7028eb092f//java/engine/org/apache/derby/catalog/types/IndexDescriptorImpl.java,setBaseColumnPositions,close,"public void		setBaseColumnPositions(int[] baseColumnPositions)
	{
		this.baseColumnPositions = baseColumnPositions;
	}"
https://github.com/apache/derby/tree/eea0d50c8d732cad9ba563ddfa786b7028eb092f//java/engine/org/apache/derby/catalog/types/IndexDescriptorImpl.java,setIsAscending,close,"public void		setIsAscending(boolean[] isAscending)
	{
		this.isAscending = isAscending;
	}"
https://github.com/apache/derby/tree/eea0d50c8d732cad9ba563ddfa786b7028eb092f//java/engine/org/apache/derby/catalog/types/ReferencedColumnsDescriptorImpl.java,getTriggerActionReferencedColumnPositions,close,"public int[] getTriggerActionReferencedColumnPositions()
	{
		return referencedColumnsInTriggerAction;
	}"
https://github.com/apache/derby/tree/eea0d50c8d732cad9ba563ddfa786b7028eb092f//java/engine/org/apache/derby/catalog/types/ReferencedColumnsDescriptorImpl.java,getReferencedColumnPositions,close,"public int[] getReferencedColumnPositions()
	{
		return referencedColumns;
	}"
https://github.com/apache/derby/tree/eea0d50c8d732cad9ba563ddfa786b7028eb092f//java/engine/org/apache/derby/catalog/types/RoutineAliasInfo.java,getParameterModes,close,"public int[] getParameterModes() {
		return parameterModes;
	}"
https://github.com/apache/derby/tree/eea0d50c8d732cad9ba563ddfa786b7028eb092f//java/engine/org/apache/derby/catalog/types/RoutineAliasInfo.java,getParameterNames,close,"public String[] getParameterNames() {
		return parameterNames;
	}"
https://github.com/apache/derby/tree/eea0d50c8d732cad9ba563ddfa786b7028eb092f//java/engine/org/apache/derby/catalog/types/RoutineAliasInfo.java,getParameterTypes,close,"public TypeDescriptor[] getParameterTypes() {
		return parameterTypes;
	}"
https://github.com/apache/derby/tree/eea0d50c8d732cad9ba563ddfa786b7028eb092f//java/engine/org/apache/derby/catalog/types/RoutineAliasInfo.java,toString,open,"public String toString() {

		StringBuffer sb = new StringBuffer(100);
		sb.append(getMethodName());
		sb.append('(');
		for (int i = 0; i < parameterCount; i++) {
			if (i != 0)
				sb.append(',');

			if (returnType == null) {
			// This is a PROCEDURE.  We only want to print the
			// parameter mode (ex. ""IN"", ""OUT"", ""INOUT"") for procedures--
			// we don't do it for functions since use of the ""IN"" keyword
			// is not part of the FUNCTION syntax.
				sb.append(RoutineAliasInfo.parameterMode(parameterModes[i]));
				sb.append(' ');
			}
			sb.append(IdUtil.normalToDelimited(parameterNames[i]));
			sb.append(' ');
			sb.append(parameterTypes[i].getSQLstring());
		}
        if ( hasVarargs() ) { sb.append( "" ... "" ); }
		sb.append(')');

		if (returnType != null) {
		// this a FUNCTION, so syntax requires us to append the return type.
			sb.append("" RETURNS "" + returnType.getSQLstring());
		}

		sb.append("" LANGUAGE JAVA PARAMETER STYLE "" );

		switch( parameterStyle )
		{
		    case PS_JAVA:    sb.append( ""JAVA "" ); break;
		    case PS_DERBY_JDBC_RESULT_SET:    sb.append( ""DERBY_JDBC_RESULT_SET "" ); break;
		    case PS_DERBY:    sb.append( ""DERBY "" ); break;
		}
        
        if ( isDeterministic() )
        { sb.append( "" DETERMINISTIC "" ); }

        if ( hasDefinersRights())
        { sb.append( "" EXTERNAL SECURITY DEFINER "" ); }

		sb.append(RoutineAliasInfo.SQL_CONTROL[getSQLAllowed()]);
		if ((returnType == null) &&
			(dynamicResultSets != 0))
		{ // Only print dynamic result sets if this is a PROCEDURE
		  // because it's not valid syntax for FUNCTIONs.
			sb.append("" DYNAMIC RESULT SETS "");
			sb.append(dynamicResultSets);
		}

		if (returnType != null) {
		// this a FUNCTION, so append the syntax telling what to
		// do with a null parameter.
			sb.append(calledOnNullInput ? "" CALLED "" : "" RETURNS NULL "");
			sb.append(""ON NULL INPUT"");
		}
		
		return sb.toString();
	}"
https://github.com/apache/derby/tree/eea0d50c8d732cad9ba563ddfa786b7028eb092f//java/engine/org/apache/derby/catalog/types/RowMultiSetImpl.java,getColumnNames,close,public  String[]    getColumnNames()    { return _columnNames; }
https://github.com/apache/derby/tree/eea0d50c8d732cad9ba563ddfa786b7028eb092f//java/engine/org/apache/derby/catalog/types/RowMultiSetImpl.java,getTypes,close,public  TypeDescriptor[]    getTypes() { return _types; }
https://github.com/apache/derby/tree/eea0d50c8d732cad9ba563ddfa786b7028eb092f//java/engine/org/apache/derby/catalog/types/TypeDescriptorImpl.java,equals,open,"public boolean equals(Object object)
	{
		TypeDescriptor typeDescriptor = (TypeDescriptor)object;

		if(!this.getTypeName().equals(typeDescriptor.getTypeName()) ||
		   this.precision != typeDescriptor.getPrecision() ||
		   this.scale != typeDescriptor.getScale() ||
		   this.isNullable != typeDescriptor.isNullable() ||
		   this.maximumWidth != typeDescriptor.getMaximumWidth())
		   return false;
	    else
	    {
			switch (typeId.getJDBCTypeId()) {
			case Types.CHAR:
			case Types.VARCHAR:
			case Types.LONGVARCHAR:
			case Types.CLOB:
				//if we are dealing with character types, then we should 
				//also compare the collation information on them.
				if(this.collationType != typeDescriptor.getCollationType())
					return false;
				else
					return true;
			default:
				//no collation checking required if we are dealing with 
				//non-char datatypes.
				return true;
			}
	    }
	}"
https://github.com/apache/derby/tree/eea0d50c8d732cad9ba563ddfa786b7028eb092f//java/engine/org/apache/derby/catalog/types/TypeDescriptorImpl.java,getRowTypes,open,"public TypeDescriptor[] getRowTypes() {
        if (!isRowMultiSet())
            return null;

        return ((RowMultiSetImpl) typeId).getTypes();
    }"
https://github.com/apache/derby/tree/eea0d50c8d732cad9ba563ddfa786b7028eb092f//java/engine/org/apache/derby/catalog/types/TypeDescriptorImpl.java,getRowColumnNames,open,"public String[] getRowColumnNames() {
        if (!isRowMultiSet())
            return null;

        return ((RowMultiSetImpl) typeId).getColumnNames();
    }"
https://github.com/apache/derby/tree/eea0d50c8d732cad9ba563ddfa786b7028eb092f//java/engine/org/apache/derby/catalog/types/TypeDescriptorImpl.java,equals,open,"public boolean equals(Object object)
	{
		TypeDescriptor typeDescriptor = (TypeDescriptor)object;

		if(!this.getTypeName().equals(typeDescriptor.getTypeName()) ||
		   this.precision != typeDescriptor.getPrecision() ||
		   this.scale != typeDescriptor.getScale() ||
		   this.isNullable != typeDescriptor.isNullable() ||
		   this.maximumWidth != typeDescriptor.getMaximumWidth())
		   return false;
	    else
	    {
			switch (typeId.getJDBCTypeId()) {
			case Types.CHAR:
			case Types.VARCHAR:
			case Types.LONGVARCHAR:
			case Types.CLOB:
				//if we are dealing with character types, then we should 
				//also compare the collation information on them.
				if(this.collationType != typeDescriptor.getCollationType())
					return false;
				else
					return true;
			default:
				//no collation checking required if we are dealing with 
				//non-char datatypes.
				return true;
			}
	    }
	}"
https://github.com/apache/derby/tree/eea0d50c8d732cad9ba563ddfa786b7028eb092f//java/engine/org/apache/derby/catalog/types/TypeDescriptorImpl.java,equals,open,"public boolean equals(Object object)
	{
		TypeDescriptor typeDescriptor = (TypeDescriptor)object;

		if(!this.getTypeName().equals(typeDescriptor.getTypeName()) ||
		   this.precision != typeDescriptor.getPrecision() ||
		   this.scale != typeDescriptor.getScale() ||
		   this.isNullable != typeDescriptor.isNullable() ||
		   this.maximumWidth != typeDescriptor.getMaximumWidth())
		   return false;
	    else
	    {
			switch (typeId.getJDBCTypeId()) {
			case Types.CHAR:
			case Types.VARCHAR:
			case Types.LONGVARCHAR:
			case Types.CLOB:
				//if we are dealing with character types, then we should 
				//also compare the collation information on them.
				if(this.collationType != typeDescriptor.getCollationType())
					return false;
				else
					return true;
			default:
				//no collation checking required if we are dealing with 
				//non-char datatypes.
				return true;
			}
	    }
	}"
https://github.com/apache/derby/tree/eea0d50c8d732cad9ba563ddfa786b7028eb092f//java/engine/org/apache/derby/catalog/types/TypeDescriptorImpl.java,getRowTypes,open,"public TypeDescriptor[] getRowTypes() {
        if (!isRowMultiSet())
            return null;

        return ((RowMultiSetImpl) typeId).getTypes();
    }"
https://github.com/apache/derby/tree/eea0d50c8d732cad9ba563ddfa786b7028eb092f//java/engine/org/apache/derby/catalog/types/TypeDescriptorImpl.java,getRowColumnNames,open,"public String[] getRowColumnNames() {
        if (!isRowMultiSet())
            return null;

        return ((RowMultiSetImpl) typeId).getColumnNames();
    }"
https://github.com/apache/derby/tree/eea0d50c8d732cad9ba563ddfa786b7028eb092f//java/engine/org/apache/derby/catalog/types/UDTAliasInfo.java,readExternal,open,"public void readExternal( ObjectInput in )
		 throws IOException, ClassNotFoundException
	{
        // as the persistent form evolves, switch on this value
        int oldVersion = in.readInt();
	}"
https://github.com/apache/derby/tree/eea0d50c8d732cad9ba563ddfa786b7028eb092f//java/client/org/apache/derby/client/ClientXid.java,equals,close,"public boolean equals(Object obj) {
        return org.apache.derby.client.net.NetXAResource.xidsEqual(this, (javax.transaction.xa.Xid) obj);
    }"
https://github.com/apache/derby/tree/eea0d50c8d732cad9ba563ddfa786b7028eb092f//java/client/org/apache/derby/client/ClientXid.java,getData,close,"public byte[] getData() {
        return data_;
    }"
https://github.com/apache/derby/tree/eea0d50c8d732cad9ba563ddfa786b7028eb092f//java/client/org/apache/derby/client/ClientXid.java,setFormatID,open,"public void setFormatID(int formatID) {
        formatID_ = formatID;
        return;
    }"
https://github.com/apache/derby/tree/eea0d50c8d732cad9ba563ddfa786b7028eb092f//java/client/org/apache/derby/client/am/ByteArrayCombinerStream.java,nextArray,open,"private byte[] nextArray() {
        if (arrayIndex >= arrays.size()) {
            return null;
        }
        byte[] tmp = (byte[])arrays.get(arrayIndex);
        arrays.set(arrayIndex++, null);
        off = 0;
        return tmp;
    }"
https://github.com/apache/derby/tree/eea0d50c8d732cad9ba563ddfa786b7028eb092f//java/client/org/apache/derby/client/am/Cursor.java,allocateCharBuffer,open,"public final void allocateCharBuffer() {
        // compute the maximum char length
        int maxCharLength = 0;
        for (int i = 0; i < columns_; i++) {
            switch (jdbcTypes_[i]) {
            case Types.CHAR:
            case Types.VARCHAR:
            case Types.LONGVARCHAR:
                if (fdocaLength_[i] > maxCharLength) {
                    maxCharLength = fdocaLength_[i];
                }
            }
        }

        // allocate char buffer to accomodate largest result column
        charBuffer_ = new char[maxCharLength];
    }"
https://github.com/apache/derby/tree/eea0d50c8d732cad9ba563ddfa786b7028eb092f//java/client/org/apache/derby/client/am/FailedProperties40.java,makeProperties,open,"public static Properties makeProperties(String name, String value) {
    Properties p = new Properties();
        if (name != null || value != null)
            p.setProperty(name, value);
    return p;
    }"
https://github.com/apache/derby/tree/eea0d50c8d732cad9ba563ddfa786b7028eb092f//java/client/org/apache/derby/client/am/Section.java,getPKGNAMCBytes,close,"public byte[] getPKGNAMCBytes() {
        return PKGNAMCBytes;
    }"
https://github.com/apache/derby/tree/eea0d50c8d732cad9ba563ddfa786b7028eb092f//java/client/org/apache/derby/client/am/Section.java,setPKGNAMCBytes,close,"public void setPKGNAMCBytes(byte[] b) {
        if (isGenerated) {
            PKGNAMCBytes = b;
        } else {
            agent_.sectionManager_.setPKGNAMCBytes(b, resultSetHoldability_);
        }
    }"
https://github.com/apache/derby/tree/eea0d50c8d732cad9ba563ddfa786b7028eb092f//java/client/org/apache/derby/client/am/SqlException.java,getMessageUtil,open,"public static MessageUtil getMessageUtil() {
        if ( msgutil_ == null ) {
            msgutil_ = new MessageUtil(CLIENT_MESSAGE_RESOURCE_NAME);
        }
        
        return msgutil_;
    }"
https://github.com/apache/derby/tree/eea0d50c8d732cad9ba563ddfa786b7028eb092f//java/client/org/apache/derby/client/am/SqlWarning.java,getSQLWarning,open,"public SQLWarning getSQLWarning()
    {
        if (wrappedException_ != null) {
            return (SQLWarning) wrappedException_;
        }

        SQLWarning sqlw = new SQLWarning(getMessage(), getSQLState(), 
            getErrorCode());

        sqlw.initCause(this);

        // Set up the nextException chain
        if ( nextWarning_ != null )
        {
            // The exception chain gets constructed automatically through 
            // the beautiful power of recursion
            //
            // We have to use the right method to convert the next exception
            // depending upon its type.  Luckily with all the other subclasses
            // of SQLException we don't have to make our own matching 
            // subclasses because 
            sqlw.setNextException(
                nextException_ instanceof SqlWarning ?
                    ((SqlWarning)nextException_).getSQLWarning() :
                    nextException_.getSQLException());
        }
        
        return sqlw;
        
    }"
https://github.com/apache/derby/tree/eea0d50c8d732cad9ba563ddfa786b7028eb092f//java/client/org/apache/derby/client/am/Sqlca.java,getSqlErrd,open,"public int[] getSqlErrd() {
        if (sqlErrd_ != null) {
            return sqlErrd_;
        }

        sqlErrd_ = new int[6]; // create an int array.
        return sqlErrd_;
    }"
https://github.com/apache/derby/tree/eea0d50c8d732cad9ba563ddfa786b7028eb092f//java/client/org/apache/derby/client/am/Sqlca.java,getSqlWarn,open,"synchronized public char[] getSqlWarn() {
        if (sqlWarn_ != null) {
            return sqlWarn_;
        }

        try {
            if (sqlWarnBytes_ == null) {
                sqlWarn_ = new char[]{' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' '}; // 11 blank.
            } else {
                sqlWarn_ = bytes2String(sqlWarnBytes_, 0, sqlWarnBytes_.length).toCharArray();
            }
            return sqlWarn_;
        } catch (java.io.UnsupportedEncodingException e) {
            sqlWarn_ = new char[]{' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' '}; // 11 blank.
            return sqlWarn_;
        }
    }"
https://github.com/apache/derby/tree/eea0d50c8d732cad9ba563ddfa786b7028eb092f//java/client/org/apache/derby/client/am/Sqlca.java,resetRowsetSqlca,close,"public void resetRowsetSqlca(org.apache.derby.client.am.Connection connection,
                                 int sqlCode,
                                 String sqlState,
                                 byte[] sqlErrpBytes) {
        connection_ = connection;
        sqlCode_ = sqlCode;
        sqlState_ = sqlState;
        sqlErrpBytes_ = sqlErrpBytes;
    }"
https://github.com/apache/derby/tree/eea0d50c8d732cad9ba563ddfa786b7028eb092f//java/client/org/apache/derby/client/am/stmtcache/StatementKey.java,equals,open,"public boolean equals(Object obj) {
        if (!(obj instanceof StatementKey)) {
            return false;
        }
        final StatementKey other = (StatementKey)obj;
        if (this.holdability != other.holdability) {
            return false;
        }
        if (this.autogeneratedKeys != other.autogeneratedKeys) {
            return false;
        }
        if (this.isCallableStatement != other.isCallableStatement) {
            return false;
        }
        if (!this.schema.equals(other.schema)) {
            return false;
        }
        if (this.sql == null && other.sql != null) {
            return false;
        }
        if (!this.sql.equals(other.sql)) {
            return false;
        }
        if (this.type != other.type) {
            return false;
        }
        if (this.concurrency != other.concurrency) {
            return false;
        }
        return true;
    }"
https://github.com/apache/derby/tree/eea0d50c8d732cad9ba563ddfa786b7028eb092f//java/client/org/apache/derby/client/net/ClientJDBCObjectFactoryImpl.java,newClientXAConnection,close,"public ClientXAConnection newClientXAConnection(ClientBaseDataSource ds,
        LogWriter logWriter,String user, String password) throws SQLException
    {
        return new ClientXAConnection((ClientXADataSource)ds,
            (NetLogWriter)logWriter,user,password);
    }"
https://github.com/apache/derby/tree/eea0d50c8d732cad9ba563ddfa786b7028eb092f//java/client/org/apache/derby/client/net/ClientJDBCObjectFactoryImpl.java,newClientXAConnection,close,"public ClientXAConnection newClientXAConnection(ClientBaseDataSource ds,
        LogWriter logWriter,String user, String password) throws SQLException
    {
        return new ClientXAConnection((ClientXADataSource)ds,
            (NetLogWriter)logWriter,user,password);
    }"
https://github.com/apache/derby/tree/eea0d50c8d732cad9ba563ddfa786b7028eb092f//java/client/org/apache/derby/client/net/NaiveTrustManager.java,getSocketFactory,open,"public static SocketFactory getSocketFactory()
        throws java.security.NoSuchAlgorithmException,
               java.security.KeyManagementException,
               java.security.NoSuchProviderException,
               java.security.KeyStoreException,
               java.security.UnrecoverableKeyException,
               java.security.cert.CertificateException,
               java.io.IOException
    {
        if (thisManager == null) {
            thisManager = new TrustManager [] {new NaiveTrustManager()};
        }

        SSLContext ctx = SSLContext.getInstance(""SSL"");
        
        if (ctx.getProvider().getName().equals(""SunJSSE"") &&
            (System.getProperty(""javax.net.ssl.keyStore"") != null) &&
            (System.getProperty(""javax.net.ssl.keyStorePassword"") != null)) {
            
            // SunJSSE does not give you a working default keystore
            // when using your own trust manager. Since a keystore is
            // needed on the client when the server does
            // peerAuthentication, we have to provide one working the
            // same way as the default one.

            String keyStore = 
                System.getProperty(""javax.net.ssl.keyStore"");
            String keyStorePassword =
                System.getProperty(""javax.net.ssl.keyStorePassword"");
            
            KeyStore ks = KeyStore.getInstance(""JKS"");
            ks.load(new FileInputStream(keyStore),
                    keyStorePassword.toCharArray());
            
            KeyManagerFactory kmf = 
                KeyManagerFactory.getInstance(""SunX509"", ""SunJSSE"");
            kmf.init(ks, keyStorePassword.toCharArray());

            ctx.init(kmf.getKeyManagers(),
                     thisManager,
                     null); // Use default random source
        } else {
            ctx.init(null, // Use default key manager
                     thisManager,
                     null); // Use default random source
        }

        return ctx.getSocketFactory();
     }"
https://github.com/apache/derby/tree/eea0d50c8d732cad9ba563ddfa786b7028eb092f//java/client/org/apache/derby/client/net/NaiveTrustManager.java,getSocketFactory,open,"public static SocketFactory getSocketFactory()
        throws java.security.NoSuchAlgorithmException,
               java.security.KeyManagementException,
               java.security.NoSuchProviderException,
               java.security.KeyStoreException,
               java.security.UnrecoverableKeyException,
               java.security.cert.CertificateException,
               java.io.IOException
    {
        if (thisManager == null) {
            thisManager = new TrustManager [] {new NaiveTrustManager()};
        }

        SSLContext ctx = SSLContext.getInstance(""SSL"");
        
        if (ctx.getProvider().getName().equals(""SunJSSE"") &&
            (System.getProperty(""javax.net.ssl.keyStore"") != null) &&
            (System.getProperty(""javax.net.ssl.keyStorePassword"") != null)) {
            
            // SunJSSE does not give you a working default keystore
            // when using your own trust manager. Since a keystore is
            // needed on the client when the server does
            // peerAuthentication, we have to provide one working the
            // same way as the default one.

            String keyStore = 
                System.getProperty(""javax.net.ssl.keyStore"");
            String keyStorePassword =
                System.getProperty(""javax.net.ssl.keyStorePassword"");
            
            KeyStore ks = KeyStore.getInstance(""JKS"");
            ks.load(new FileInputStream(keyStore),
                    keyStorePassword.toCharArray());
            
            KeyManagerFactory kmf = 
                KeyManagerFactory.getInstance(""SunX509"", ""SunJSSE"");
            kmf.init(ks, keyStorePassword.toCharArray());

            ctx.init(kmf.getKeyManagers(),
                     thisManager,
                     null); // Use default random source
        } else {
            ctx.init(null, // Use default key manager
                     thisManager,
                     null); // Use default random source
        }

        return ctx.getSocketFactory();
     }"
https://github.com/apache/derby/tree/eea0d50c8d732cad9ba563ddfa786b7028eb092f//java/client/org/apache/derby/client/net/NaiveTrustManager.java,getSocketFactory,open,"public static SocketFactory getSocketFactory()
        throws java.security.NoSuchAlgorithmException,
               java.security.KeyManagementException,
               java.security.NoSuchProviderException,
               java.security.KeyStoreException,
               java.security.UnrecoverableKeyException,
               java.security.cert.CertificateException,
               java.io.IOException
    {
        if (thisManager == null) {
            thisManager = new TrustManager [] {new NaiveTrustManager()};
        }

        SSLContext ctx = SSLContext.getInstance(""SSL"");
        
        if (ctx.getProvider().getName().equals(""SunJSSE"") &&
            (System.getProperty(""javax.net.ssl.keyStore"") != null) &&
            (System.getProperty(""javax.net.ssl.keyStorePassword"") != null)) {
            
            // SunJSSE does not give you a working default keystore
            // when using your own trust manager. Since a keystore is
            // needed on the client when the server does
            // peerAuthentication, we have to provide one working the
            // same way as the default one.

            String keyStore = 
                System.getProperty(""javax.net.ssl.keyStore"");
            String keyStorePassword =
                System.getProperty(""javax.net.ssl.keyStorePassword"");
            
            KeyStore ks = KeyStore.getInstance(""JKS"");
            ks.load(new FileInputStream(keyStore),
                    keyStorePassword.toCharArray());
            
            KeyManagerFactory kmf = 
                KeyManagerFactory.getInstance(""SunX509"", ""SunJSSE"");
            kmf.init(ks, keyStorePassword.toCharArray());

            ctx.init(kmf.getKeyManagers(),
                     thisManager,
                     null); // Use default random source
        } else {
            ctx.init(null, // Use default key manager
                     thisManager,
                     null); // Use default random source
        }

        return ctx.getSocketFactory();
     }"
https://github.com/apache/derby/tree/eea0d50c8d732cad9ba563ddfa786b7028eb092f//java/client/org/apache/derby/client/net/NetConnection.java,flowReconnect,open,"protected boolean flowReconnect(String password, int securityMechanism) throws SqlException {
        constructExtnam();
        // these calls need to be after newing up the agent
        // because they require the ccsid manager
        constructPrddta();  //modify this to not new up an array

        checkSecmgrForSecmecSupport(securityMechanism);
        try {
            switch (securityMechanism) {
            case NetConfiguration.SECMEC_USRIDPWD: // Clear text user id and password
                checkUserPassword(user_, password);
                resetConnectionAtFirstSql_ = true;
                setDeferredResetPassword(password);
                return true;
            case NetConfiguration.SECMEC_USRIDONL: // Clear text user, no password sent to server
                checkUser(user_);
                resetConnectionAtFirstSql_ = true;
                return true;
            case NetConfiguration.SECMEC_USRENCPWD: // Clear text user, encrypted password
                checkUserPassword(user_, password);
                resetConnectionAtFirstSql_ = true;
                setDeferredResetPassword(password);
                return true;
            case NetConfiguration.SECMEC_EUSRIDPWD: // Encrypted user, encrypted password
                checkUserPassword(user_, password);
                resetConnectionAtFirstSql_ = true;
                setDeferredResetPassword(password);
                return true;
            case NetConfiguration.SECMEC_EUSRIDDTA:
                checkUserPassword(user_, password);
                resetConnectionAtFirstSql_ = true;
                setDeferredResetPassword(password);
                return true;
            case NetConfiguration.SECMEC_EUSRPWDDTA:
                checkUserPassword(user_, password);
                resetConnectionAtFirstSql_ = true;
                setDeferredResetPassword(password);
                return true;
            case NetConfiguration.SECMEC_USRSSBPWD: // Clear text user, strong password substitute
                checkUserPassword(user_, password);
                resetConnectionAtFirstSql_ = true;
                setDeferredResetPassword(password);
                return true;
            default:
                throw new SqlException(agent_.logWriter_, 
                    new ClientMessageId(SQLState.SECMECH_NOT_SUPPORTED),
                    securityMechanism);
            }
        } catch (SqlException sqle) {            // this may not be needed because on method up the stack
            open_ = false;                       // all reset exceptions are caught and wrapped in disconnect exceptions
            try {
                if (agent_ != null) {
                    agent_.close();
                }
            } catch (SqlException ignoreMe) {
            }
            throw sqle;
        }
    }"
https://github.com/apache/derby/tree/eea0d50c8d732cad9ba563ddfa786b7028eb092f//java/client/org/apache/derby/client/net/NetConnection.java,mapSecchkcd,open,"private SqlException mapSecchkcd(int secchkcd) {
        if (secchkcd == CodePoint.SECCHKCD_00) {
            return null;
        }

        // the net driver will not support new password at this time.
        // Here is the message for -30082 (STATE ""08001""):
        //    Attempt to establish connection failed with security
        //    reason {0} {1} +  reason-code + reason-string.
        switch (secchkcd) {
        case CodePoint.SECCHKCD_01:  // ERROR SVRCOD
            return new SqlException(agent_.logWriter_,
                new ClientMessageId(SQLState.NET_CONNECT_AUTH_FAILED),
                msgutil.getTextMessage(MessageId.CONN_SECMECH_NOT_SUPPORTED));
        case CodePoint.SECCHKCD_10:  // ERROR SVRCOD
            return new SqlException(agent_.logWriter_,
                new ClientMessageId(SQLState.NET_CONNECT_AUTH_FAILED),
                msgutil.getTextMessage(MessageId.CONN_PASSWORD_MISSING));
        case CodePoint.SECCHKCD_12:  // ERROR SVRCOD
            return new SqlException(agent_.logWriter_,
                new ClientMessageId(SQLState.NET_CONNECT_AUTH_FAILED),
                msgutil.getTextMessage(MessageId.CONN_USERID_MISSING));
        case CodePoint.SECCHKCD_13:  // ERROR SVRCOD
            return new SqlException(agent_.logWriter_,
                new ClientMessageId(SQLState.NET_CONNECT_AUTH_FAILED),
                msgutil.getTextMessage(MessageId.CONN_USERID_OR_PASSWORD_INVALID));
        case CodePoint.SECCHKCD_14:  // ERROR SVRCOD
            return new SqlException(agent_.logWriter_,
                new ClientMessageId(SQLState.NET_CONNECT_AUTH_FAILED),
                msgutil.getTextMessage(MessageId.CONN_USERID_REVOKED));
        case CodePoint.SECCHKCD_15:  // ERROR SVRCOD
            return new SqlException(agent_.logWriter_,
                new ClientMessageId(SQLState.NET_CONNECT_AUTH_FAILED),
                msgutil.getTextMessage(MessageId.CONN_NEW_PASSWORD_INVALID));
        case CodePoint.SECCHKCD_0A:  // ERROR SVRCOD
            return new SqlException(agent_.logWriter_,
                new ClientMessageId(SQLState.NET_CONNECT_AUTH_FAILED),
                msgutil.getTextMessage(MessageId.CONN_SECSVC_NONRETRYABLE_ERR));
        case CodePoint.SECCHKCD_0B:  // ERROR SVRCOD
            return new SqlException(agent_.logWriter_,
                new ClientMessageId(SQLState.NET_CONNECT_AUTH_FAILED),
                msgutil.getTextMessage(MessageId.CONN_SECTKN_MISSING_OR_INVALID));
        case CodePoint.SECCHKCD_0E:  // ERROR SVRCOD
            return new SqlException(agent_.logWriter_,
                new ClientMessageId(SQLState.NET_CONNECT_AUTH_FAILED),
                msgutil.getTextMessage(MessageId.CONN_PASSWORD_EXPIRED));
        case CodePoint.SECCHKCD_0F:  // ERROR SVRCOD
            return new SqlException(agent_.logWriter_,
                new ClientMessageId(SQLState.NET_CONNECT_AUTH_FAILED),
                msgutil.getTextMessage(MessageId.CONN_USERID_OR_PASSWORD_INVALID));
        default:  // ERROR SVRCOD
            return new SqlException(agent_.logWriter_,
                new ClientMessageId(SQLState.NET_CONNECT_AUTH_FAILED),
                msgutil.getTextMessage(MessageId.CONN_NOT_SPECIFIED));
        }
    }"
https://github.com/apache/derby/tree/eea0d50c8d732cad9ba563ddfa786b7028eb092f//java/client/org/apache/derby/client/net/NetConnection.java,getTargetPublicKey,close,"public byte[] getTargetPublicKey() {
        return targetPublicKey_;
    }"
https://github.com/apache/derby/tree/eea0d50c8d732cad9ba563ddfa786b7028eb092f//java/client/org/apache/derby/client/net/NetConnection.java,setIndoubtTransactions,open,"public void setIndoubtTransactions(java.util.Hashtable indoubtTransactions) {
        if (isXAConnection_) {
            if (indoubtTransactions_ != null) {
                indoubtTransactions_.clear();
            }
            indoubtTransactions_ = indoubtTransactions;
        }
    }"
https://github.com/apache/derby/tree/eea0d50c8d732cad9ba563ddfa786b7028eb092f//java/client/org/apache/derby/client/net/NetConnectionReply.java,doValnsprmSemantics,open,"void doValnsprmSemantics(int codePoint, int value) throws DisconnectException {
        doValnsprmSemantics(codePoint, Integer.toString(value));
    }"
https://github.com/apache/derby/tree/eea0d50c8d732cad9ba563ddfa786b7028eb092f//java/client/org/apache/derby/client/net/NetConnectionReply.java,parseSECCHKreply,close,"private void parseSECCHKreply(NetConnection netConnection) throws DisconnectException {
        if (peekCodePoint() != CodePoint.SECCHKRM) {
            parseSecurityCheckError(netConnection);
            return;
        }

        parseSECCHKRM(netConnection);
        if (peekCodePoint() == CodePoint.SECTKN) {
            // rpydta used only if the security mechanism returns
            // a security token that must be sent back to the source system.
            // this is only used for DCSSEC.  In the case of DCESEC,
            // the sectkn must be returned as reply data if DCE is using
            // mutual authentication.
            // Need to double check what to map this to.  This is probably
            // incorrect but consider it a conversation protocol error
            // 0x03 - OBJDSS sent when not allowed.
            //parseSECTKN (true);
            boolean done = false;
            byte[] bytes = parseSECTKN(false);
        }
    }"
https://github.com/apache/derby/tree/eea0d50c8d732cad9ba563ddfa786b7028eb092f//java/client/org/apache/derby/client/net/NetConnectionReply.java,parseSQLCNGRP,open,"private void parseSQLCNGRP() throws DisconnectException {
        skipBytes(18);
        String sqlcnRDB = parseFastVCS();    // RDBNAM
        String sqlcnClass = parseFastVCS();  // CLASS_NAME
        String sqlcnAuthid = parseFastVCS(); // AUTHID
    }"
https://github.com/apache/derby/tree/eea0d50c8d732cad9ba563ddfa786b7028eb092f//java/client/org/apache/derby/client/net/NetConnectionReply.java,parseSQLCNGRP,open,"private void parseSQLCNGRP() throws DisconnectException {
        skipBytes(18);
        String sqlcnRDB = parseFastVCS();    // RDBNAM
        String sqlcnClass = parseFastVCS();  // CLASS_NAME
        String sqlcnAuthid = parseFastVCS(); // AUTHID
    }"
https://github.com/apache/derby/tree/eea0d50c8d732cad9ba563ddfa786b7028eb092f//java/client/org/apache/derby/client/net/NetConnectionReply.java,parseSQLDIAGSTT,open,"private long parseSQLDIAGSTT(Sqlca[] rowsetSqlca) throws DisconnectException {
        if (readFastUnsignedByte() == CodePoint.NULLDATA) {
            return 0;
        }
        int sqldsFcod = readFastInt(); // FUNCTION_CODE
        int sqldsCost = readFastInt(); // COST_ESTIMATE
        int sqldsLrow = readFastInt(); // LAST_ROW

        skipFastBytes(16);

        long sqldsRowc = readFastLong(); // ROW_COUNT

        skipFastBytes(24);

        return sqldsRowc;
    }"
https://github.com/apache/derby/tree/eea0d50c8d732cad9ba563ddfa786b7028eb092f//java/client/org/apache/derby/client/net/NetConnectionReply.java,parseSQLDCGRP,open,"private int parseSQLDCGRP(Sqlca[] rowsetSqlca, int lastRow) throws DisconnectException {
        int sqldcCode = readFastInt(); // SQLCODE
        String sqldcState = readFastString(5, Typdef.UTF8ENCODING); // SQLSTATE
        int sqldcReason = readFastInt();  // REASON_CODE
        int sqldcLinen = readFastInt(); // LINE_NUMBER
        int sqldcRown = (int) readFastLong(); // ROW_NUMBER

        // save +20237 in the 0th entry of the rowsetSqlca's.
        // this info is going to be used when a subsequent fetch prior is issued, and if already
        // received a +20237 then we've gone beyond the first row and there is no need to
        // flow another fetch to the server.
        if (sqldcCode == 20237) {
            rowsetSqlca[0] = new NetSqlca(netAgent_.netConnection_,
                    sqldcCode,
                    sqldcState,
                    null);
        } else {
            if (rowsetSqlca[sqldcRown] != null) {
                rowsetSqlca[sqldcRown].resetRowsetSqlca(netAgent_.netConnection_,
                        sqldcCode,
                        sqldcState,
                        null);
            } else {
                rowsetSqlca[sqldcRown] = new NetSqlca(netAgent_.netConnection_,
                        sqldcCode,
                        sqldcState,
                        null);
            }
        }

        // reset all entries between lastRow and sqldcRown to null
        for (int i = lastRow + 1; i < sqldcRown; i++) {
            rowsetSqlca[i] = null;
        }

        skipFastBytes(47);
        String sqldcRdb = parseFastVCS(); // RDBNAM
        // skip the tokens for now, since we already have the complete message.
        parseSQLDCTOKS(); // MESSAGE_TOKENS
        String sqldcMsg = parseFastNVCMorNVCS(); // MESSAGE_TEXT

        // skip the following for now.
        skipFastNVCMorNVCS();  // COLUMN_NAME
        skipFastNVCMorNVCS();  // PARAMETER_NAME
        skipFastNVCMorNVCS();  // EXTENDED_NAMES

        parseSQLDCXGRP(); // SQLDCXGRP
        return sqldcRown;
    }"
https://github.com/apache/derby/tree/eea0d50c8d732cad9ba563ddfa786b7028eb092f//java/client/org/apache/derby/client/net/NetConnectionReply.java,parseSQLDCGRP,open,"private int parseSQLDCGRP(Sqlca[] rowsetSqlca, int lastRow) throws DisconnectException {
        int sqldcCode = readFastInt(); // SQLCODE
        String sqldcState = readFastString(5, Typdef.UTF8ENCODING); // SQLSTATE
        int sqldcReason = readFastInt();  // REASON_CODE
        int sqldcLinen = readFastInt(); // LINE_NUMBER
        int sqldcRown = (int) readFastLong(); // ROW_NUMBER

        // save +20237 in the 0th entry of the rowsetSqlca's.
        // this info is going to be used when a subsequent fetch prior is issued, and if already
        // received a +20237 then we've gone beyond the first row and there is no need to
        // flow another fetch to the server.
        if (sqldcCode == 20237) {
            rowsetSqlca[0] = new NetSqlca(netAgent_.netConnection_,
                    sqldcCode,
                    sqldcState,
                    null);
        } else {
            if (rowsetSqlca[sqldcRown] != null) {
                rowsetSqlca[sqldcRown].resetRowsetSqlca(netAgent_.netConnection_,
                        sqldcCode,
                        sqldcState,
                        null);
            } else {
                rowsetSqlca[sqldcRown] = new NetSqlca(netAgent_.netConnection_,
                        sqldcCode,
                        sqldcState,
                        null);
            }
        }

        // reset all entries between lastRow and sqldcRown to null
        for (int i = lastRow + 1; i < sqldcRown; i++) {
            rowsetSqlca[i] = null;
        }

        skipFastBytes(47);
        String sqldcRdb = parseFastVCS(); // RDBNAM
        // skip the tokens for now, since we already have the complete message.
        parseSQLDCTOKS(); // MESSAGE_TOKENS
        String sqldcMsg = parseFastNVCMorNVCS(); // MESSAGE_TEXT

        // skip the following for now.
        skipFastNVCMorNVCS();  // COLUMN_NAME
        skipFastNVCMorNVCS();  // PARAMETER_NAME
        skipFastNVCMorNVCS();  // EXTENDED_NAMES

        parseSQLDCXGRP(); // SQLDCXGRP
        return sqldcRown;
    }"
https://github.com/apache/derby/tree/eea0d50c8d732cad9ba563ddfa786b7028eb092f//java/client/org/apache/derby/client/net/NetPackageReply.java,parseDTAMCHRM,open,"void parseDTAMCHRM() throws DisconnectException {
        boolean svrcodReceived = false;
        int svrcod = CodePoint.SVRCOD_INFO;
        boolean rdbnamReceived = false;
        String rdbnam = null;

        parseLengthAndMatchCodePoint(CodePoint.DTAMCHRM);
        pushLengthOnCollectionStack();
        int peekCP = peekCodePoint();

        while (peekCP != Reply.END_OF_COLLECTION) {

            boolean foundInPass = false;

            if (peekCP == CodePoint.SVRCOD) {
                foundInPass = true;
                svrcodReceived = checkAndGetReceivedFlag(svrcodReceived);
                svrcod = parseSVRCOD(CodePoint.SVRCOD_ERROR, CodePoint.SVRCOD_ERROR);
                peekCP = peekCodePoint();
            }

            if (peekCP == CodePoint.RDBNAM) {
                foundInPass = true;
                rdbnamReceived = checkAndGetReceivedFlag(rdbnamReceived);
                rdbnam = parseRDBNAM(true);
                peekCP = peekCodePoint();
            }

            if (!foundInPass) {
                doPrmnsprmSemantics(peekCP);
            }

        }
        popCollectionStack();
        checkRequiredObjects(svrcodReceived, rdbnamReceived);

        netAgent_.setSvrcod(svrcod);
        doDtamchrmSemantics();
    }"
https://github.com/apache/derby/tree/eea0d50c8d732cad9ba563ddfa786b7028eb092f//java/client/org/apache/derby/client/net/NetXAConnectionReply.java,parseIndoubtList,close,"protected java.util.Hashtable parseIndoubtList() throws DisconnectException {
        boolean found = false;
        int port = 0;
        int numXid = 0;
        String sIpAddr = null;
        int peekCP = peekCodePoint();
        parseLengthAndMatchCodePoint(CodePoint.PRPHRCLST);
        peekCP = peekCodePoint();
        if (peekCP == CodePoint.XIDCNT) {
            found = true;
            numXid = parseXIDCNT();
            peekCP = peekCodePoint();
        }

        java.util.Hashtable<Xid, NetIndoubtTransaction> indoubtTransactions =
                new java.util.Hashtable<Xid, NetIndoubtTransaction>();
        while (peekCP == CodePoint.XID) {
            Xid xid = parseXID();
            indoubtTransactions.put(xid, new NetIndoubtTransaction(xid, null, null, null, sIpAddr, port));
            peekCP = peekCodePoint();
        }

        return indoubtTransactions;
    }"
https://github.com/apache/derby/tree/eea0d50c8d732cad9ba563ddfa786b7028eb092f//java/client/org/apache/derby/client/net/NetXAConnectionReply.java,parseSQLSTTGRPNOCMorNOCS,open,"private String parseSQLSTTGRPNOCMorNOCS() throws DisconnectException {
        int mixedNullInd = readUnsignedByte();
        int singleNullInd = 0;
        String sqlsttString = null;
        int stringLength = 0;

        if (mixedNullInd == CodePoint.NULLDATA) {
            singleNullInd = readUnsignedByte();
            if (singleNullInd == CodePoint.NULLDATA) {
                // throw DTAMCHRM
                doDtamchrmSemantics();
            }
            // read 4-byte length
            stringLength = readInt();
            // read sqlstt string
            sqlsttString = readString(stringLength, netAgent_.targetTypdef_.getCcsidSbcEncoding());
        } else {
            // read 4-byte length
            stringLength = readInt();
            // read sqlstt string
            sqlsttString = readString(stringLength, netAgent_.targetTypdef_.getCcsidMbcEncoding());
            // read null indicator
            singleNullInd = readUnsignedByte();
        }
        return sqlsttString;
    }"
https://github.com/apache/derby/tree/eea0d50c8d732cad9ba563ddfa786b7028eb092f//java/client/org/apache/derby/client/net/NetXAConnectionReply.java,parseSYNCCRD,open,"int parseSYNCCRD(ConnectionCallbackInterface connection) throws DisconnectException {
        boolean svrcodReceived = false;
        int svrcod = CodePoint.SVRCOD_INFO;
        int xaretval = 0;
        int synctype = 0;
        NetConnection conn = netAgent_.netConnection_;

        parseLengthAndMatchCodePoint(CodePoint.SYNCCRD);
        pushLengthOnCollectionStack();
        int peekCP = peekCodePoint();

        while (peekCP != Reply.END_OF_COLLECTION) {

            boolean foundInPass = false;

            if (peekCP == CodePoint.SVRCOD) {
                foundInPass = true;
                svrcodReceived = checkAndGetReceivedFlag(svrcodReceived);
                svrcod = parseSVRCOD(CodePoint.SVRCOD_ERROR, CodePoint.SVRCOD_ERROR);
                peekCP = peekCodePoint();
            }

            if (peekCP == CodePoint.XARETVAL) {
                foundInPass = true;
                xaretval = parseXARETVAL();
                conn.xares_.callInfoArray_[conn.currXACallInfoOffset_].xaRetVal_ =
                        xaretval;
                peekCP = peekCodePoint();
            }

            if (peekCP == CodePoint.SYNCTYPE) {
                foundInPass = true;
                synctype = parseSYNCTYPE();
                peekCP = peekCodePoint();
            }

            if (peekCP == CodePoint.PRPHRCLST) {
                foundInPass = true;
                conn.setIndoubtTransactions(parseIndoubtList());
                peekCP = peekCodePoint();
            }

            if (!foundInPass) {
                doPrmnsprmSemantics(peekCP);
            }
        }
        popCollectionStack();


        return xaretval;

    }"
https://github.com/apache/derby/tree/eea0d50c8d732cad9ba563ddfa786b7028eb092f//java/client/org/apache/derby/client/net/PublicBufferOutputStream.java,getBuffer,open,"public byte[] getBuffer() {
        return buf;
    }"
https://github.com/apache/derby/tree/eea0d50c8d732cad9ba563ddfa786b7028eb092f//java/engine/org/apache/derby/iapi/error/StandardException.java,getArguments,close,"public final Object[] getArguments()
	{
		return arguments;
	}"
https://github.com/apache/derby/tree/eea0d50c8d732cad9ba563ddfa786b7028eb092f//java/engine/org/apache/derby/iapi/services/context/ContextService.java,resetCurrentContextManager,close,"public void resetCurrentContextManager(ContextManager cm) {
		ThreadLocal tcl = threadContextList;

		if (tcl == null) {
			// The context service is already stopped.
			return;
		}

		if (SanityManager.DEBUG) {

			if (Thread.currentThread() != cm.activeThread) {
				SanityManager.THROWASSERT(""resetCurrentContextManager - mismatch threads - current"" + Thread.currentThread() + "" - cm's "" + cm.activeThread);
			}

			if (getCurrentContextManager() != cm) {
				SanityManager.THROWASSERT(""resetCurrentContextManager - mismatch contexts - "" + Thread.currentThread());
			}

			if (cm.activeCount < -1) {
				SanityManager.THROWASSERT(""resetCurrentContextManager - invalid count - current"" + Thread.currentThread() + "" - count "" + cm.activeCount);
			}

			if (cm.activeCount == 0) {
				SanityManager.THROWASSERT(""resetCurrentContextManager - invalid count - current"" + Thread.currentThread() + "" - count "" + cm.activeCount);
			}

			if (cm.activeCount > 0) {
				if (tcl.get() != cm)
					SanityManager.THROWASSERT(""resetCurrentContextManager - invalid thread local "" + Thread.currentThread() + "" - object "" + tcl.get());

			}
		}

		if (cm.activeCount != -1) {
			if (--cm.activeCount == 0) {
				cm.activeThread = null;
                
                // If the ContextManager is empty
                // then don't keep a reference to it
                // when it is not in use. The ContextManager
                // has been closed (most likely) and this
                // is now unwanted. Keeping the reference
                // would hold onto memory and increase the
                // chance of holding onto a another reference
                // will could cause issues for future operations.
                if (cm.isEmpty())
                    tcl.set(null);
                    
            }
			return;
		}

		java.util.Stack stack = (java.util.Stack) tcl.get();

		Object oldCM = stack.pop();

		ContextManager nextCM = (ContextManager) stack.peek();

		boolean seenMultipleCM = false;
		boolean seenCM = false;
		for (int i = 0; i < stack.size(); i++) {

			Object stackCM = stack.elementAt(i);
			if (stackCM != nextCM)
				seenMultipleCM = true;

			if (stackCM == cm)
				seenCM = true;
		}

		if (!seenCM) {
			cm.activeThread = null;
			cm.activeCount = 0;
		}

		if (!seenMultipleCM)
		{
			// all the context managers on the stack
			// are the same so reduce to a simple count.
			nextCM.activeCount = stack.size();
			tcl.set(nextCM);
		}
	}"
https://github.com/apache/derby/tree/eea0d50c8d732cad9ba563ddfa786b7028eb092f//java/engine/org/apache/derby/iapi/services/context/SystemContext.java,cleanupOnError,open,"public void cleanupOnError(Throwable t) {

		boolean doShutdown = false;
		if (t instanceof StandardException) {
			StandardException se = (StandardException) t;
			int severity = se.getSeverity();
			if (severity < ExceptionSeverity.SESSION_SEVERITY)
				return;
            
            popMe();

			if (severity >= ExceptionSeverity.SYSTEM_SEVERITY)
				doShutdown = true;
		} else if (t instanceof ShutdownException) {
			// system is already shutting down ...
		} else if (t instanceof ThreadDeath) {
			// ignore this too, it means we explicitly told thread to
			// stop.  one way this can happen is after monitor
			// shutdown, so we don't need to shut down again
		}
		
		if (!doShutdown) {
			//ContextManager cm = getContextManager();
			// need to remove me from the list of all contexts.
			getContextManager().owningCsf.removeContext(getContextManager());
			return;
		}


		try {
			// try to print out that the shutdown is occurring.
			// REVISIT: does this need to be a localizable message?
			System.err.println(""Shutting down due to severe error."");
			Monitor.getStream().printlnWithHeader(""Shutting down due to severe error."" + t.getMessage());

		} finally {
			// we need this to happen even if we fail to print out a notice
			Monitor.getMonitor().shutdown();
		}

	}"
https://github.com/apache/derby/tree/eea0d50c8d732cad9ba563ddfa786b7028eb092f//java/engine/org/apache/derby/iapi/services/io/FormatableArrayHolder.java,setArray,close,"public void setArray(Object[] array)
	{
		if (SanityManager.DEBUG)
		{
			SanityManager.ASSERT(array != null, 
					""array input to setArray() is null, code can't handle this."");
		}

		this.array = array;
	}"
https://github.com/apache/derby/tree/eea0d50c8d732cad9ba563ddfa786b7028eb092f//java/engine/org/apache/derby/iapi/services/io/FormatableBitSet.java,getByteArray,close,"public byte[] getByteArray()
	{
		// In some cases the array is bigger than the actual number
		// of valid bytes.
		int realByteLength = getLengthInBytes();

		// Currently the case is that the return from this
		// call only includes the valid bytes.
		if (value.length != realByteLength) {
			byte[] data = new byte[realByteLength];
			System.arraycopy(value, 0, data, 0, realByteLength);

			value = data;
		}

		return value;
	}"
https://github.com/apache/derby/tree/eea0d50c8d732cad9ba563ddfa786b7028eb092f//java/engine/org/apache/derby/iapi/services/io/FormatableHashtable.java,put,open,"public Object put(Object key, Object value)
	{
		if (value == null)
		{
			return remove(key);
		}

		if (SanityManager.DEBUG) {

		if ((value instanceof FormatableIntHolder) ||
			(value instanceof FormatableLongHolder) ||
			((value instanceof java.io.Serializable) && (!(value instanceof Formatable)) && (!(value instanceof String)))
			) {

			if (!value.getClass().isArray()) {

				// System.out.println(""key "" + key + "" class "" + value.getClass());
				//new Throwable().printStackTrace(System.out);
				//System.exit(1);
			}
		}
		}
		return super.put(key, value);
	}"
https://github.com/apache/derby/tree/eea0d50c8d732cad9ba563ddfa786b7028eb092f//java/engine/org/apache/derby/iapi/services/io/FormatableIntHolder.java,getFormatableIntHolders,open,"public static FormatableIntHolder[] getFormatableIntHolders(int[] theInts)
	{
		if (theInts == null)
		{
			return null;
		}

		FormatableIntHolder[] fihArray = new FormatableIntHolder[theInts.length];

		for (int index = 0; index < theInts.length; index++)
		{
			fihArray[index] = new FormatableIntHolder(theInts[index]);
		}
		return fihArray;
	}"
https://github.com/apache/derby/tree/eea0d50c8d732cad9ba563ddfa786b7028eb092f//java/engine/org/apache/derby/iapi/services/io/FormatableLongHolder.java,getFormatableLongHolders,open,"public static FormatableLongHolder[] getFormatableLongHolders(long[] theLongs)
	{
		if (theLongs == null)
		{
			return null;
		}

		FormatableLongHolder[] flhArray = new FormatableLongHolder[theLongs.length];

		for (int index = 0; index < theLongs.length; index++)
		{
			flhArray[index] = new FormatableLongHolder(theLongs[index]);
		}
		return flhArray;
	}"
https://github.com/apache/derby/tree/eea0d50c8d732cad9ba563ddfa786b7028eb092f//java/engine/org/apache/derby/iapi/services/loader/ClassInspector.java,getParameterTypes,open,"public String[] getParameterTypes(Member method)
	{

		Class[] parameterClasses;
		if (method instanceof Method) {
			parameterClasses = ((Method) method).getParameterTypes();
		} else {
			parameterClasses = ((Constructor) method).getParameterTypes();
		}

		String[] parameterTypes = new String[parameterClasses.length];

		for (int i = 0; i < parameterTypes.length; i++) {
			parameterTypes[i] = ClassInspector.readableClassName(parameterClasses[i]);
		}

		return parameterTypes;
	}"
https://github.com/apache/derby/tree/eea0d50c8d732cad9ba563ddfa786b7028eb092f//java/engine/org/apache/derby/iapi/services/property/PropertyUtil.java,intPropertyValue,open,"public static int intPropertyValue(String p, Serializable v,
									   int minValue, int maxValue, int defaultValue)
		 throws StandardException
	{
		if (v==null)
			return defaultValue;

		String vs = ((String)v).trim();
		try {
			int result = Integer.parseInt(vs);
			if (result < minValue || result > maxValue)
				throw StandardException.newException(SQLState.PROPERTY_INVALID_VALUE, p,vs);
			return result;
		}
		catch (NumberFormatException nfe) {
			throw StandardException.newException(SQLState.PROPERTY_INVALID_VALUE, p,vs);
		}
	}"
https://github.com/apache/derby/tree/eea0d50c8d732cad9ba563ddfa786b7028eb092f//java/engine/org/apache/derby/iapi/services/property/PropertyUtil.java,booleanProperty,open,"public static boolean booleanProperty(String p, Serializable v, boolean defaultValue)
		 throws StandardException
	{
		if (v==null)
			return defaultValue;

		String vS = ((String) v).trim();

		if (""TRUE"".equals(StringUtil.SQLToUpperCase(vS)))
			return true;
        if (""FALSE"".equals(StringUtil.SQLToUpperCase(vS)))
			return false;

		throw StandardException.newException(SQLState.PROPERTY_INVALID_VALUE, p,vS);
	}"
https://github.com/apache/derby/tree/eea0d50c8d732cad9ba563ddfa786b7028eb092f//java/engine/org/apache/derby/iapi/sql/dictionary/CatalogRowFactory.java,initInfo,close,"public	void	initInfo(int        columnCount,
							 String 	catalogName,
							 int[][] 	indexColumnPositions,
							 boolean[] 	indexUniqueness,
							 String[]	uuidStrings)
							 
	{
		indexCount = (indexColumnPositions != null) ? 
			                 indexColumnPositions.length : 0;

		this.catalogName = catalogName;
		this.columnCount = columnCount;

		UUIDFactory	uf = getUUIDFactory();
		this.tableUUID = uf.recreateUUID(uuidStrings[0] );
		this.heapUUID = uf.recreateUUID( uuidStrings[1] );

		if (indexCount > 0)
		{
			indexNames = new String[indexCount];
			indexUUID = new UUID[indexCount];
			for (int ictr = 0; ictr < indexCount; ictr++)
			{
				indexNames[ictr] = generateIndexName(ictr);
				indexUUID[ictr] = uf.recreateUUID(uuidStrings[ictr + 2 ]);
			}
			this.indexColumnPositions = indexColumnPositions;
			this.indexUniqueness = indexUniqueness;
 
		}
	}"
https://github.com/apache/derby/tree/eea0d50c8d732cad9ba563ddfa786b7028eb092f//java/engine/org/apache/derby/iapi/sql/dictionary/CatalogRowFactory.java,initInfo,close,"public	void	initInfo(int        columnCount,
							 String 	catalogName,
							 int[][] 	indexColumnPositions,
							 boolean[] 	indexUniqueness,
							 String[]	uuidStrings)
							 
	{
		indexCount = (indexColumnPositions != null) ? 
			                 indexColumnPositions.length : 0;

		this.catalogName = catalogName;
		this.columnCount = columnCount;

		UUIDFactory	uf = getUUIDFactory();
		this.tableUUID = uf.recreateUUID(uuidStrings[0] );
		this.heapUUID = uf.recreateUUID( uuidStrings[1] );

		if (indexCount > 0)
		{
			indexNames = new String[indexCount];
			indexUUID = new UUID[indexCount];
			for (int ictr = 0; ictr < indexCount; ictr++)
			{
				indexNames[ictr] = generateIndexName(ictr);
				indexUUID[ictr] = uf.recreateUUID(uuidStrings[ictr + 2 ]);
			}
			this.indexColumnPositions = indexColumnPositions;
			this.indexUniqueness = indexUniqueness;
 
		}
	}"
https://github.com/apache/derby/tree/eea0d50c8d732cad9ba563ddfa786b7028eb092f//java/engine/org/apache/derby/iapi/sql/dictionary/CatalogRowFactory.java,getIndexName,open,"public String getIndexName(int indexNum)
	{
		return indexNames[indexNum];
	}"
https://github.com/apache/derby/tree/eea0d50c8d732cad9ba563ddfa786b7028eb092f//java/engine/org/apache/derby/iapi/sql/dictionary/CatalogRowFactory.java,getIndexColumnPositions,open,"public int[] getIndexColumnPositions(int indexNumber)
	{
		return indexColumnPositions[indexNumber];
	}"
https://github.com/apache/derby/tree/eea0d50c8d732cad9ba563ddfa786b7028eb092f//java/engine/org/apache/derby/iapi/sql/dictionary/CatalogRowFactory.java,getIndexColumnCount,open,"public int getIndexColumnCount(int indexNum)
	{
		return indexColumnPositions[indexNum].length;
	}"
https://github.com/apache/derby/tree/eea0d50c8d732cad9ba563ddfa786b7028eb092f//java/engine/org/apache/derby/iapi/sql/dictionary/ConglomerateDescriptor.java,getColumnNames,close,"public String[] getColumnNames()
	{
		return columnNames;
	}"
https://github.com/apache/derby/tree/eea0d50c8d732cad9ba563ddfa786b7028eb092f//java/engine/org/apache/derby/iapi/sql/dictionary/ConglomerateDescriptor.java,setColumnNames,close,"public void setColumnNames(String[] columnNames)
	{
		this.columnNames = columnNames;
	}"
https://github.com/apache/derby/tree/eea0d50c8d732cad9ba563ddfa786b7028eb092f//java/engine/org/apache/derby/iapi/sql/dictionary/ConglomerateDescriptor.java,getSchemaID,open,"public UUID	getSchemaID()
	{
		return schemaID;
	}"
https://github.com/apache/derby/tree/eea0d50c8d732cad9ba563ddfa786b7028eb092f//java/engine/org/apache/derby/iapi/sql/dictionary/ConglomerateDescriptor.java,getTableID,open,"public UUID	getTableID()
	{
		return	tableID;
	}"
https://github.com/apache/derby/tree/eea0d50c8d732cad9ba563ddfa786b7028eb092f//java/engine/org/apache/derby/iapi/sql/dictionary/ConstraintDescriptor.java,getColumnDescriptors,close,"public ColumnDescriptorList getColumnDescriptors()
		throws StandardException
	{
		if (colDL == null)
		{
			DataDictionary dd = getDataDictionary();
			colDL = new ColumnDescriptorList();
	
			int[]	refCols = getReferencedColumns();
			for (int i = 0; i < refCols.length; i++)
			{
				colDL.add(table.getColumnDescriptor(refCols[i]));
			}
		}
		return colDL;
	}"
https://github.com/apache/derby/tree/eea0d50c8d732cad9ba563ddfa786b7028eb092f//java/engine/org/apache/derby/iapi/sql/dictionary/ConstraintDescriptor.java,getReferencedColumns,close,"public int[]	getReferencedColumns()
	{
		return referencedColumns;
	}"
https://github.com/apache/derby/tree/eea0d50c8d732cad9ba563ddfa786b7028eb092f//java/engine/org/apache/derby/iapi/sql/dictionary/DDUtils.java,getCurrentDeleteConnections,open,"private	static int  getCurrentDeleteConnections
	(
	 DataDictionary	dd,
	 TableDescriptor	td,
	 int refActionType,
	 Hashtable dch,
	 boolean prevNotCascade,
	 boolean findSelfRef
	 )
		throws StandardException
	{

		int selfRefValue = -1; //store the self reference referential action 

		//make sure we get any foreign key constraints added earlier in the same statement.
		td.emptyConstraintDescriptorList();
		ConstraintDescriptorList cdl = dd.getConstraintDescriptors(td);
		int cdlSize = cdl.size();

		boolean passedInPrevNotCascade = prevNotCascade;
		for (int index = 0; index < cdlSize; index++)
		{
				ConstraintDescriptor cd = cdl.elementAt(index);

				//look for  foreign keys
				if ((cd instanceof ForeignKeyConstraintDescriptor))
				{
					ForeignKeyConstraintDescriptor fkcd = (ForeignKeyConstraintDescriptor) cd;
					String constraintName = fkcd.getConstraintName();
					int raDeleteRule = fkcd.getRaDeleteRule();
					int raUpdateRule = fkcd.getRaUpdateRule();

					 if(findSelfRef && fkcd.isSelfReferencingFK())
					 {
						 //All self references will have same  referential actions type
						 selfRefValue = raDeleteRule;
						 findSelfRef = false;
					 }

					ReferencedKeyConstraintDescriptor refcd =
						fkcd.getReferencedConstraint(); 
					TableDescriptor refTd = refcd.getTableDescriptor();
					int childRefAction = refActionType == -1 ? raDeleteRule : refActionType;
				   
					String refTableName = refTd.getSchemaName() + ""."" + refTd.getName();
					//check with  the existing references.
					Integer rAction = ((Integer)dch.get(refTableName));
					if(rAction != null) // we already looked at this table
					{
						prevNotCascade = passedInPrevNotCascade;
						continue;
					}

					//if we are not cascading, check whether the link before
					//this was cascade or not. If we travel through  two NON CASCADE ACTION
					//links then the  delete connection is broken(only a delete can have further
					// referential effects)
					if(raDeleteRule != StatementType.RA_CASCADE)
					{
						if(prevNotCascade)
						{
							prevNotCascade = passedInPrevNotCascade;
							continue;
						}
						else
							prevNotCascade = true;
					}

					//store the delete connection info in the hash table,
					//note that the referential action value is not what is
					//not specified on the current link. It is actually the 
					//value of what happens to the table whose delete
					// connections we are finding.
					dch.put(refTableName, (new Integer(childRefAction)));
					
					//find the next delete conectiions on this path for non
					//self referencig delete connections.
					if(!fkcd.isSelfReferencingFK())
						getCurrentDeleteConnections(dd , refTd, childRefAction,
													dch, true, false);
					prevNotCascade = passedInPrevNotCascade;
				}
		}
		
		return selfRefValue;
	}"
https://github.com/apache/derby/tree/eea0d50c8d732cad9ba563ddfa786b7028eb092f//java/engine/org/apache/derby/iapi/sql/dictionary/DDUtils.java,getCurrentDeleteConnections,open,"private	static int  getCurrentDeleteConnections
	(
	 DataDictionary	dd,
	 TableDescriptor	td,
	 int refActionType,
	 Hashtable dch,
	 boolean prevNotCascade,
	 boolean findSelfRef
	 )
		throws StandardException
	{

		int selfRefValue = -1; //store the self reference referential action 

		//make sure we get any foreign key constraints added earlier in the same statement.
		td.emptyConstraintDescriptorList();
		ConstraintDescriptorList cdl = dd.getConstraintDescriptors(td);
		int cdlSize = cdl.size();

		boolean passedInPrevNotCascade = prevNotCascade;
		for (int index = 0; index < cdlSize; index++)
		{
				ConstraintDescriptor cd = cdl.elementAt(index);

				//look for  foreign keys
				if ((cd instanceof ForeignKeyConstraintDescriptor))
				{
					ForeignKeyConstraintDescriptor fkcd = (ForeignKeyConstraintDescriptor) cd;
					String constraintName = fkcd.getConstraintName();
					int raDeleteRule = fkcd.getRaDeleteRule();
					int raUpdateRule = fkcd.getRaUpdateRule();

					 if(findSelfRef && fkcd.isSelfReferencingFK())
					 {
						 //All self references will have same  referential actions type
						 selfRefValue = raDeleteRule;
						 findSelfRef = false;
					 }

					ReferencedKeyConstraintDescriptor refcd =
						fkcd.getReferencedConstraint(); 
					TableDescriptor refTd = refcd.getTableDescriptor();
					int childRefAction = refActionType == -1 ? raDeleteRule : refActionType;
				   
					String refTableName = refTd.getSchemaName() + ""."" + refTd.getName();
					//check with  the existing references.
					Integer rAction = ((Integer)dch.get(refTableName));
					if(rAction != null) // we already looked at this table
					{
						prevNotCascade = passedInPrevNotCascade;
						continue;
					}

					//if we are not cascading, check whether the link before
					//this was cascade or not. If we travel through  two NON CASCADE ACTION
					//links then the  delete connection is broken(only a delete can have further
					// referential effects)
					if(raDeleteRule != StatementType.RA_CASCADE)
					{
						if(prevNotCascade)
						{
							prevNotCascade = passedInPrevNotCascade;
							continue;
						}
						else
							prevNotCascade = true;
					}

					//store the delete connection info in the hash table,
					//note that the referential action value is not what is
					//not specified on the current link. It is actually the 
					//value of what happens to the table whose delete
					// connections we are finding.
					dch.put(refTableName, (new Integer(childRefAction)));
					
					//find the next delete conectiions on this path for non
					//self referencig delete connections.
					if(!fkcd.isSelfReferencingFK())
						getCurrentDeleteConnections(dd , refTd, childRefAction,
													dch, true, false);
					prevNotCascade = passedInPrevNotCascade;
				}
		}
		
		return selfRefValue;
	}"
https://github.com/apache/derby/tree/eea0d50c8d732cad9ba563ddfa786b7028eb092f//java/engine/org/apache/derby/iapi/sql/dictionary/IndexLister.java,getDistinctIndexConglomerateNumbers,close,"public	long[]		getDistinctIndexConglomerateNumbers()
					throws StandardException
	{
		if ( distinctIndexConglomerateNumbers == null ) { getAllIndexes(); }
		return	distinctIndexConglomerateNumbers;
	}"
https://github.com/apache/derby/tree/eea0d50c8d732cad9ba563ddfa786b7028eb092f//java/engine/org/apache/derby/iapi/sql/dictionary/IndexLister.java,getDistinctIndexNames,close,"public	String[]		getDistinctIndexNames()	throws StandardException
	{
		if ( indexNames == null ) { getAllIndexes(); }
		return	indexNames;
	}"
https://github.com/apache/derby/tree/eea0d50c8d732cad9ba563ddfa786b7028eb092f//java/engine/org/apache/derby/iapi/sql/dictionary/IndexLister.java,getDistinctIndexRowGenerators,close,"public	IndexRowGenerator[]		getDistinctIndexRowGenerators()
					throws StandardException
	{
		if ( distinctIndexRowGenerators == null ) { getAllIndexes(); }
		return	distinctIndexRowGenerators;
	}"
https://github.com/apache/derby/tree/eea0d50c8d732cad9ba563ddfa786b7028eb092f//java/engine/org/apache/derby/iapi/sql/dictionary/IndexLister.java,getIndexRowGenerators,close,"public	IndexRowGenerator[]		getIndexRowGenerators()
					throws StandardException
	{
		if ( indexRowGenerators == null ) { getAllIndexes(); }
		return	indexRowGenerators;
	}"
https://github.com/apache/derby/tree/eea0d50c8d732cad9ba563ddfa786b7028eb092f//java/engine/org/apache/derby/iapi/sql/dictionary/IndexLister.java,getIndexConglomerateNumbers,close,"public	long[]		getIndexConglomerateNumbers()
					throws StandardException
	{
		if ( indexConglomerateNumbers == null ) { getAllIndexes(); }
		return	indexConglomerateNumbers;
	}"
https://github.com/apache/derby/tree/eea0d50c8d732cad9ba563ddfa786b7028eb092f//java/engine/org/apache/derby/iapi/sql/dictionary/SPSDescriptor.java,getCompileTime,close,"public final synchronized Timestamp getCompileTime()
	{
		return compileTime;
	}"
https://github.com/apache/derby/tree/eea0d50c8d732cad9ba563ddfa786b7028eb092f//java/engine/org/apache/derby/iapi/sql/dictionary/SPSDescriptor.java,getParameterDefaults,close,"public final synchronized Object[] getParameterDefaults()
		throws StandardException
	{
		if (paramDefaults == null)
			getParams();

		return paramDefaults;
	}"
https://github.com/apache/derby/tree/eea0d50c8d732cad9ba563ddfa786b7028eb092f//java/engine/org/apache/derby/iapi/sql/dictionary/SPSDescriptor.java,getParams,close,"public final synchronized DataTypeDescriptor[] getParams()
		throws StandardException
	{
        if (params == null && !lookedUpParams) {
            List tmpDefaults = new ArrayList();
            params = getDataDictionary().getSPSParams(this, tmpDefaults);
            paramDefaults = tmpDefaults.toArray();
            lookedUpParams = true;
        }

		return params;
	}"
https://github.com/apache/derby/tree/eea0d50c8d732cad9ba563ddfa786b7028eb092f//java/engine/org/apache/derby/iapi/sql/dictionary/SPSDescriptor.java,setParameterDefaults,close,"public final synchronized void setParameterDefaults(Object[] values)
	{
		this.paramDefaults = values;
	}"
https://github.com/apache/derby/tree/eea0d50c8d732cad9ba563ddfa786b7028eb092f//java/engine/org/apache/derby/iapi/sql/dictionary/SPSDescriptor.java,setParams,close,"public final synchronized void setParams(DataTypeDescriptor params[])
	{
		this.params = params;
	}"
https://github.com/apache/derby/tree/eea0d50c8d732cad9ba563ddfa786b7028eb092f//java/engine/org/apache/derby/iapi/sql/dictionary/SequenceDescriptor.java,prepareToInvalidate,open,"public void prepareToInvalidate
	(
		Provider 					p,
		int							action,
		LanguageConnectionContext	lcc
	) throws StandardException
	{
		switch (action)
		{   			
			default:
				break;
		}
	}"
https://github.com/apache/derby/tree/eea0d50c8d732cad9ba563ddfa786b7028eb092f//java/engine/org/apache/derby/iapi/sql/dictionary/StatementColumnPermission.java,equals,open,"public boolean equals( Object obj)
	{
		if( obj instanceof StatementColumnPermission)
		{
			StatementColumnPermission other = (StatementColumnPermission) obj;
			if( ! columns.equals( other.columns))
				return false;
			return super.equals( obj);
		}
		return false;
	}"
https://github.com/apache/derby/tree/eea0d50c8d732cad9ba563ddfa786b7028eb092f//java/engine/org/apache/derby/iapi/sql/dictionary/StatementColumnPermission.java,check,open,"public void check( LanguageConnectionContext lcc,
					   boolean forGrant,
					   Activation activation)
		throws StandardException
	{
		DataDictionary dd = lcc.getDataDictionary();
		ExecPreparedStatement ps = activation.getPreparedStatement();

        if (hasPermissionOnTable(lcc, activation, forGrant, ps)) {
			return;
		}

        String currentUserId = lcc.getCurrentUserId(activation);

		FormatableBitSet permittedColumns = null;
		if( ! forGrant)
		{
			permittedColumns = addPermittedColumns( dd,
													false /* non-grantable permissions */,
													Authorizer.PUBLIC_AUTHORIZATION_ID,
													permittedColumns);
			permittedColumns = addPermittedColumns( dd,
													false /* non-grantable permissions */,
                                                    currentUserId,
													permittedColumns);
		}
		permittedColumns = addPermittedColumns( dd,
												true /* grantable permissions */,
												Authorizer.PUBLIC_AUTHORIZATION_ID,
												permittedColumns);
		permittedColumns = addPermittedColumns( dd,
												true /* grantable permissions */,
                                                currentUserId,
												permittedColumns);
		
		//DERBY-4191
		//If we are looking for select privilege on ANY column,
		//then we can quit as soon as we find some column with select
		//privilege. This is needed for queries like
		//select count(*) from t1
		//select count(1) from t1
		//select 1 from t1
		//select t1.c1 from t1, t2
		if (privType == Authorizer.MIN_SELECT_PRIV && permittedColumns != null)
			return;

		FormatableBitSet unresolvedColumns = (FormatableBitSet)columns.clone();

		for (int i = unresolvedColumns.anySetBit();
			 i >= 0;
			 i = unresolvedColumns.anySetBit(i)) {

			if (permittedColumns != null && permittedColumns.get(i)) {
				// column i (zero-based here) accounted for:
				unresolvedColumns.clear(i);
			}
		}

		if (unresolvedColumns.anySetBit() < 0) {
			// all ok
			return;
		}

		// If columns are still unauthorized, look to role closure for
		// resolution.
		String role = lcc.getCurrentRoleId(activation);
		RoleGrantDescriptor rd = null;

		if (role != null) {
			// Check that role is still granted to current user or
			// to PUBLIC: A revoked role which is current for this
			// session, is lazily set to none when it is attempted
			// used.
			String dbo = dd.getAuthorizationDatabaseOwner();
            rd = dd.getRoleGrantDescriptor(role, currentUserId, dbo);

			if (rd == null) {
				rd = dd.getRoleGrantDescriptor
					(role,
					 Authorizer.PUBLIC_AUTHORIZATION_ID,
					 dbo);
			}

			if (rd == null) {
				// we have lost the right to set this role, so we can't
				// make use of any permission granted to it or its ancestors.
				lcc.setCurrentRole(activation, null);
			} else {
				// The current role is OK, so we can make use of
				// any permission granted to it.
				//
				// Look at the current role and, if necessary, the transitive
				// closure of roles granted to current role to see if
				// permission has been granted to any of the applicable roles.

				RoleClosureIterator rci =
					dd.createRoleClosureIterator
					(activation.getTransactionController(),
					 role, true /* inverse relation*/);

				String r;

				while (unresolvedColumns.anySetBit() >= 0 &&
					   (r = rci.next()) != null ) {
					//The user does not have needed privilege directly 
					//granted to it, so let's see if he has that privilege
					//available to him/her through his roles.
					permittedColumns = tryRole(lcc, dd,	forGrant, r);
					//DERBY-4191
					//If we are looking for select privilege on ANY column,
					//then we can quit as soon as we find some column with select
					//privilege through this role. This is needed for queries like
					//select count(*) from t1
					//select count(1) from t1
					//select 1 from t1
					//select t1.c1 from t1, t2
					if (privType == Authorizer.MIN_SELECT_PRIV && permittedColumns != null) {
						DependencyManager dm = dd.getDependencyManager();
						RoleGrantDescriptor rgd =
							dd.getRoleDefinitionDescriptor(role);
						ContextManager cm = lcc.getContextManager();

						dm.addDependency(ps, rgd, cm);
						dm.addDependency(activation, rgd, cm);
						return;
					}

					//Use the privileges obtained through the role to satisfy
					//the column level privileges we need. If all the remaining
					//column level privileges are satisfied through this role,
					//we will quit out of this while loop
					for(int i = unresolvedColumns.anySetBit();
						i >= 0;
						i = unresolvedColumns.anySetBit(i)) {

						if(permittedColumns != null && permittedColumns.get(i)) {
							unresolvedColumns.clear(i);
						}
					}
				}
			}
		}
		TableDescriptor td = getTableDescriptor(dd);
		//if we are still here, then that means that we didn't find any select
		//privilege on the table or any column in the table
		if (privType == Authorizer.MIN_SELECT_PRIV)
			throw StandardException.newException( forGrant ? SQLState.AUTH_NO_TABLE_PERMISSION_FOR_GRANT
					  : SQLState.AUTH_NO_TABLE_PERMISSION,
                      currentUserId,
					  getPrivName(),
					  td.getSchemaName(),
					  td.getName());

		int remains = unresolvedColumns.anySetBit();

		if (remains >= 0) {
			// No permission on this column.
			ColumnDescriptor cd = td.getColumnDescriptor(remains + 1);

			if(cd == null) {
				throw StandardException.newException(
					SQLState.AUTH_INTERNAL_BAD_UUID, ""column"");
			} else {
				throw StandardException.newException(
					(forGrant
					 ? SQLState.AUTH_NO_COLUMN_PERMISSION_FOR_GRANT
					 : SQLState.AUTH_NO_COLUMN_PERMISSION),
                    currentUserId,
					getPrivName(),
					cd.getColumnName(),
					td.getSchemaName(),
					td.getName());
			}
		} else {
			// We found and successfully applied a role to resolve the
			// (remaining) required permissions.
			//
			// Also add a dependency on the role (qua provider), so
			// that if role is no longer available to the current
			// user (e.g. grant is revoked, role is dropped,
			// another role has been set), we are able to
			// invalidate the ps or activation (the latter is used
			// if the current role changes).
			DependencyManager dm = dd.getDependencyManager();
			RoleGrantDescriptor rgd =
				dd.getRoleDefinitionDescriptor(role);
			ContextManager cm = lcc.getContextManager();

			dm.addDependency(ps, rgd, cm);
			dm.addDependency(activation, rgd, cm);
		}

	}"
https://github.com/apache/derby/tree/eea0d50c8d732cad9ba563ddfa786b7028eb092f//java/engine/org/apache/derby/iapi/sql/dictionary/StatementPermission.java,genericCheck,open,"public void genericCheck
        (
         LanguageConnectionContext lcc,
         boolean forGrant,
         Activation activation,
         String privilegeType )
        throws StandardException
	{
		DataDictionary dd = lcc.getDataDictionary();
		TransactionController tc = lcc.getTransactionExecute();
		ExecPreparedStatement ps = activation.getPreparedStatement();

        PermissionsDescriptor perm =
            getPermissionDescriptor( lcc.getCurrentUserId(activation), dd );
		if( !isCorrectPermission( perm ) ) { perm = getPermissionDescriptor(Authorizer.PUBLIC_AUTHORIZATION_ID, dd ); }

        // if the user has the correct permission, we're done
		if ( isCorrectPermission( perm ) ) { return; }

		boolean resolved = false;

		// Since no permission exists for the current user or PUBLIC,
		// check if a permission exists for the current role (if set).
		String role = lcc.getCurrentRoleId(activation);

		if (role != null) {

			// Check that role is still granted to current user or
			// to PUBLIC: A revoked role which is current for this
			// session, is lazily set to none when it is attemped
			// used.
			String dbo = dd.getAuthorizationDatabaseOwner();
			RoleGrantDescriptor rd = dd.getRoleGrantDescriptor
                (role, lcc.getCurrentUserId(activation), dbo);

			if (rd == null) {
				rd = dd.getRoleGrantDescriptor(
					role,
					Authorizer.PUBLIC_AUTHORIZATION_ID,
					dbo);
			}

			if (rd == null) {
				// We have lost the right to set this role, so we can't
				// make use of any permission granted to it or its
				// ancestors.
				lcc.setCurrentRole(activation, null);
			} else {
				// The current role is OK, so we can make use of
				// any permission granted to it.
				//
				// Look at the current role and, if necessary, the
				// transitive closure of roles granted to current role to
				// see if permission has been granted to any of the
				// applicable roles.

				RoleClosureIterator rci =
					dd.createRoleClosureIterator
					(activation.getTransactionController(),
					 role, true );

				String r;
				while (!resolved && (r = rci.next()) != null)
                {
					perm = getPermissionDescriptor( r, dd );

					if ( isCorrectPermission( perm ) ) { resolved = true; }
				}
			}

			if (resolved ) {
				// Also add a dependency on the role (qua provider), so that if
				// role is no longer available to the current user (e.g. grant
				// is revoked, role is dropped, another role has been set), we
				// are able to invalidate the ps or activation (the latter is
				// used if the current role changes).
				DependencyManager dm = dd.getDependencyManager();
				RoleGrantDescriptor rgd = dd.getRoleDefinitionDescriptor(role);
				ContextManager cm = lcc.getContextManager();
				dm.addDependency(ps, rgd, cm);
				dm.addDependency(activation, rgd, cm);
			}
		}

		if (!resolved)
        {
            PrivilegedSQLObject pso = getPrivilegedObject( dd );

			if( pso == null )
            {
				throw StandardException.newException
                    ( SQLState.AUTH_INTERNAL_BAD_UUID, getObjectType() );
            }

			SchemaDescriptor sd = pso.getSchemaDescriptor();

			if( sd == null)
            {
				throw StandardException.newException(
					SQLState.AUTH_INTERNAL_BAD_UUID, ""SCHEMA"");
            }

			throw StandardException.newException(
				(forGrant
				 ? SQLState.AUTH_NO_GENERIC_PERMISSION_FOR_GRANT
				 : SQLState.AUTH_NO_GENERIC_PERMISSION),
                lcc.getCurrentUserId(activation),
                privilegeType,
				getObjectType(),
				sd.getSchemaName(),
				pso.getName());
		}

	}"
https://github.com/apache/derby/tree/eea0d50c8d732cad9ba563ddfa786b7028eb092f//java/engine/org/apache/derby/iapi/sql/dictionary/StatementRolePermission.java,check,open,"public void check(LanguageConnectionContext lcc,
                      boolean forGrant,
                      Activation activation
                      ) throws StandardException
    {
        DataDictionary dd = lcc.getDataDictionary();
        TransactionController tc = lcc.getTransactionExecute();

        // For now, only allowed for database owner, and this check
        // is never called for dbo, so always throw.
        switch (privType) {
        case Authorizer.CREATE_ROLE_PRIV:
            throw StandardException.newException
                (SQLState.AUTH_ROLE_DBO_ONLY, ""CREATE ROLE"");
            // break;
        case Authorizer.DROP_ROLE_PRIV:
            throw StandardException.newException
                (SQLState.AUTH_ROLE_DBO_ONLY, ""DROP ROLE"");
            // break;
        default:
            if (SanityManager.DEBUG) {
                SanityManager.THROWASSERT
                    (""Unexpected value ("" + privType + "") for privType"");
            }
            break;
        }
    }"
https://github.com/apache/derby/tree/eea0d50c8d732cad9ba563ddfa786b7028eb092f//java/engine/org/apache/derby/iapi/sql/dictionary/StatementRolePermission.java,check,open,"public void check(LanguageConnectionContext lcc,
                      boolean forGrant,
                      Activation activation
                      ) throws StandardException
    {
        DataDictionary dd = lcc.getDataDictionary();
        TransactionController tc = lcc.getTransactionExecute();

        // For now, only allowed for database owner, and this check
        // is never called for dbo, so always throw.
        switch (privType) {
        case Authorizer.CREATE_ROLE_PRIV:
            throw StandardException.newException
                (SQLState.AUTH_ROLE_DBO_ONLY, ""CREATE ROLE"");
            // break;
        case Authorizer.DROP_ROLE_PRIV:
            throw StandardException.newException
                (SQLState.AUTH_ROLE_DBO_ONLY, ""DROP ROLE"");
            // break;
        default:
            if (SanityManager.DEBUG) {
                SanityManager.THROWASSERT
                    (""Unexpected value ("" + privType + "") for privType"");
            }
            break;
        }
    }"
https://github.com/apache/derby/tree/eea0d50c8d732cad9ba563ddfa786b7028eb092f//java/engine/org/apache/derby/iapi/sql/dictionary/StatementTablePermission.java,oneAuthHasPermissionOnTable,open,"protected boolean oneAuthHasPermissionOnTable(DataDictionary dd, String authorizationId, boolean forGrant)
		throws StandardException
	{
		TablePermsDescriptor perms = dd.getTablePermissions( tableUUID, authorizationId);
		if( perms == null)
			return false;
		
		String priv = null;
			
		switch( privType)
		{
		case Authorizer.SELECT_PRIV:
		case Authorizer.MIN_SELECT_PRIV:
			priv = perms.getSelectPriv();
			break;
		case Authorizer.UPDATE_PRIV:
			priv = perms.getUpdatePriv();
			break;
		case Authorizer.REFERENCES_PRIV:
			priv = perms.getReferencesPriv();
			break;
		case Authorizer.INSERT_PRIV:
			priv = perms.getInsertPriv();
			break;
		case Authorizer.DELETE_PRIV:
			priv = perms.getDeletePriv();
			break;
		case Authorizer.TRIGGER_PRIV:
			priv = perms.getTriggerPriv();
			break;
		}

		return ""Y"".equals(priv) || (!forGrant) && ""y"".equals( priv);
	}"
https://github.com/apache/derby/tree/eea0d50c8d732cad9ba563ddfa786b7028eb092f//java/engine/org/apache/derby/iapi/sql/dictionary/StatisticsDescriptor.java,getUpdateTimestamp,close,public Timestamp getUpdateTimestamp() { return statUpdateTime; }
https://github.com/apache/derby/tree/eea0d50c8d732cad9ba563ddfa786b7028eb092f//java/engine/org/apache/derby/iapi/sql/dictionary/TableDescriptor.java,getAutoincIncrementArray,open,"public long[]   getAutoincIncrementArray()
	{
		if (!tableHasAutoincrement())
			return null;

		int size = getNumberOfColumns();
		long[] inc = new long[size];

		for (int i = 0; i < size; i++)
		{
			ColumnDescriptor cd = getColumnDescriptor(i + 1);
			if (cd.isAutoincrement())
				inc[i] = cd.getAutoincInc();
		}

		return inc;
	}"
https://github.com/apache/derby/tree/eea0d50c8d732cad9ba563ddfa786b7028eb092f//java/engine/org/apache/derby/iapi/sql/dictionary/TriggerDescriptor.java,getCreationTimestamp,close,"public Timestamp getCreationTimestamp()
	{
		return creationTimestamp;
	}"
https://github.com/apache/derby/tree/eea0d50c8d732cad9ba563ddfa786b7028eb092f//java/engine/org/apache/derby/iapi/sql/dictionary/TriggerDescriptor.java,getReferencedCols,close,"public int[] getReferencedCols()
	{
		return referencedCols;
	}"
https://github.com/apache/derby/tree/eea0d50c8d732cad9ba563ddfa786b7028eb092f//java/engine/org/apache/derby/iapi/sql/dictionary/TriggerDescriptor.java,getReferencedColsInTriggerAction,close,"public int[] getReferencedColsInTriggerAction()
	{
		return referencedColsInTriggerAction;
	}"
https://github.com/apache/derby/tree/eea0d50c8d732cad9ba563ddfa786b7028eb092f//java/engine/org/apache/derby/iapi/sql/dictionary/UserDescriptor.java,getLastModified,close,public  Timestamp   getLastModified()   { return _lastModified; }
https://github.com/apache/derby/tree/eea0d50c8d732cad9ba563ddfa786b7028eb092f//java/engine/org/apache/derby/iapi/sql/execute/ExecRowBuilder.java,setColumn,open,"public void setColumn(int column, Object columnTemplate) {
        if (SanityManager.DEBUG &&
                !(columnTemplate instanceof DataTypeDescriptor) &&
                !(columnTemplate instanceof DataValueDescriptor)) {
            SanityManager.THROWASSERT(
                ""Expected DataTypeDescriptor or DataValueDescriptor. Got: "" +
                ((columnTemplate == null) ? columnTemplate :
                    columnTemplate.getClass().getName()));
        }
        template[count] = columnTemplate;
        columns[count] = column;
        count++;
        maxColumnNumber = Math.max(maxColumnNumber, column);
    }"
https://github.com/apache/derby/tree/eea0d50c8d732cad9ba563ddfa786b7028eb092f//java/engine/org/apache/derby/iapi/store/access/DiskHashtable.java,nextElement,open,"public Object nextElement()
        {
            if( ! hasMore)
                throw new NoSuchElementException();
            try
            {
                if (scan.isHeldAfterCommit()) {
                    // automatically reopens scan:
                    if (!scan.positionAtRowLocation(rowloc)) {
                        // Will not happen unless compress of this table
                        // has invalidated the row location. Possible?
                        throw StandardException.
                            newException(SQLState.NO_CURRENT_ROW);
                    }
                }

                scan.fetch(row);

                Object retValue =  BackingStoreHashtable.shallowCloneRow( row);
                hasMore = scan.next();

                if( ! hasMore)
                {
                    scan.close();
                    scan = null;
                } else if (keepAfterCommit) {
                    scan.fetchLocation(rowloc);
                }

                return retValue;
            }
            catch( StandardException se)
            {
                if( scan != null)
                {
                    try
                    {
                        scan.close();
                    }
                    catch( StandardException se1){};
                    scan = null;
                }
                throw new NoSuchElementException();
            }
        }"
https://github.com/apache/derby/tree/eea0d50c8d732cad9ba563ddfa786b7028eb092f//java/engine/org/apache/derby/iapi/store/access/GlobalXact.java,toString,open,"public String toString()
    {
		String globalhex = """";
		String branchhex = """";
		if (global_id != null) 
	    {
			int mask = 0;
			for (int i = 0; i < global_id.length; i++)
		    {
				mask = (global_id[i] & 0xFF);
                if (mask < 16) {
                    globalhex += ""0"" + Integer.toHexString(mask);
                } else {
                    globalhex += Integer.toHexString(mask);
                }
		    }
	    }
	
		if (branch_id != null)
	    {
			int mask = 0;
			for (int i = 0; i < branch_id.length; i++)
		    {
				mask = (branch_id[i] & 0xFF);
                if (mask < 16) {
                    branchhex += ""0"" + Integer.toHexString(mask);
                } else {
                    branchhex += Integer.toHexString(mask);
                }
		    }
	    }

		return(""("" + format_id + "","" + globalhex + "","" + branchhex + "")"");
	
    }"
https://github.com/apache/derby/tree/eea0d50c8d732cad9ba563ddfa786b7028eb092f//java/engine/org/apache/derby/iapi/store/access/RowUtil.java,toString,open,"public static String toString(Object[] row)
    {
        if (SanityManager.DEBUG)
        {

            String str = """";

            if (row != null)
            {
                if (row.length == 0)
                {
                    str = ""empty row"";
                }
                else
                {
                    for (int i = 0; i < row.length; i++)
                        str += ""col["" + i + ""]="" + row[i];
                }
            }
            else
            {
                str = ""row is null"";
            }

            return(str);
        }
        else
        {
            return(null);
        }
    }"
https://github.com/apache/derby/tree/eea0d50c8d732cad9ba563ddfa786b7028eb092f//java/engine/org/apache/derby/iapi/store/access/RowUtil.java,toString,open,"public static String toString(Object[] row)
    {
        if (SanityManager.DEBUG)
        {

            String str = """";

            if (row != null)
            {
                if (row.length == 0)
                {
                    str = ""empty row"";
                }
                else
                {
                    for (int i = 0; i < row.length; i++)
                        str += ""col["" + i + ""]="" + row[i];
                }
            }
            else
            {
                str = ""row is null"";
            }

            return(str);
        }
        else
        {
            return(null);
        }
    }"
https://github.com/apache/derby/tree/eea0d50c8d732cad9ba563ddfa786b7028eb092f//java/engine/org/apache/derby/iapi/store/access/xa/XAXactId.java,getBranchQualifier,close,"public byte[] getBranchQualifier()
    {
        return(branch_id);
    }"
https://github.com/apache/derby/tree/eea0d50c8d732cad9ba563ddfa786b7028eb092f//java/engine/org/apache/derby/iapi/store/access/xa/XAXactId.java,getGlobalTransactionId,close,"public byte[] getGlobalTransactionId()
    {
        return(global_id);
    }"
https://github.com/apache/derby/tree/eea0d50c8d732cad9ba563ddfa786b7028eb092f//java/engine/org/apache/derby/iapi/store/access/xa/XAXactId.java,equals,open,"public boolean equals(Object other) 
    {
		if (other == this)
			return true;

		if (other == null)
			return false;
	
		try
	    {
			if (other instanceof GlobalXact)
				return super.equals(other);
			// Just cast it and catch the exception rather than doing the type
			// checking twice.
			Xid other_xid = (Xid) other;
		
			return(
				   java.util.Arrays.equals(
									other_xid.getGlobalTransactionId(),
									this.global_id)          &&
				   java.util.Arrays.equals(
									other_xid.getBranchQualifier(),
									this.branch_id)          &&
				   other_xid.getFormatId() == this.format_id);
		
	    }
		catch(ClassCastException cce)
	    {
			// this class only knows how to compare with other Xids
			if (SanityManager.DEBUG)
				SanityManager.THROWASSERT(""comparing XAXactId with "" + 
										  other.getClass().getName(), cce); 
		
			return false;
	    }
    }"
https://github.com/apache/derby/tree/eea0d50c8d732cad9ba563ddfa786b7028eb092f//java/engine/org/apache/derby/iapi/store/raw/ContainerKey.java,getContainerId,open,"public long getContainerId() {
		return containerId;
	}"
https://github.com/apache/derby/tree/eea0d50c8d732cad9ba563ddfa786b7028eb092f//java/engine/org/apache/derby/iapi/store/raw/FetchDescriptor.java,getQualifierList,open,"public final Qualifier[][] getQualifierList()
    {
        return(qualifier_list);
    }"
https://github.com/apache/derby/tree/eea0d50c8d732cad9ba563ddfa786b7028eb092f//java/engine/org/apache/derby/iapi/store/raw/FetchDescriptor.java,getMaterializedColumns,open,"public final int[] getMaterializedColumns()
    {
        return(materialized_cols);
    }"
https://github.com/apache/derby/tree/eea0d50c8d732cad9ba563ddfa786b7028eb092f//java/engine/org/apache/derby/iapi/store/raw/FetchDescriptor.java,getValidColumnsArray,open,"public final int[] getValidColumnsArray()
    {
        return(validColumnsArray);
    }"
https://github.com/apache/derby/tree/eea0d50c8d732cad9ba563ddfa786b7028eb092f//java/tools/org/apache/derby/iapi/tools/i18n/LocalizedResource.java,getInstance,open,"public static LocalizedResource getInstance(){
		if (local == null){
			local = new  LocalizedResource();
		}
		return local;
	}"
https://github.com/apache/derby/tree/eea0d50c8d732cad9ba563ddfa786b7028eb092f//java/tools/org/apache/derby/iapi/tools/i18n/LocalizedResource.java,InputReader,open,"public static LocalizedInput InputReader(){
		return getInstance().in;
	}"
https://github.com/apache/derby/tree/eea0d50c8d732cad9ba563ddfa786b7028eb092f//java/tools/org/apache/derby/iapi/tools/i18n/LocalizedResource.java,OutputWriter,open,"public static LocalizedOutput OutputWriter(){
		return getInstance().out;
	}"
https://github.com/apache/derby/tree/eea0d50c8d732cad9ba563ddfa786b7028eb092f//java/tools/org/apache/derby/iapi/tools/i18n/LocalizedResource.java,getNewLocale,open,"private Locale getNewLocale(String locStr){
			String l="""", r="""", v="""";
			StringTokenizer st;
			if (locStr==null) {
				return null;
			}
			st=new StringTokenizer(locStr, ""_"");
			try {
				l=st.nextToken();
				if(st.hasMoreTokens()==true)
					r=st.nextToken();
				if(st.hasMoreTokens()==true)
					v=st.nextToken();
				return new Locale(l,r,v);
			} catch (Exception e) {
				return null;
			}
	}"
https://github.com/apache/derby/tree/eea0d50c8d732cad9ba563ddfa786b7028eb092f//java/tools/org/apache/derby/iapi/tools/i18n/LocalizedResource.java,getTextMessage,open,"public String getTextMessage(String key ) {
        return getTextMessage(key, new Object[0]);
	}"
https://github.com/apache/derby/tree/eea0d50c8d732cad9ba563ddfa786b7028eb092f//java/engine/org/apache/derby/iapi/types/NumberDataType.java,setBigDecimal,open,"public void setBigDecimal(Number bigDecimal) throws StandardException
	{
		if (objectNull(bigDecimal))
			return;

		Comparable bdc = (Comparable) bigDecimal;


		// See comment in SQLDecimal.getLong()

		if (   (bdc.compareTo(NumberDataType.MINLONG_MINUS_ONE) == 1)
			&& (bdc.compareTo(NumberDataType.MAXLONG_PLUS_ONE) == -1)) {

			setValue(bigDecimal.longValue());
		} else {

			throw StandardException.newException(SQLState.LANG_OUTSIDE_RANGE_FOR_DATATYPE, getTypeName());
		}
	}"
https://github.com/apache/derby/tree/eea0d50c8d732cad9ba563ddfa786b7028eb092f//java/engine/org/apache/derby/iapi/types/NumberDataType.java,setBigDecimal,open,"public void setBigDecimal(Number bigDecimal) throws StandardException
	{
		if (objectNull(bigDecimal))
			return;

		Comparable bdc = (Comparable) bigDecimal;


		// See comment in SQLDecimal.getLong()

		if (   (bdc.compareTo(NumberDataType.MINLONG_MINUS_ONE) == 1)
			&& (bdc.compareTo(NumberDataType.MAXLONG_PLUS_ONE) == -1)) {

			setValue(bigDecimal.longValue());
		} else {

			throw StandardException.newException(SQLState.LANG_OUTSIDE_RANGE_FOR_DATATYPE, getTypeName());
		}
	}"
https://github.com/apache/derby/tree/eea0d50c8d732cad9ba563ddfa786b7028eb092f//java/drda/org/apache/derby/impl/drda/NetworkServerControlImpl.java,checkShutdownPrivileges,open,"public void checkShutdownPrivileges() throws SQLException {    
        // get the system's authentication service
        final AuthenticationService auth
            = ((AuthenticationService)
               Monitor.findService(AuthenticationService.MODULE,
                                   ""authentication""));

        // authenticate user
        if (auth != null) {
            final Properties finfo = new Properties();
            if (userArg != null) {
                finfo.setProperty(""user"", userArg);
            }
            if (passwordArg != null) {
                finfo.setProperty(""password"", passwordArg);
            }
            if (!auth.authenticate((String)null, finfo)) {
                // not a valid user
                throw Util.generateCsSQLException(
                SQLState.NET_CONNECT_AUTH_FAILED,
                MessageService.getTextMessage(MessageId.AUTH_INVALID));
            }
        }

        // approve action if not running under a security manager
        if (System.getSecurityManager() == null) {
            return;
        }

        // the check
        try {
            final Permission sp  = new SystemPermission(
                  SystemPermission.SERVER, SystemPermission.SHUTDOWN);
            // For porting the network server to J2ME/CDC, consider calling
            // abstract method InternalDriver.checkShutdownPrivileges(user)
            // instead of static SecurityUtil.checkUserHasPermission().
            // SecurityUtil.checkUserHasPermission(userArg, sp);
        } catch (AccessControlException ace) {
            throw Util.generateCsSQLException(
                SQLState.AUTH_SHUTDOWN_MISSING_PERMISSION,
                userArg, (Object)ace); // overloaded method
        }
    }"
https://github.com/apache/derby/tree/eea0d50c8d732cad9ba563ddfa786b7028eb092f//java/engine/org/apache/derby/impl/io/DirFile.java,deleteAll,close,"public boolean deleteAll()
    {
        if( !exists())
            return false;
        if( isDirectory())
        {
            String[] childList = super.list();
            String parentName = getPath();
            for( int i = 0; i < childList.length; i++)
            {
                if( childList[i].equals( ""."") || childList[i].equals( ""..""))
                    continue;
                DirFile child = new DirFile( parentName, childList[i]);
                if( ! child.deleteAll())
                    return false;
            }
        }
        return delete();
    }"
https://github.com/apache/derby/tree/eea0d50c8d732cad9ba563ddfa786b7028eb092f//java/engine/org/apache/derby/impl/jdbc/EmbedResultSet.java,updateObject,open,"public void updateObject(int columnIndex, Object x, int scale)
			throws SQLException {
		updateObject(columnIndex, x);
		/*
		* If the parameter type is DECIMAL or NUMERIC, then
		* we need to set them to the passed scale.
		*/
		int colType = getColumnType(columnIndex);
		if ((colType == Types.DECIMAL) || (colType == Types.NUMERIC)) {
			if (scale < 0)
				throw newSQLException(SQLState.BAD_SCALE_VALUE, new Integer(scale));

			try {
				DataValueDescriptor value = updateRow.getColumn(columnIndex);

				int origvaluelen = value.getLength();
				((VariableSizeDataValue)
						value).setWidth(VariableSizeDataValue.IGNORE_PRECISION,
							scale,
							false);

			} catch (StandardException t) {
				throw EmbedResultSet.noStateChangeException(t);
			}
		}
	}"
https://github.com/apache/derby/tree/eea0d50c8d732cad9ba563ddfa786b7028eb092f//java/engine/org/apache/derby/impl/sql/GenericPreparedStatement.java,getEndCompileTimestamp,close,"public Timestamp getEndCompileTimestamp()
	{
		return endCompileTimestamp;
	}"
https://github.com/apache/derby/tree/eea0d50c8d732cad9ba563ddfa786b7028eb092f//java/engine/org/apache/derby/impl/sql/GenericPreparedStatement.java,getBeginCompileTimestamp,close,"public Timestamp getBeginCompileTimestamp()
	{
		return beginCompileTimestamp;
	}"
https://github.com/apache/derby/tree/eea0d50c8d732cad9ba563ddfa786b7028eb092f//java/engine/org/apache/derby/impl/sql/GenericPreparedStatement.java,getParameterTypes,close,"public DataTypeDescriptor[]	getParameterTypes()	{
		return paramTypeDescriptors;
	}"
https://github.com/apache/derby/tree/eea0d50c8d732cad9ba563ddfa786b7028eb092f//java/engine/org/apache/derby/impl/sql/GenericPreparedStatement.java,getSavedObjects,close,"public	final Object[]	getSavedObjects()
	{
		return	savedObjects;
	}"
https://github.com/apache/derby/tree/eea0d50c8d732cad9ba563ddfa786b7028eb092f//java/engine/org/apache/derby/impl/sql/GenericResultDescription.java,getColumnInfo,close,"public ResultColumnDescriptor[] getColumnInfo() {
		return columns;
	}"
https://github.com/apache/derby/tree/eea0d50c8d732cad9ba563ddfa786b7028eb092f//java/engine/org/apache/derby/impl/sql/GenericStatement.java,prepMinion,open,"private PreparedStatement prepMinion(LanguageConnectionContext lcc, boolean cacheMe, Object[] paramDefaults,
		SchemaDescriptor spsSchema, boolean internalSQL)
		throws StandardException
	{
						  
		long				beginTime = 0;
		long				parseTime = 0;
		long				bindTime = 0;
		long				optimizeTime = 0;
		long				generateTime = 0;
		Timestamp			beginTimestamp = null;
		Timestamp			endTimestamp = null;
		StatementContext	statementContext = null;

		// verify it isn't already prepared...
		// if it is, and is valid, simply return that tree.
		// if it is invalid, we will recompile now.
		if (preparedStmt != null) {
			if (preparedStmt.upToDate())
				return preparedStmt;
		}

		// Clear the optimizer trace from the last statement
		if (lcc.getOptimizerTrace())
			lcc.setOptimizerTraceOutput(getSource() + ""\n"");

		beginTime = getCurrentTimeMillis(lcc);
		/* beginTimestamp only meaningful if beginTime is meaningful.
		 * beginTime is meaningful if STATISTICS TIMING is ON.
		 */
		if (beginTime != 0)
		{
			beginTimestamp = new Timestamp(beginTime);
		}

		/** set the prepare Isolaton from the LanguageConnectionContext now as 
		 * we need to consider it in caching decisions
		 */
		prepareIsolationLevel = lcc.getPrepareIsolationLevel();

		/* a note on statement caching:
		 * 
		 * A GenericPreparedStatement (GPS) is only added it to the cache if the
		 * parameter cacheMe is set to TRUE when the GPS is created.
		 * 
		 * Earlier only CacheStatement (CS) looked in the statement cache for a
		 * prepared statement when prepare was called. Now the functionality 
		 * of CS has been folded into GenericStatement (GS). So we search the
		 * cache for an existing PreparedStatement only when cacheMe is TRUE.
		 * i.e if the user calls prepare with cacheMe set to TRUE:
		 * then we 
		 *         a) look for the prepared statement in the cache.
		 *         b) add the prepared statement to the cache.
		 *
		 * In cases where the statement cache has been disabled (by setting the
		 * relevant Derby property) then the value of cacheMe is irrelevant.
		 */ 
		boolean foundInCache = false;
		if (preparedStmt == null) 
		{
			if (cacheMe)
				preparedStmt = (GenericPreparedStatement)((GenericLanguageConnectionContext)lcc).lookupStatement(this);

			if (preparedStmt == null) 
			{
				preparedStmt = new GenericPreparedStatement(this);
			}
			else
			{
				foundInCache = true;
			}
		}

		// if anyone else also has this prepared statement,
		// we don't want them trying to compile with it while
		// we are.  So, we synchronize on it and re-check
		// its validity first.
		// this is a no-op if and until there is a central
		// cache of prepared statement objects...
		synchronized (preparedStmt) 
		{

			for (;;) {

				if (foundInCache) {
					if (preparedStmt.referencesSessionSchema()) {
						// cannot use this state since it is private to a connection.
						// switch to a new statement.
						foundInCache = false;
						preparedStmt = new GenericPreparedStatement(this);
						break;
					}
				}

				// did it get updated while we waited for the lock on it?
				if (preparedStmt.upToDate()) {
					return preparedStmt;
				}

				if (!preparedStmt.compilingStatement) {
					break;
				}

				try {
					preparedStmt.wait();
				} catch (InterruptedException ie) {
                    InterruptStatus.setInterrupted();
				}
			}

			preparedStmt.compilingStatement = true;
			preparedStmt.setActivationClass(null);
		}

		try {

			HeaderPrintWriter istream = lcc.getLogStatementText() ? Monitor.getStream() : null;

			/*
			** For stored prepared statements, we want all
			** errors, etc in the context of the underlying
			** EXECUTE STATEMENT statement, so don't push/pop
			** another statement context unless we don't have
			** one.  We won't have one if it is an internal
			** SPS (e.g. jdbcmetadata).
			*/
			if (!preparedStmt.isStorable() || lcc.getStatementDepth() == 0)
			{
				// since this is for compilation only, set atomic
				// param to true and timeout param to 0
				statementContext = lcc.pushStatementContext(true, isForReadOnly, getSource(),
                                                            null, false, 0L);
			}



			/*
			** RESOLVE: we may ultimately wish to pass in
			** whether we are a jdbc metadata query or not to
			** get the CompilerContext to make the createDependency()
			** call a noop.
			*/
			CompilerContext cc = lcc.pushCompilerContext(compilationSchema);
			
			if (prepareIsolationLevel != 
				ExecutionContext.UNSPECIFIED_ISOLATION_LEVEL)
			{
				cc.setScanIsolationLevel(prepareIsolationLevel);
			}


			// Look for stored statements that are in a system schema
			// and with a match compilation schema. If so, allow them
			// to compile using internal SQL constructs.

			if (internalSQL ||
				(spsSchema != null) && (spsSchema.isSystemSchema()) &&
					(spsSchema.equals(compilationSchema))) {
						cc.setReliability(CompilerContext.INTERNAL_SQL_LEGAL);
			}

			try 
			{
				// Statement logging if lcc.getLogStatementText() is true
				if (istream != null)
				{
					String xactId = lcc.getTransactionExecute().getActiveStateTxIdString();
					istream.printlnWithHeader(LanguageConnectionContext.xidStr + 
											  xactId + 
											  ""), "" +
											  LanguageConnectionContext.lccStr +
												  lcc.getInstanceNumber() +
											  ""), "" +
											  LanguageConnectionContext.dbnameStr +
												  lcc.getDbname() +
											  ""), "" +
											  LanguageConnectionContext.drdaStr +
												  lcc.getDrdaID() +
											  ""), Begin compiling prepared statement: "" + 
											  getSource() +
											  "" :End prepared statement"");
				}

				Parser p = cc.getParser();

				cc.setCurrentDependent(preparedStmt);

				//Only top level statements go through here, nested statement
				//will invoke this method from other places
				StatementNode qt = (StatementNode)
                        p.parseStatement(statementText, paramDefaults);

				parseTime = getCurrentTimeMillis(lcc);

                // Call user-written tree-printer if it exists
                walkAST( lcc, qt, ASTVisitor.AFTER_PARSE);

				if (SanityManager.DEBUG) 
				{
					if (SanityManager.DEBUG_ON(""DumpParseTree"")) 
					{
						SanityManager.GET_DEBUG_STREAM().print(
							""\n\n============PARSE===========\n\n"");
						qt.treePrint();
						lcc.getPrintedObjectsMap().clear();
					}

					if (SanityManager.DEBUG_ON(""StopAfterParsing"")) 
					{
                        lcc.setLastQueryTree( qt );
                        
						throw StandardException.newException(SQLState.LANG_STOP_AFTER_PARSING);
					}
				}

				/*
				** Tell the data dictionary that we are about to do
				** a bunch of ""get"" operations that must be consistent with
				** each other.
				*/
				
				DataDictionary dataDictionary = lcc.getDataDictionary();

				int ddMode = dataDictionary == null ? 0 : dataDictionary.startReading(lcc);

				try
				{
					// start a nested transaction -- all locks acquired by bind
					// and optimize will be released when we end the nested
					// transaction.
					lcc.beginNestedTransaction(true);

					qt.bindStatement();
					bindTime = getCurrentTimeMillis(lcc);

                    // Call user-written tree-printer if it exists
                    walkAST( lcc, qt, ASTVisitor.AFTER_BIND);

					if (SanityManager.DEBUG) 
					{
						if (SanityManager.DEBUG_ON(""DumpBindTree"")) 
						{
							SanityManager.GET_DEBUG_STREAM().print(
								""\n\n============BIND===========\n\n"");
							qt.treePrint();
							lcc.getPrintedObjectsMap().clear();
						}

						if (SanityManager.DEBUG_ON(""StopAfterBinding"")) {
							throw StandardException.newException(SQLState.LANG_STOP_AFTER_BINDING);
						}
					}

					//Derby424 - In order to avoid caching select statements referencing
					// any SESSION schema objects (including statements referencing views
					// in SESSION schema), we need to do the SESSION schema object check
					// here.  
					//a specific eg for statement referencing a view in SESSION schema 
					//CREATE TABLE t28A (c28 int)
					//INSERT INTO t28A VALUES (280),(281)
					//CREATE VIEW SESSION.t28v1 as select * from t28A
					//SELECT * from SESSION.t28v1 should show contents of view and we
					// should not cache this statement because a user can later define
					// a global temporary table with the same name as the view name.
					//Following demonstrates that
					//DECLARE GLOBAL TEMPORARY TABLE SESSION.t28v1(c21 int, c22 int) not
					//     logged
					//INSERT INTO SESSION.t28v1 VALUES (280,1),(281,2)
					//SELECT * from SESSION.t28v1 should show contents of global temporary
					//table and not the view.  Since this select statement was not cached
					// earlier, it will be compiled again and will go to global temporary
					// table to fetch data. This plan will not be cached either because
					// select statement is using SESSION schema object.
					//
					//Following if statement makes sure that if the statement is
					// referencing SESSION schema objects, then we do not want to cache it.
					// We will remove the entry that was made into the cache for 
					//this statement at the beginning of the compile phase.
					//The reason we do this check here rather than later in the compile
					// phase is because for a view, later on, we loose the information that
					// it was referencing SESSION schema because the reference
					//view gets replaced with the actual view definition. Right after
					// binding, we still have the information on the view and that is why
					// we do the check here.
					if (preparedStmt.referencesSessionSchema(qt)) {
						if (foundInCache)
							((GenericLanguageConnectionContext)lcc).removeStatement(this);
					}
					
					qt.optimizeStatement();

					optimizeTime = getCurrentTimeMillis(lcc);

                    // Call user-written tree-printer if it exists
                    walkAST( lcc, qt, ASTVisitor.AFTER_OPTIMIZE);

					// Statement logging if lcc.getLogStatementText() is true
					if (istream != null)
					{
						String xactId = lcc.getTransactionExecute().getActiveStateTxIdString();
						istream.printlnWithHeader(LanguageConnectionContext.xidStr + 
												  xactId + 
												  ""), "" +
												  LanguageConnectionContext.lccStr +
												  lcc.getInstanceNumber() +
												  ""), "" +
												  LanguageConnectionContext.dbnameStr +
												  lcc.getDbname() +
												  ""), "" +
												  LanguageConnectionContext.drdaStr +
												  lcc.getDrdaID() +
												  ""), End compiling prepared statement: "" + 
												  getSource() +
												  "" :End prepared statement"");
					}
				}

				catch (StandardException se)
				{
					lcc.commitNestedTransaction();

					// Statement logging if lcc.getLogStatementText() is true
					if (istream != null)
					{
						String xactId = lcc.getTransactionExecute().getActiveStateTxIdString();
						istream.printlnWithHeader(LanguageConnectionContext.xidStr + 
												  xactId + 
												  ""), "" +
												  LanguageConnectionContext.lccStr +
												  lcc.getInstanceNumber() +
												  ""), "" +
												  LanguageConnectionContext.dbnameStr +
												  lcc.getDbname() +
												  ""), "" +
												  LanguageConnectionContext.drdaStr +
												  lcc.getDrdaID() +
												  ""), Error compiling prepared statement: "" + 
												  getSource() +
												  "" :End prepared statement"");
					}
					throw se;
				}

				finally
				{
					/* Tell the data dictionary that we are done reading */
					if (dataDictionary != null)
					dataDictionary.doneReading(ddMode, lcc);
				}

				/* we need to move the commit of nested sub-transaction
				 * after we mark PS valid, during compilation, we might need
				 * to get some lock to synchronize with another thread's DDL
				 * execution, in particular, the compilation of insert/update/
				 * delete vs. create index/constraint (see Beetle 3976).  We
				 * can't release such lock until after we mark the PS valid.
				 * Otherwise we would just erase the DDL's invalidation when
				 * we mark it valid.
				 */
				try		// put in try block, commit sub-transaction if bad
				{
					if (SanityManager.DEBUG) 
					{
						if (SanityManager.DEBUG_ON(""DumpOptimizedTree"")) 
						{
							SanityManager.GET_DEBUG_STREAM().print(
								""\n\n============OPT===========\n\n"");
							qt.treePrint();
							lcc.getPrintedObjectsMap().clear();
						}

						if (SanityManager.DEBUG_ON(""StopAfterOptimizing"")) 
						{
							throw StandardException.newException(SQLState.LANG_STOP_AFTER_OPTIMIZING);
						}
					}

					GeneratedClass ac = qt.generate(preparedStmt.getByteCodeSaver());

					generateTime = getCurrentTimeMillis(lcc);
					/* endTimestamp only meaningful if generateTime is meaningful.
					 * generateTime is meaningful if STATISTICS TIMING is ON.
					 */
					if (generateTime != 0)
					{
						endTimestamp = new Timestamp(generateTime);
					}

					if (SanityManager.DEBUG) 
					{
						if (SanityManager.DEBUG_ON(""StopAfterGenerating"")) 
						{
							throw StandardException.newException(SQLState.LANG_STOP_AFTER_GENERATING);
						}
					}

					/*
						copy over the compile-time created objects
						to the prepared statement.  This always happens
						at the end of a compile, so there is no need
						to erase the previous entries on a re-compile --
						this erases as it replaces.  Set the activation
						class in case it came from a StorablePreparedStatement
					*/
					preparedStmt.setConstantAction( qt.makeConstantAction() );
					preparedStmt.setSavedObjects( cc.getSavedObjects() );
					preparedStmt.setRequiredPermissionsList(cc.getRequiredPermissionsList());
                    preparedStmt.incrementVersionCounter();
					preparedStmt.setActivationClass(ac);
					preparedStmt.setNeedsSavepoint(qt.needsSavepoint());
					preparedStmt.setCursorInfo((CursorInfo)cc.getCursorInfo());
					preparedStmt.setIsAtomic(qt.isAtomic());
					preparedStmt.setExecuteStatementNameAndSchema(
												qt.executeStatementName(),
												qt.executeSchemaName()
												);
					preparedStmt.setSPSName(qt.getSPSName());
					preparedStmt.completeCompile(qt);
					preparedStmt.setCompileTimeWarnings(cc.getWarnings());

                    // Schedule updates of any stale index statistics we may
                    // have detected when creating the plan.
                    TableDescriptor[] tds = qt.updateIndexStatisticsFor();
                    if (tds.length > 0) {
                        IndexStatisticsDaemon isd = lcc.getDataDictionary().
                            getIndexStatsRefresher(true);
                        if (isd != null) {
                            for (int i=0; i < tds.length; i++) {
                                isd.schedule(tds[i]);
                            }
                        }
                    }
                }
				catch (StandardException e) 	// hold it, throw it
				{
					lcc.commitNestedTransaction();
					throw e;
				}

				if (lcc.getRunTimeStatisticsMode())
				{
					preparedStmt.setCompileTimeMillis(
						parseTime - beginTime, //parse time
						bindTime - parseTime, //bind time
						optimizeTime - bindTime, //optimize time
						generateTime - optimizeTime, //generate time
						generateTime - beginTime, //total compile time
						beginTimestamp,
						endTimestamp);
				}

			}
			finally // for block introduced by pushCompilerContext()
			{
				lcc.popCompilerContext( cc );
			}
		}
		catch (StandardException se)
		{
			if (foundInCache)
				((GenericLanguageConnectionContext)lcc).removeStatement(this);

			throw se;
		}
		finally
		{
			synchronized (preparedStmt) {
				preparedStmt.compilingStatement = false;
				preparedStmt.notifyAll();
			}
		}

		lcc.commitNestedTransaction();

		if (statementContext != null)
			lcc.popStatementContext(statementContext, null);

		return preparedStmt;
	}"
https://github.com/apache/derby/tree/eea0d50c8d732cad9ba563ddfa786b7028eb092f//java/engine/org/apache/derby/impl/sql/GenericStorablePreparedStatement.java,writeExternal,open,"public void writeExternal(ObjectOutput out) throws IOException
	{
		out.writeObject(getCursorInfo());
		out.writeBoolean(needsSavepoint());
		out.writeBoolean(isAtomic);
		out.writeObject(executionConstants);
		out.writeObject(resultDesc);

		// savedObjects may be null
		if (savedObjects == null)
		{
			out.writeBoolean(false);
		}
		else
		{	
			out.writeBoolean(true);
			ArrayUtil.writeArrayLength(out, savedObjects);
			ArrayUtil.writeArrayItems(out, savedObjects);
		}

		/*
		** Write out the class name and byte code
		** if we have them.  They might be null if
		** we don't want to write out the plan, and
		** would prefer it just write out null (e.g.
		** we know the plan is invalid).
		*/
		out.writeObject(className);
		out.writeBoolean(byteCode != null);
		if (byteCode != null)
		    byteCode.writeExternal(out);
	}"
https://github.com/apache/derby/tree/eea0d50c8d732cad9ba563ddfa786b7028eb092f//java/engine/org/apache/derby/impl/sql/LanguageDbPropertySetter.java,validate,open,"public boolean validate
	(
		String			key,
		Serializable	value,
		Dictionary		p
	) throws StandardException 
	{
        // Can't change the dictionary version manually. That could make the database
        // unbootable. See DERBY-5838.
		if ( key.trim().equals( DataDictionary.CORE_DATA_DICTIONARY_VERSION ) )
		{
            throw StandardException.newException( SQLState.PROPERTY_UNSUPPORTED_CHANGE, key, value );
        }
        
		// Disallow changing sqlAuthorization from true to false or null after
		// switching to Standard authorization
		if (key.trim().equals(Property.SQL_AUTHORIZATION_PROPERTY))
		{
			LanguageConnectionContext lcc = (LanguageConnectionContext)
					ContextService.getContext(LanguageConnectionContext.CONTEXT_ID);

			if (lcc.usesSqlAuthorization() && !Boolean.valueOf((String)value).booleanValue())
				throw StandardException.newException(SQLState.PROPERTY_UNSUPPORTED_CHANGE,
					key, value);
		}

		if (key.equals(Property.LANGUAGE_STALE_PLAN_CHECK_INTERVAL)) {
			PropertyUtil.intPropertyValue(
						Property.LANGUAGE_STALE_PLAN_CHECK_INTERVAL,
						value,
						Property.MIN_LANGUAGE_STALE_PLAN_CHECK_INTERVAL,
						Integer.MAX_VALUE,
						Property.DEFAULT_LANGUAGE_STALE_PLAN_CHECK_INTERVAL
						);
			return true;
		}

		return false;
	}"
https://github.com/apache/derby/tree/eea0d50c8d732cad9ba563ddfa786b7028eb092f//java/engine/org/apache/derby/impl/sql/catalog/DD_Version.java,handleMinorRevisionChange,open,"private void handleMinorRevisionChange(TransactionController tc, DD_Version fromVersion, boolean softUpgradeRun) 
		throws StandardException
	{
		boolean isReadOnly = bootingDictionary.af.isReadOnly();

		if (!isReadOnly) {
			// Once a database is version 10.5 we will start updating metadata SPSes
			// on any version change,up or down.  This will ensure that metadata queries 
			// match the version we are using.  We don't want to do this for lower 
			// database versions because on reverting to the previous version the 
			// SPSes won't be restored.
			if (fromVersion.majorVersionNumber >= DataDictionary.DD_VERSION_DERBY_10_5)
				bootingDictionary.updateMetadataSPSes(tc);
			//Following make sure that the stored plans (including the ones for
			//triggers) will get cleared during upgrade and hence we will not
			//hold on to stale plans.
			bootingDictionary.clearSPSPlans();

			DD_Version lastRun;
			
			if (softUpgradeRun)
			{
				// log a version that will cause a minor revision change
				// for any subsequent re-boot, including an old Cloudscape version
				fromVersion.minorVersionNumber = 1; // see getJBMSMinorVersionNumber
				lastRun = fromVersion;
			}
			else
			{
				// log the new version
				lastRun = this;
			
				// and change the in-memory version.
				fromVersion.majorVersionNumber = majorVersionNumber;
				fromVersion.minorVersionNumber = minorVersionNumber;
			}

			tc.setProperty(DataDictionary.CORE_DATA_DICTIONARY_VERSION, fromVersion, true);
		}
		else
		{
			// For a readonly database where we need some kind of upgrade
			// (either minor release or soft upgrade) then since we cannot
			// invalidate all the procedures we need to indicate that
			// any procedure we read off disk is automatically invalid,
			// so we do not try to load the generated class.
			bootingDictionary.setReadOnlyUpgrade();
		}

		bootingDictionary.clearCaches();
	}"
https://github.com/apache/derby/tree/eea0d50c8d732cad9ba563ddfa786b7028eb092f//java/engine/org/apache/derby/impl/sql/catalog/DataDictionaryImpl.java,addConstraintDescriptor,open,"public void	addConstraintDescriptor(
			ConstraintDescriptor descriptor,
			TransactionController tc)
		throws StandardException
	{
		int						type = descriptor.getConstraintType();

		if (SanityManager.DEBUG)
		{
			if (!(type == DataDictionary.PRIMARYKEY_CONSTRAINT ||
								 type == DataDictionary.FOREIGNKEY_CONSTRAINT ||
								 type == DataDictionary.UNIQUE_CONSTRAINT ||
								 type == DataDictionary.CHECK_CONSTRAINT))
			{
				SanityManager.THROWASSERT(""constraint type ("" + type +
					"") is unexpected value"");
			}
		}

		addDescriptor(descriptor, descriptor.getSchemaDescriptor(),
					  SYSCONSTRAINTS_CATALOG_NUM, false,
					  tc);

		switch (type)
		{
			case DataDictionary.PRIMARYKEY_CONSTRAINT:
			case DataDictionary.FOREIGNKEY_CONSTRAINT:
			case DataDictionary.UNIQUE_CONSTRAINT:
				if (SanityManager.DEBUG)
				{
					if (!(descriptor instanceof KeyConstraintDescriptor))
					{
						SanityManager.THROWASSERT(
							""descriptor expected to be instanceof KeyConstraintDescriptor, "" +
							""not, "" + descriptor.getClass().getName());
					}
				}

				addSubKeyConstraint((KeyConstraintDescriptor) descriptor, tc);
				break;

			case DataDictionary.CHECK_CONSTRAINT:
				if (SanityManager.DEBUG)
				{
					if (!(descriptor instanceof CheckConstraintDescriptor))
					{
						SanityManager.THROWASSERT(""descriptor expected ""+
							""to be instanceof CheckConstraintDescriptorImpl, "" +
							""not, "" + descriptor.getClass().getName());
					}
				}

				addDescriptor(descriptor, null, SYSCHECKS_CATALOG_NUM, true, tc);
				break;
		}
	}"
https://github.com/apache/derby/tree/eea0d50c8d732cad9ba563ddfa786b7028eb092f//java/engine/org/apache/derby/impl/sql/catalog/DataDictionaryImpl.java,dropAllPermDescriptors,open,"public void dropAllPermDescriptors(UUID objectID, TransactionController tc)
            throws StandardException {
        TabInfoImpl ti = getNonCoreTI(SYSPERMS_CATALOG_NUM);
        SYSPERMSRowFactory rf = (SYSPERMSRowFactory) ti.getCatalogRowFactory();
        DataValueDescriptor objIdOrderable;
        ExecRow curRow;
        PermissionsDescriptor perm;

        // In Derby authorization mode, permission catalogs may not be present
        if (!usesSqlAuthorization)
            return;

        /* Use objIDOrderable in both start and stop position for scan. */
        objIdOrderable = getIDValueAsCHAR(objectID);

        /* Set up the start/stop position for the scan */
        ExecIndexRow keyRow = exFactory.getIndexableRow(1);
        keyRow.setColumn(1, objIdOrderable);

        while ((curRow = ti.getRow(tc, keyRow, rf.PERMS_OBJECTID_IDX_NUM)) != null) {
            perm = (PermissionsDescriptor) rf.buildDescriptor(curRow, (TupleDescriptor) null, this);
            removePermEntryInCache(perm);

            // Build new key based on UUID and drop the entry as we want to drop
            // only this row
            ExecIndexRow uuidKey;
            uuidKey = rf.buildIndexKeyRow(rf.PERMS_UUID_IDX_NUM, perm);
            ti.deleteRow(tc, uuidKey, rf.PERMS_UUID_IDX_NUM);
        }
    }"
https://github.com/apache/derby/tree/eea0d50c8d732cad9ba563ddfa786b7028eb092f//java/engine/org/apache/derby/impl/sql/catalog/DataDictionaryImpl.java,isSchemaReferenced,close,"protected boolean isSchemaReferenced(TransactionController	tc, 
						TabInfoImpl					ti, 
						int						indexId, 
						int						indexCol, 
						DataValueDescriptor		schemaIdOrderable )
		throws StandardException
	{
		ConglomerateController	heapCC = null;
		ScanController			scanController = null;
		boolean					foundRow;
		FormatableBitSet					colToCheck = new FormatableBitSet(indexCol);
		CatalogRowFactory		rf = ti.getCatalogRowFactory();	

		if (SanityManager.DEBUG)
		{
			SanityManager.ASSERT(indexId >= 0, ""code needs to be enhanced""+
				"" to support a table scan to find the index id"");
		}

		colToCheck.set(indexCol - 1);

		ScanQualifier[][] qualifier = exFactory.getScanQualifier(1);
		qualifier[0][0].setQualifier
				(indexCol - 1,
				 schemaIdOrderable,
				 Orderable.ORDER_OP_EQUALS,
				 false,
				 false,
				 false);

		try
		{
			heapCC = 
	            tc.openConglomerate(
	                ti.getHeapConglomerate(), false, 0, 
                    TransactionController.MODE_RECORD,
                    TransactionController.ISOLATION_REPEATABLE_READ);
	
			scanController = tc.openScan(
					ti.getIndexConglomerate(indexId),	// conglomerate to open
					false, 								// don't hold open across commit
					0,                                  // for read
	                TransactionController.MODE_RECORD,	// row locking
                    TransactionController.ISOLATION_REPEATABLE_READ,
					colToCheck, 						// don't get any rows
					null,   							// start position - first row
					ScanController.GE,      			// startSearchOperation
					qualifier, 							// scanQualifier,
					null,   							// stop position - through last row
					ScanController.GT);     			// stopSearchOperation
	
			foundRow = (scanController.next());
		}
		finally
		{
			if (scanController != null)	
			{
				scanController.close();
			}
			if (heapCC != null)
			{
				heapCC.close();
			}
		}
		
		return foundRow;
	}"
https://github.com/apache/derby/tree/eea0d50c8d732cad9ba563ddfa786b7028eb092f//java/engine/org/apache/derby/impl/sql/catalog/DataDictionaryImpl.java,populateSYSDUMMY1,open,"protected void populateSYSDUMMY1(
							TransactionController tc)
		throws StandardException
	{
		TabInfoImpl						ti = getNonCoreTI(SYSDUMMY1_CATALOG_NUM);
		ExecRow row = ti.getCatalogRowFactory().makeRow(null, null);

		int insertRetCode = ti.insertRow(row, tc);
	}"
https://github.com/apache/derby/tree/eea0d50c8d732cad9ba563ddfa786b7028eb092f//java/engine/org/apache/derby/impl/sql/catalog/DataDictionaryImpl.java,upgradeSYSROUTINEPERMS_10_6,open,"void upgradeSYSROUTINEPERMS_10_6( TransactionController tc )
        throws StandardException
    {
        //
        // Get the aliasID of SYSCS_INPLACE_COMPRESS_TABLE
        //
		TabInfoImpl          aliasTI = getNonCoreTI(SYSALIASES_CATALOG_NUM);
		ExecIndexRow         aliasKeyRow = exFactory.getIndexableRow(3);
		DataValueDescriptor  aliasNameOrderable = new SQLVarchar( ""SYSCS_INPLACE_COMPRESS_TABLE"" );;
		DataValueDescriptor	 nameSpaceOrderable = new SQLChar
            ( new String( new char[] { AliasInfo.ALIAS_TYPE_PROCEDURE_AS_CHAR } ) );
        
		aliasKeyRow.setColumn(1, new SQLChar( SchemaDescriptor.SYSCS_UTIL_SCHEMA_UUID ));
		aliasKeyRow.setColumn(2, aliasNameOrderable);
		aliasKeyRow.setColumn(3, nameSpaceOrderable);

        AliasDescriptor      oldAD = (AliasDescriptor) getDescriptorViaIndex
            (
             SYSALIASESRowFactory.SYSALIASES_INDEX1_ID,
             aliasKeyRow,
             (ScanQualifier [][]) null,
             aliasTI,
             (TupleDescriptor) null,
             (List) null,
             true,
             TransactionController.ISOLATION_REPEATABLE_READ,
             tc);
        UUID                 aliasID = oldAD.getUUID();

        //
        // Now delete the permissions tuple which has a null grantor
        //
		TabInfoImpl          rpTI = getNonCoreTI(SYSROUTINEPERMS_CATALOG_NUM);
		ExecIndexRow         rpKeyRow = exFactory.getIndexableRow(3);

		rpKeyRow.setColumn(1, new SQLVarchar( ""PUBLIC"" ));
		rpKeyRow.setColumn(2, new SQLChar( aliasID.toString() ));
		rpKeyRow.setColumn(3, new SQLVarchar( (String) null ) );

		int deleteCount = rpTI.deleteRow(tc, rpKeyRow, SYSROUTINEPERMSRowFactory.GRANTEE_ALIAS_GRANTOR_INDEX_NUM);
    }"
https://github.com/apache/derby/tree/eea0d50c8d732cad9ba563ddfa786b7028eb092f//java/engine/org/apache/derby/impl/sql/catalog/DataDictionaryImpl.java,makePasswordHasher,close,"public  PasswordHasher  makePasswordHasher( Dictionary props )
        throws StandardException
    {
        // Support for configurable hash algorithm was added in Derby 10.6, so
        // we don't want to store a hash using the new scheme if the database
        // is running in soft upgrade and may be used with an older version
        // later.
        boolean supportConfigurableHash = checkVersion(DataDictionary.DD_VERSION_DERBY_10_6, null);

        // Support for key stretching was added in Derby 10.9, so don't use it
        // if the database may still be used with an older version.
        boolean supportKeyStretching = checkVersion(DataDictionary.DD_VERSION_DERBY_10_9, null);

        if ( !supportConfigurableHash ) { return null; }
        else
        {
            String algorithm = (String)
                    PropertyUtil.getPropertyFromSet(
                        props,
                        Property.AUTHENTICATION_BUILTIN_ALGORITHM);

            if ( algorithm == null ) { return null; }

            byte[] salt = null;
            int iterations = 1;
            
            if (algorithm != null && algorithm.length() > 0) {

                if (supportKeyStretching) {
                    salt = generateRandomSalt(props);
                    iterations = getIntProperty(
                            props,
                            Property.AUTHENTICATION_BUILTIN_ITERATIONS,
                            Property.AUTHENTICATION_BUILTIN_ITERATIONS_DEFAULT,
                            1, Integer.MAX_VALUE);
                }
            }

            return new PasswordHasher( algorithm, salt, iterations );
        }
    }"
https://github.com/apache/derby/tree/eea0d50c8d732cad9ba563ddfa786b7028eb092f//java/engine/org/apache/derby/impl/sql/catalog/DataDictionaryImpl.java,addConstraintDescriptor,open,"public void	addConstraintDescriptor(
			ConstraintDescriptor descriptor,
			TransactionController tc)
		throws StandardException
	{
		int						type = descriptor.getConstraintType();

		if (SanityManager.DEBUG)
		{
			if (!(type == DataDictionary.PRIMARYKEY_CONSTRAINT ||
								 type == DataDictionary.FOREIGNKEY_CONSTRAINT ||
								 type == DataDictionary.UNIQUE_CONSTRAINT ||
								 type == DataDictionary.CHECK_CONSTRAINT))
			{
				SanityManager.THROWASSERT(""constraint type ("" + type +
					"") is unexpected value"");
			}
		}

		addDescriptor(descriptor, descriptor.getSchemaDescriptor(),
					  SYSCONSTRAINTS_CATALOG_NUM, false,
					  tc);

		switch (type)
		{
			case DataDictionary.PRIMARYKEY_CONSTRAINT:
			case DataDictionary.FOREIGNKEY_CONSTRAINT:
			case DataDictionary.UNIQUE_CONSTRAINT:
				if (SanityManager.DEBUG)
				{
					if (!(descriptor instanceof KeyConstraintDescriptor))
					{
						SanityManager.THROWASSERT(
							""descriptor expected to be instanceof KeyConstraintDescriptor, "" +
							""not, "" + descriptor.getClass().getName());
					}
				}

				addSubKeyConstraint((KeyConstraintDescriptor) descriptor, tc);
				break;

			case DataDictionary.CHECK_CONSTRAINT:
				if (SanityManager.DEBUG)
				{
					if (!(descriptor instanceof CheckConstraintDescriptor))
					{
						SanityManager.THROWASSERT(""descriptor expected ""+
							""to be instanceof CheckConstraintDescriptorImpl, "" +
							""not, "" + descriptor.getClass().getName());
					}
				}

				addDescriptor(descriptor, null, SYSCHECKS_CATALOG_NUM, true, tc);
				break;
		}
	}"
https://github.com/apache/derby/tree/eea0d50c8d732cad9ba563ddfa786b7028eb092f//java/engine/org/apache/derby/impl/sql/catalog/SYSTRIGGERSRowFactory.java,buildDescriptor,close,"public TupleDescriptor buildDescriptor
	(
		ExecRow					row,
		TupleDescriptor			parentTupleDescriptor,
		DataDictionary 			dd 
	) throws StandardException
	{
		DataValueDescriptor		col;
		String					name;
		char					theChar;
		String					uuidStr;
		String					triggerDefinition;
		String					oldReferencingName;
		String					newReferencingName;
		UUID					uuid;	
		UUID					suuid;					// schema	
		UUID					tuuid;					// referenced table	
		UUID					actionSPSID = null;		// action sps uuid string
		UUID					whenSPSID = null;		// when clause sps uuid string
		Timestamp				createTime;
		int						eventMask = 0;
		boolean					isBefore;
		boolean					isRow;
		boolean					isEnabled;
		boolean					referencingOld;
		boolean					referencingNew;
		ReferencedColumns rcd;
		TriggerDescriptor		descriptor;
		DataDescriptorGenerator	ddg = dd.getDataDescriptorGenerator();

		if (SanityManager.DEBUG)
		{
			SanityManager.ASSERT(row.nColumns() == SYSTRIGGERS_COLUMN_COUNT, 
								 ""Wrong number of columns for a SYSTRIGGERS row"");
		}

		// 1st column is TRIGGERID (UUID - char(36))
		col = row.getColumn(1);
		uuidStr = col.getString();
		uuid = getUUIDFactory().recreateUUID(uuidStr);

		// 2nd column is TRIGGERNAME (varchar(128))
		col = row.getColumn(2);
		name = col.getString();

		// 3rd column is SCHEMAID (UUID - char(36))
		col = row.getColumn(3);
		uuidStr = col.getString();
		suuid = getUUIDFactory().recreateUUID(uuidStr);

		// 4th column is CREATIONTIMESTAMP (TIMESTAMP)
		col = row.getColumn(4);
		createTime = (Timestamp) col.getObject();

		// 5th column is EVENT (char(1))
		col = row.getColumn(5);
		theChar = col.getString().charAt(0);
		switch (theChar)
		{
			case 'U': 
						eventMask = TriggerDescriptor.TRIGGER_EVENT_UPDATE;
						break;

			case 'I': 
						eventMask = TriggerDescriptor.TRIGGER_EVENT_INSERT;
						break;

			case 'D': 
						eventMask = TriggerDescriptor.TRIGGER_EVENT_DELETE;
						break;

			default:
					if (SanityManager.DEBUG)	
					{
						SanityManager.THROWASSERT(""bad event mask: ""+theChar);
					}
		}
		
		// 6th column is FIRINGTIME (char(1))
		isBefore = getCharBoolean(row.getColumn(6), 'B', 'A');

		// 7th column is TYPE (char(1))
		isRow = getCharBoolean(row.getColumn(7), 'R', 'S');

		// 8th column is STATE (char(1))
		isEnabled = getCharBoolean(row.getColumn(8), 'E', 'D');

		// 9th column is TABLEID (UUID - char(36))
		col = row.getColumn(9);
		uuidStr = col.getString();
		tuuid = getUUIDFactory().recreateUUID(uuidStr);

		// 10th column is WHENSTMTID (UUID - char(36))
		col = row.getColumn(10);
		uuidStr = col.getString();
		if (uuidStr != null)
			whenSPSID = getUUIDFactory().recreateUUID(uuidStr);

		// 11th column is ACTIONSTMTID (UUID - char(36))
		col = row.getColumn(11);
		uuidStr = col.getString();
		if (uuidStr != null)
			actionSPSID = getUUIDFactory().recreateUUID(uuidStr);

		// 12th column is REFERENCEDCOLUMNS user type org.apache.derby.catalog.ReferencedColumns
		col = row.getColumn(12);
		rcd = (ReferencedColumns) col.getObject();
		
		// 13th column is TRIGGERDEFINITION (longvarhar)
		col = row.getColumn(13);
		triggerDefinition = col.getString();

		// 14th column is REFERENCINGOLD (boolean)
		col = row.getColumn(14);
		referencingOld = col.getBoolean();

		// 15th column is REFERENCINGNEW (boolean)
		col = row.getColumn(15);
		referencingNew = col.getBoolean();

		// 16th column is REFERENCINGNAME (varchar(128))
		col = row.getColumn(16);
		oldReferencingName = col.getString();

		// 17th column is REFERENCINGNAME (varchar(128))
		col = row.getColumn(17);
		newReferencingName = col.getString();

		descriptor = new TriggerDescriptor(
									dd,
									dd.getSchemaDescriptor(suuid, null),
									uuid, 
									name, 
									eventMask,
									isBefore, 
									isRow,
									isEnabled,
									dd.getTableDescriptor(tuuid),
									whenSPSID,
									actionSPSID,
									createTime,
									(rcd == null) ? (int[])null : rcd.getReferencedColumnPositions(),
									(rcd == null) ? (int[])null : rcd.getTriggerActionReferencedColumnPositions(),
									triggerDefinition,
									referencingOld,
									referencingNew,
									oldReferencingName,
									newReferencingName
									);

		return descriptor;
	}"
https://github.com/apache/derby/tree/eea0d50c8d732cad9ba563ddfa786b7028eb092f//java/engine/org/apache/derby/impl/sql/catalog/SYSUSERSRowFactory.java,makeRow,open,"public ExecRow makeRow( TupleDescriptor td, TupleDescriptor parent )
        throws StandardException
	{
		String  userName = null;
		String  hashingScheme = null;
		char[]  password = null;
		Timestamp   lastModified = null;
		
		ExecRow        			row;

        try {
            if ( td != null )	
            {
                UserDescriptor descriptor = (UserDescriptor) td;
                userName = descriptor.getUserName();
                hashingScheme = descriptor.getHashingScheme();
                password = descriptor.getAndZeroPassword();
                lastModified = descriptor.getLastModified();
            }
	
            /* Build the row to insert  */
            row = getExecutionFactory().getValueRow( SYSUSERS_COLUMN_COUNT );

            /* 1st column is USERNAME (varchar(128)) */
            row.setColumn( USERNAME_COL_NUM, new SQLVarchar( userName ) );

            /* 2nd column is HASHINGSCHEME (varchar(32672)) */
            row.setColumn( HASHINGSCHEME_COL_NUM, new SQLVarchar( hashingScheme ) );

            /* 3rd column is PASSWORD (varchar(32672)) */
            row.setColumn( PASSWORD_COL_NUM, new SQLVarchar( password ) );

            /* 4th column is LASTMODIFIED (timestamp) */
            row.setColumn( LASTMODIFIED_COL_NUM, new SQLTimestamp( lastModified ) );
        }
        finally
        {
            // zero out the password to prevent it from being memory-sniffed
            if ( password != null ) { Arrays.fill( password, (char) 0 ); }
        }

		return row;
	}"
https://github.com/apache/derby/tree/eea0d50c8d732cad9ba563ddfa786b7028eb092f//java/engine/org/apache/derby/impl/sql/catalog/SYSVIEWSRowFactory.java,makeRow,open,"public ExecRow makeRow(TupleDescriptor td, TupleDescriptor parent)
		throws StandardException 
	{
		DataValueDescriptor		col;
		ExecRow    				row;
		String					tableID = null;
		String					compSchemaId = null;
		String					viewText = null;
		String	   				checkSType = null;
		int	   					checkIType;

		if (td != null)
		{
			UUID	tableUUID;
			ViewDescriptor vd = (ViewDescriptor)td;

			/*
			** We only allocate a new UUID if the descriptor doesn't already have one.
			** For descriptors replicated from a Source system, we already have an UUID.
			*/
			tableUUID = vd.getUUID();
			if ( tableUUID == null )
		    {
				tableUUID = getUUIDFactory().createUUID();
				vd.setUUID(tableUUID);
			}
			tableID = tableUUID.toString();
			viewText = vd.getViewText();

			/* RESOLVE - check constraints not supported yet */
			checkIType = vd.getCheckOptionType();

			if (SanityManager.DEBUG)
			{
				if (checkIType != ViewDescriptor.NO_CHECK_OPTION)
				{
					SanityManager.THROWASSERT(""checkIType expected to be "" + 
						ViewDescriptor.NO_CHECK_OPTION +
						"", not "" + checkIType);
				}
			}
			checkSType = ""N"";

			UUID tmpId = vd.getCompSchemaId();
			compSchemaId = (tmpId == null) ? null : tmpId.toString();
		}

		/* Insert info into sysviews */

		/* RESOLVE - It would be nice to require less knowledge about sysviews
		 * and have this be more table driven.
		 */

		/* Build the row to insert  */
		row = getExecutionFactory().getValueRow(SYSVIEWS_COLUMN_COUNT);

		/* 1st column is TABLEID (UUID - char(36)) */
		row.setColumn(SYSVIEWS_TABLEID, new SQLChar(tableID));

		/* 2nd column is VIEWDEFINITION */
		row.setColumn(SYSVIEWS_VIEWDEFINITION,
				dvf.getLongvarcharDataValue(viewText));

		/* 3rd column is CHECKOPTION (char(1)) */
		row.setColumn(SYSVIEWS_CHECKOPTION, new SQLChar(checkSType));

		/* 4th column is COMPILATIONSCHEMAID (UUID - char(36)) */
		row.setColumn(SYSVIEWS_COMPILATION_SCHEMAID, new SQLChar(compSchemaId));

		return row;
	}"
https://github.com/apache/derby/tree/eea0d50c8d732cad9ba563ddfa786b7028eb092f//java/engine/org/apache/derby/impl/sql/compile/BinaryComparisonOperatorNode.java,bindComparisonOperator,close,"public void bindComparisonOperator()
			throws StandardException
	{
		TypeId	leftType;
		TypeId	rightType;
		boolean				nullableResult;

		leftType = leftOperand.getTypeId();
		rightType = rightOperand.getTypeId();


		/*
		** Can the types be compared to each other?  If not, throw an
		** exception.
		*/
		boolean forEquals = operator.equals(""="") || operator.equals(""<>"");

        boolean cmp = leftOperand.getTypeServices().comparable(
        		rightOperand.getTypeServices(),
				forEquals,
				getClassFactory());
		// Bypass the comparable check if this is a rewrite from the 
		// optimizer.  We will assume Mr. Optimizer knows what he is doing.
          if (!cmp && !forQueryRewrite) {
			throw StandardException.newException(SQLState.LANG_NOT_COMPARABLE, 
					leftOperand.getTypeServices().getSQLTypeNameWithCollation() ,
					rightOperand.getTypeServices().getSQLTypeNameWithCollation());
				
		  }

		
		/*
		** Set the result type of this comparison operator based on the
		** operands.  The result type is always SQLBoolean - the only question
		** is whether it is nullable or not.  If either of the operands is
		** nullable, the result of the comparison must be nullable, too, so
		** we can represent the unknown truth value.
		*/
		nullableResult = leftOperand.getTypeServices().isNullable() ||
							rightOperand.getTypeServices().isNullable();
		setType(new DataTypeDescriptor(TypeId.BOOLEAN_ID, nullableResult));


	}"
https://github.com/apache/derby/tree/eea0d50c8d732cad9ba563ddfa786b7028eb092f//java/engine/org/apache/derby/impl/sql/compile/BinaryComparisonOperatorNode.java,bindExpression,close,"public ValueNode bindExpression(
		FromList fromList, SubqueryList subqueryList,
		Vector	aggregateVector)
			throws StandardException
	{
		super.bindExpression(fromList, subqueryList, aggregateVector);

		TypeCompiler leftTC = leftOperand.getTypeCompiler();
		TypeCompiler rightTC = rightOperand.getTypeCompiler();
		TypeId leftTypeId = leftOperand.getTypeId();
		TypeId rightTypeId = rightOperand.getTypeId();

		/*
		 * If we are comparing a non-string with a string type, then we
		 * must prevent the non-string value from being used to probe into
		 * an index on a string column. This is because the string types
		 * are all of low precedence, so the comparison rules of the non-string
		 * value are used, so it may not find values in a string index because
		 * it will be in the wrong order. So, cast the string value to its
		 * own type. This is easier than casting it to the non-string type,
		 * because we would have to figure out the right length to cast it to.
		 */
		if (! leftTypeId.isStringTypeId() && rightTypeId.isStringTypeId())
		{
			DataTypeDescriptor rightTypeServices = rightOperand.getTypeServices();

			rightOperand =  (ValueNode)
				getNodeFactory().getNode(
					C_NodeTypes.CAST_NODE,
					rightOperand, 
					new DataTypeDescriptor(
							rightTypeId,
							true, 
							rightTypeServices.getMaximumWidth()),
					getContextManager());
			((CastNode) rightOperand).bindCastNodeOnly();
		}
		else if (! rightTypeId.isStringTypeId() && leftTypeId.isStringTypeId())
		{
			DataTypeDescriptor leftTypeServices = leftOperand.getTypeServices();

			leftOperand =  (ValueNode)
				getNodeFactory().getNode(
					C_NodeTypes.CAST_NODE,
					leftOperand, 
					new DataTypeDescriptor(
							leftTypeId,
							true, 
							leftTypeServices.getMaximumWidth()),
					getContextManager());
			((CastNode) leftOperand).bindCastNodeOnly();
		}

		/* Test type compatability and set type info for this node */
		bindComparisonOperator();

		return this;
	}"
https://github.com/apache/derby/tree/eea0d50c8d732cad9ba563ddfa786b7028eb092f//java/engine/org/apache/derby/impl/sql/compile/BinaryOperatorNode.java,bindXMLQuery,close,"public ValueNode bindXMLQuery()
        throws StandardException
    {
        // Check operand types.
        TypeId leftOperandType = leftOperand.getTypeId();
        TypeId rightOperandType = rightOperand.getTypeId();

        // Left operand is query expression and must be a string
        // literal.  SQL/XML spec doesn't allow params nor expressions
        // 6.17: <XQuery expression> ::= <character string literal> 
        if (!(leftOperand instanceof CharConstantNode))
        {
            throw StandardException.newException(
                SQLState.LANG_INVALID_XML_QUERY_EXPRESSION);
        }
        else {
            xmlQuery = ((CharConstantNode)leftOperand).getString();
        }

        // Right operand must be an XML data value.  NOTE: This
        // is a Derby-specific restriction, not an SQL/XML one.
        // We have this restriction because the query engine
        // that we use (currently Xalan) cannot handle non-XML
        // context items.
        if ((rightOperandType != null) &&
            !rightOperandType.isXMLTypeId())
        {
            throw StandardException.newException(
                SQLState.LANG_INVALID_CONTEXT_ITEM_TYPE,
                rightOperandType.getSQLTypeName());
        }

        // Is there a ? parameter on the right?
        if (rightOperand.requiresTypeFromContext())
        {
            // For now, since JDBC has no type defined for XML, we
            // don't allow binding to an XML parameter.
            throw StandardException.newException(
                SQLState.LANG_ATTEMPT_TO_BIND_XML);
        }

        // Set the result type of this operator.
        if (operatorType == XMLEXISTS_OP) {
        // For XMLEXISTS, the result type is always SQLBoolean.
        // The ""true"" in the next line says that the result
        // can be nullable--which it can be if evaluation of
        // the expression returns a null (this is per SQL/XML
        // spec, 8.4)
            setType(new DataTypeDescriptor(TypeId.BOOLEAN_ID, true));
        }
        else {
        // The result of an XMLQUERY operator is always another
        // XML data value, per SQL/XML spec 6.17: ""...yielding a value
        // X1 of an XML type.""
            setType(DataTypeDescriptor.getBuiltInDataTypeDescriptor(
                    JDBC40Translation.SQLXML));
        }

        return genSQLJavaSQLTree();
    }"
https://github.com/apache/derby/tree/eea0d50c8d732cad9ba563ddfa786b7028eb092f//java/engine/org/apache/derby/impl/sql/compile/BinaryRelationalOperatorNode.java,generateOperator,open,"public void generateOperator(MethodBuilder mb,
								 Optimizable optTable)
	{
		switch (operatorType)
		{
			case RelationalOperator.EQUALS_RELOP:
				mb.push(Orderable.ORDER_OP_EQUALS);
				break;

			case RelationalOperator.NOT_EQUALS_RELOP:
				mb.push(Orderable.ORDER_OP_EQUALS);
				break;

			case RelationalOperator.LESS_THAN_RELOP:
			case RelationalOperator.GREATER_EQUALS_RELOP:
				mb.push(keyColumnOnLeft(optTable) ? 
						Orderable.ORDER_OP_LESSTHAN : Orderable.ORDER_OP_LESSOREQUALS);
				break;
			case RelationalOperator.LESS_EQUALS_RELOP:
			case RelationalOperator.GREATER_THAN_RELOP:
				mb.push(keyColumnOnLeft(optTable) ? 
						Orderable.ORDER_OP_LESSOREQUALS : Orderable.ORDER_OP_LESSTHAN);
				
		}											
	}"
https://github.com/apache/derby/tree/eea0d50c8d732cad9ba563ddfa786b7028eb092f//java/engine/org/apache/derby/impl/sql/compile/BinaryRelationalOperatorNode.java,generateNegate,open,"public void generateNegate(MethodBuilder mb, Optimizable optTable)
	{
		switch (operatorType)
		{
			case RelationalOperator.EQUALS_RELOP:
				mb.push(false);
				break;
			case RelationalOperator.NOT_EQUALS_RELOP:
				mb.push(true);
				break;
			case RelationalOperator.LESS_THAN_RELOP:
			case RelationalOperator.LESS_EQUALS_RELOP:
				mb.push(!keyColumnOnLeft(optTable));
				break;
			case RelationalOperator.GREATER_THAN_RELOP:
			case RelationalOperator.GREATER_EQUALS_RELOP:
				mb.push(keyColumnOnLeft(optTable));
				break;
		}
		
		return;
	}"
https://github.com/apache/derby/tree/eea0d50c8d732cad9ba563ddfa786b7028eb092f//java/engine/org/apache/derby/impl/sql/compile/BinaryRelationalOperatorNode.java,generateOperator,open,"public void generateOperator(MethodBuilder mb,
								 Optimizable optTable)
	{
		switch (operatorType)
		{
			case RelationalOperator.EQUALS_RELOP:
				mb.push(Orderable.ORDER_OP_EQUALS);
				break;

			case RelationalOperator.NOT_EQUALS_RELOP:
				mb.push(Orderable.ORDER_OP_EQUALS);
				break;

			case RelationalOperator.LESS_THAN_RELOP:
			case RelationalOperator.GREATER_EQUALS_RELOP:
				mb.push(keyColumnOnLeft(optTable) ? 
						Orderable.ORDER_OP_LESSTHAN : Orderable.ORDER_OP_LESSOREQUALS);
				break;
			case RelationalOperator.LESS_EQUALS_RELOP:
			case RelationalOperator.GREATER_THAN_RELOP:
				mb.push(keyColumnOnLeft(optTable) ? 
						Orderable.ORDER_OP_LESSOREQUALS : Orderable.ORDER_OP_LESSTHAN);
				
		}											
	}"
https://github.com/apache/derby/tree/eea0d50c8d732cad9ba563ddfa786b7028eb092f//java/engine/org/apache/derby/impl/sql/compile/CastNode.java,bindExpression,close,"public ValueNode bindExpression(FromList fromList, SubqueryList subqueryList,
									Vector aggregateVector)
				throws StandardException
	{
		castOperand = castOperand.bindExpression(
								fromList, subqueryList,
								aggregateVector);

		if (getTypeServices() == null)   //CHAR or VARCHAR function without specifying target length
		{
			DataTypeDescriptor opndType = castOperand.getTypeServices();
			int length = -1;
			TypeId srcTypeId = opndType.getTypeId();
			if (opndType != null)
			{
				if (srcTypeId.isNumericTypeId())
				{
					length = opndType.getPrecision() + 1; // 1 for the sign
					if (opndType.getScale() > 0)
						length += 1;               // 1 for the decimal .
				 
				}
				/*
				 * Derby-1132 : The length for the target type was calculated
				 * incorrectly while Char & Varchar functions were used. Thus
				 * adding the check for Char & Varchar and calculating the
				 * length based on the operand type.
				 */
				else if(srcTypeId.isStringTypeId())
				{
					length = opndType.getMaximumWidth();
			
					// Truncate the target type width to the max width of the
					// data type
					if (this.targetCharType == Types.CHAR)
						length = Math.min(length, Limits.DB2_CHAR_MAXWIDTH);
					else if (this.targetCharType == Types.VARCHAR)
						length = Math.min(length, Limits.DB2_VARCHAR_MAXWIDTH);
				}
				else 
				{
					TypeId typeid = opndType.getTypeId();
					if (length < 0)
						length = DataTypeUtilities.getColumnDisplaySize(typeid.getJDBCTypeId(),-1);

				}
			}
			if (length < 0)
				length = 1;  // same default as in parser
			setType(DataTypeDescriptor.getBuiltInDataTypeDescriptor(targetCharType, length));
			
		}

		/* 
		** If castOperand is an untyped null, 
		** then we must set the type.
		*/
		if (castOperand instanceof UntypedNullConstantNode)
		{
			castOperand.setType(getTypeServices());
		}

		bindCastNodeOnly();
		
		/* We can't chop out cast above an untyped null because
		 * the store can't handle it.
		 */
		if ((castOperand instanceof ConstantNode) &&
			!(castOperand instanceof UntypedNullConstantNode))
		{
			/* If the castOperand is a typed constant then we do the cast at
			 * bind time and return a constant of the correct type.
			 * NOTE: This could return an exception, but we're prepared to 
			 * deal with that. (NumberFormatException, etc.)
			 * We only worry about the easy (and useful)
			 * converions at bind time.
			 * Here's what we support:
			 *			source					destination
			 *			------					-----------
			 *			boolean					boolean
			 *			boolean					char
			 *			char					boolean
			 *			char					date/time/ts
			 *			char					non-decimal numeric
			 *			date/time/ts			char
			 *			numeric					char
			 *			numeric					non-decimal numeric
			 */
			/* RESOLVE - to be filled in. */
			ValueNode retNode = this;
			int		  sourceJDBCTypeId = sourceCTI.getJDBCTypeId();
			int		  destJDBCTypeId = getTypeId().getJDBCTypeId();

			switch (sourceJDBCTypeId)
			{
				case Types.BIT:
				case Types.BOOLEAN:
					// (BIT is boolean)
					if (destJDBCTypeId == Types.BIT || destJDBCTypeId == Types.BOOLEAN)
					{
						retNode = castOperand;
					}
					else if (destJDBCTypeId == Types.CHAR)
					{
						BooleanConstantNode bcn = (BooleanConstantNode) castOperand;
						String booleanString = bcn.getValueAsString();
						retNode = (ValueNode) getNodeFactory().getNode(
											C_NodeTypes.CHAR_CONSTANT_NODE,
											booleanString,
											ReuseFactory.getInteger(
                                                    getTypeServices().getMaximumWidth()),
											getContextManager());
					}
					break;

					case Types.CHAR:
						retNode = getCastFromCharConstant(destJDBCTypeId);
						break;

					case Types.DATE:
					case Types.TIME:
					case Types.TIMESTAMP:
						if (destJDBCTypeId == Types.CHAR)
						{
							String castValue =  
								((UserTypeConstantNode) castOperand).
											getObjectValue().
												toString();
							retNode = (ValueNode) getNodeFactory().getNode(
												C_NodeTypes.CHAR_CONSTANT_NODE,
												castValue, 
												ReuseFactory.getInteger(
                                                        getTypeServices().getMaximumWidth()),
												getContextManager());
						}
						break;

					case Types.DECIMAL:
						// ignore decimal -> decimal casts for now
						if (destJDBCTypeId == Types.DECIMAL ||
							destJDBCTypeId == Types.NUMERIC)
							break;
						// fall through
					case Types.TINYINT:
					case Types.SMALLINT:
					case Types.INTEGER:
					case Types.BIGINT:
					case Types.DOUBLE:
					case Types.REAL:
						retNode = getCastFromNumericType(
											((ConstantNode) castOperand).getValue(), 
											destJDBCTypeId);
						break;

			}

			// Return the new constant if the cast was performed
			return retNode;
		}

		return this;
	}"
https://github.com/apache/derby/tree/eea0d50c8d732cad9ba563ddfa786b7028eb092f//java/engine/org/apache/derby/impl/sql/compile/CastNode.java,bindExpression,open,"public ValueNode bindExpression(FromList fromList, SubqueryList subqueryList,
									Vector aggregateVector)
				throws StandardException
	{
		castOperand = castOperand.bindExpression(
								fromList, subqueryList,
								aggregateVector);

		if (getTypeServices() == null)   //CHAR or VARCHAR function without specifying target length
		{
			DataTypeDescriptor opndType = castOperand.getTypeServices();
			int length = -1;
			TypeId srcTypeId = opndType.getTypeId();
			if (opndType != null)
			{
				if (srcTypeId.isNumericTypeId())
				{
					length = opndType.getPrecision() + 1; // 1 for the sign
					if (opndType.getScale() > 0)
						length += 1;               // 1 for the decimal .
				 
				}
				/*
				 * Derby-1132 : The length for the target type was calculated
				 * incorrectly while Char & Varchar functions were used. Thus
				 * adding the check for Char & Varchar and calculating the
				 * length based on the operand type.
				 */
				else if(srcTypeId.isStringTypeId())
				{
					length = opndType.getMaximumWidth();
			
					// Truncate the target type width to the max width of the
					// data type
					if (this.targetCharType == Types.CHAR)
						length = Math.min(length, Limits.DB2_CHAR_MAXWIDTH);
					else if (this.targetCharType == Types.VARCHAR)
						length = Math.min(length, Limits.DB2_VARCHAR_MAXWIDTH);
				}
				else 
				{
					TypeId typeid = opndType.getTypeId();
					if (length < 0)
						length = DataTypeUtilities.getColumnDisplaySize(typeid.getJDBCTypeId(),-1);

				}
			}
			if (length < 0)
				length = 1;  // same default as in parser
			setType(DataTypeDescriptor.getBuiltInDataTypeDescriptor(targetCharType, length));
			
		}

		/* 
		** If castOperand is an untyped null, 
		** then we must set the type.
		*/
		if (castOperand instanceof UntypedNullConstantNode)
		{
			castOperand.setType(getTypeServices());
		}

		bindCastNodeOnly();
		
		/* We can't chop out cast above an untyped null because
		 * the store can't handle it.
		 */
		if ((castOperand instanceof ConstantNode) &&
			!(castOperand instanceof UntypedNullConstantNode))
		{
			/* If the castOperand is a typed constant then we do the cast at
			 * bind time and return a constant of the correct type.
			 * NOTE: This could return an exception, but we're prepared to 
			 * deal with that. (NumberFormatException, etc.)
			 * We only worry about the easy (and useful)
			 * converions at bind time.
			 * Here's what we support:
			 *			source					destination
			 *			------					-----------
			 *			boolean					boolean
			 *			boolean					char
			 *			char					boolean
			 *			char					date/time/ts
			 *			char					non-decimal numeric
			 *			date/time/ts			char
			 *			numeric					char
			 *			numeric					non-decimal numeric
			 */
			/* RESOLVE - to be filled in. */
			ValueNode retNode = this;
			int		  sourceJDBCTypeId = sourceCTI.getJDBCTypeId();
			int		  destJDBCTypeId = getTypeId().getJDBCTypeId();

			switch (sourceJDBCTypeId)
			{
				case Types.BIT:
				case Types.BOOLEAN:
					// (BIT is boolean)
					if (destJDBCTypeId == Types.BIT || destJDBCTypeId == Types.BOOLEAN)
					{
						retNode = castOperand;
					}
					else if (destJDBCTypeId == Types.CHAR)
					{
						BooleanConstantNode bcn = (BooleanConstantNode) castOperand;
						String booleanString = bcn.getValueAsString();
						retNode = (ValueNode) getNodeFactory().getNode(
											C_NodeTypes.CHAR_CONSTANT_NODE,
											booleanString,
											ReuseFactory.getInteger(
                                                    getTypeServices().getMaximumWidth()),
											getContextManager());
					}
					break;

					case Types.CHAR:
						retNode = getCastFromCharConstant(destJDBCTypeId);
						break;

					case Types.DATE:
					case Types.TIME:
					case Types.TIMESTAMP:
						if (destJDBCTypeId == Types.CHAR)
						{
							String castValue =  
								((UserTypeConstantNode) castOperand).
											getObjectValue().
												toString();
							retNode = (ValueNode) getNodeFactory().getNode(
												C_NodeTypes.CHAR_CONSTANT_NODE,
												castValue, 
												ReuseFactory.getInteger(
                                                        getTypeServices().getMaximumWidth()),
												getContextManager());
						}
						break;

					case Types.DECIMAL:
						// ignore decimal -> decimal casts for now
						if (destJDBCTypeId == Types.DECIMAL ||
							destJDBCTypeId == Types.NUMERIC)
							break;
						// fall through
					case Types.TINYINT:
					case Types.SMALLINT:
					case Types.INTEGER:
					case Types.BIGINT:
					case Types.DOUBLE:
					case Types.REAL:
						retNode = getCastFromNumericType(
											((ConstantNode) castOperand).getValue(), 
											destJDBCTypeId);
						break;

			}

			// Return the new constant if the cast was performed
			return retNode;
		}

		return this;
	}"
https://github.com/apache/derby/tree/eea0d50c8d732cad9ba563ddfa786b7028eb092f//java/engine/org/apache/derby/impl/sql/compile/CastNode.java,getCastFromNumericType,open,"private ValueNode getCastFromNumericType(
									  DataValueDescriptor constantValue, 
									  int destJDBCTypeId)
		throws StandardException
	{
		int nodeType = -1;
		Object constantObject = null;

		switch (destJDBCTypeId)
		{
			case Types.CHAR:
				nodeType = C_NodeTypes.CHAR_CONSTANT_NODE;
				constantObject = constantValue.getString();
				return (ValueNode) getNodeFactory().getNode(
										nodeType,
										constantObject, 
										ReuseFactory.getInteger(
                                                getTypeServices().getMaximumWidth()),
										getContextManager());

			case Types.TINYINT:
				nodeType = C_NodeTypes.TINYINT_CONSTANT_NODE;
				constantObject = new Byte(constantValue.getByte());
				break;

			case Types.SMALLINT:
				nodeType = C_NodeTypes.SMALLINT_CONSTANT_NODE;
				constantObject = ReuseFactory.getShort(constantValue.getShort());
				break;

			case Types.INTEGER:
				nodeType = C_NodeTypes.INT_CONSTANT_NODE;
				constantObject = ReuseFactory.getInteger(constantValue.getInt());
				break;

			case Types.BIGINT:
				nodeType = C_NodeTypes.LONGINT_CONSTANT_NODE;
				constantObject = ReuseFactory.getLong(constantValue.getLong());
				break;

			case Types.REAL:
				nodeType = C_NodeTypes.FLOAT_CONSTANT_NODE;
				constantObject = new Float(NumberDataType.normalizeREAL(constantValue.getDouble()));
				break;

			case Types.DOUBLE:
				// no need to normalize here because no constant could be out of range for a double
				nodeType = C_NodeTypes.DOUBLE_CONSTANT_NODE;
				constantObject = new Double(constantValue.getDouble());
				break;
		}

		if (nodeType == -1)
			return this;


		return (ValueNode) getNodeFactory().getNode(
										nodeType,
										constantObject, 
										getContextManager());

	}"
https://github.com/apache/derby/tree/eea0d50c8d732cad9ba563ddfa786b7028eb092f//java/engine/org/apache/derby/impl/sql/compile/ColumnOrdering.java,toString,open,"public String toString() {
		String retval = """";

		if (SanityManager.DEBUG) {
			retval += ""Direction: "" + myDirection;

			for (int i = 0; i < columns.size(); i++) {
				retval += "" Table "" + tables.get(i) +
							"", Column "" + columns.get(i);
			}
		}

		return retval;
	}"
https://github.com/apache/derby/tree/eea0d50c8d732cad9ba563ddfa786b7028eb092f//java/engine/org/apache/derby/impl/sql/compile/ColumnReference.java,remapColumnReferencesToExpressions,open,"public ValueNode remapColumnReferencesToExpressions()
		throws StandardException
	{
		ResultColumn	rc;
		ResultColumn	sourceRC = source;

		/* Nothing to do if we are not pointing to a redundant RC */
		if (! source.isRedundant())
		{
			return this;
		}

		/* Find the last redundant RC in the chain.  We
		 * want to clone its expression.
		 */
		for (rc = source; rc != null && rc.isRedundant(); )
		{
			/* Find the matching ResultColumn */
            ResultColumn nextRC = rc.getExpression().getSourceResultColumn();

			if (nextRC != null && nextRC.isRedundant())
			{
				sourceRC = nextRC;
			}
			rc = nextRC;
		}

		if (SanityManager.DEBUG)
		{
			if (sourceRC == null)
			{
				SanityManager.THROWASSERT(
					""sourceRC is expected to be non-null for "" +
					columnName);
			}

			if ( ! sourceRC.isRedundant())
			{
				SanityManager.THROWASSERT(
					""sourceRC is expected to be redundant for "" +
					columnName);
			}
		}

		/* If last expression is a VCN, then we can't clone it.
		 * Instead, we just reset our source to point to the
		 * source of the VCN, those chopping out the layers.
		 * Otherwise, we return a clone of the underlying expression.
		 */
		if (sourceRC.getExpression() instanceof VirtualColumnNode)
		{
			VirtualColumnNode vcn =
				(VirtualColumnNode) (sourceRC.getExpression());
			ResultSetNode rsn = vcn.getSourceResultSet();
			if (rsn instanceof FromTable)
			{
				FromTable ft = (FromTable)rsn;

				/* It's not enough to just set the table number.  Depending
				 * on the original query specified and on whether or not
				 * subquery flattening has occurred, it's possible that
				 * the expression to which we're remapping has a different
				 * RCL ordering than the one to which we were mapped before
				 * we got here.  In that case we also need to update the
				 * columnNumber to point to the correct column in ""ft"".
				 * See DERBY-2526 for details.
                 * See DERBY-3023 and DERBY-4679 for further improvement
                 * details.
				 */

                ResultColumnList rcl = ft.getResultColumns();

                ResultColumn ftRC = null;


                // Need to save original (tn,cn) in case we have several
                // flattenings so we can relocate the correct column many
                // times. After the first flattening, the (tn,cn) pair points
                // to the top RCL which is going away..
                if (tableNumberBeforeFlattening == -1) {
                    tableNumberBeforeFlattening = tableNumber;
                    columnNumberBeforeFlattening = columnNumber;
                }

                // Covers references to a table not being flattened out, e.g.
                // inside a join tree, which can have many columns in the rcl
                // with the same name, so looking up via column name can give
                // the wrong column. DERBY-4679.
                ftRC = rcl.getResultColumn(
                    tableNumberBeforeFlattening,
                    columnNumberBeforeFlattening,
                    columnName);

                if (ftRC == null) {
                    // The above lookup won't work for references to a base
                    // column, so fall back on column name, which is unique
                    // then.
                    ftRC = rcl.getResultColumn(columnName);
                }

                if (SanityManager.DEBUG) {
                    SanityManager.ASSERT(
                        ftRC != null,
                        ""Failed to find column '"" + columnName +
                        ""' in the "" + ""RCL for '"" + ft.getTableName() +
                        ""'."");
                }

                tableNumber = ft.getTableNumber();

				if (SanityManager.DEBUG) {
					SanityManager.ASSERT(tableNumber != -1,
						""tableNumber not expected to be -1"");
				}

				/* Use the virtual column id if the ResultColumn's expression
				 * is a virtual column (DERBY-3023).
				 */
				columnNumber =
					(ftRC.getExpression() instanceof VirtualColumnNode)
						? ftRC.getVirtualColumnId()
						: ftRC.getColumnPosition();
			}
			else
			{
				if (SanityManager.DEBUG)
				{
					SanityManager.THROWASSERT(""rsn expected to be a FromTable, but is a "" + rsn.getClass().getName());
				}
			}
			source = sourceRC.getExpression().getSourceResultColumn();
			return this;
		}
		else
		{
			return sourceRC.getExpression().getClone();
		}
	}"
https://github.com/apache/derby/tree/eea0d50c8d732cad9ba563ddfa786b7028eb092f//java/engine/org/apache/derby/impl/sql/compile/CompilerContextImpl.java,getParameterTypes,open,"public DataTypeDescriptor[] getParameterTypes()
	{
		return parameterDescriptors;
	}"
https://github.com/apache/derby/tree/eea0d50c8d732cad9ba563ddfa786b7028eb092f//java/engine/org/apache/derby/impl/sql/compile/CompilerContextImpl.java,getSavedObjects,open,"public Object[] getSavedObjects() {
		if (savedObjects == null) return null;

		Object[] retVal = new Object[savedObjects.size()];
		savedObjects.copyInto(retVal);
		savedObjects = null; // erase to start over
		return retVal;
	}"
https://github.com/apache/derby/tree/eea0d50c8d732cad9ba563ddfa786b7028eb092f//java/engine/org/apache/derby/impl/sql/compile/CompilerContextImpl.java,getUniqueClassName,open,"public String getUniqueClassName()
	{
		// REMIND: should get a new UUID if we roll over...
		if (SanityManager.DEBUG)
		{
    		SanityManager.ASSERT(nextClassName <= Long.MAX_VALUE);
    	}
		return classPrefix.concat(Long.toHexString(nextClassName++));
	}"
https://github.com/apache/derby/tree/eea0d50c8d732cad9ba563ddfa786b7028eb092f//java/engine/org/apache/derby/impl/sql/compile/CompilerContextImpl.java,getRequiredPermissionsList,open,"public List getRequiredPermissionsList()
	{
		int size = 0;
		if( requiredRoutinePrivileges != null)
        { size += requiredRoutinePrivileges.size(); }
		if( requiredUsagePrivileges != null)
        { size += requiredUsagePrivileges.size(); }
		if( requiredTablePrivileges != null)
        { size += requiredTablePrivileges.size(); }
		if( requiredSchemaPrivileges != null)
        { size += requiredSchemaPrivileges.size(); }
		if( requiredColumnPrivileges != null)
        { size += requiredColumnPrivileges.size(); }
		if( requiredRolePrivileges != null)
        { size += requiredRolePrivileges.size(); }
		
		ArrayList list = new ArrayList( size);
		if( requiredRoutinePrivileges != null)
		{
			for( Iterator itr = requiredRoutinePrivileges.keySet().iterator(); itr.hasNext();)
			{
				UUID routineUUID = (UUID) itr.next();
				
				list.add( new StatementRoutinePermission( routineUUID));
			}
		}
		if( requiredUsagePrivileges != null)
		{
			for( Iterator itr = requiredUsagePrivileges.keySet().iterator(); itr.hasNext();)
			{
				UUID objectID = (UUID) itr.next();
				
				list.add( new StatementGenericPermission( objectID, (String) requiredUsagePrivileges.get( objectID ), PermDescriptor.USAGE_PRIV ) );
			}
		}
		if( requiredTablePrivileges != null)
		{
			for( Iterator itr = requiredTablePrivileges.values().iterator(); itr.hasNext();)
			{
				list.add( itr.next());
			}
		}
		if( requiredSchemaPrivileges != null)
		{
			for( Iterator itr = requiredSchemaPrivileges.values().iterator(); itr.hasNext();)
			{
				list.add( itr.next());
			}
		}
		if( requiredColumnPrivileges != null)
		{
			for( Iterator itr = requiredColumnPrivileges.values().iterator(); itr.hasNext();)
			{
				list.add( itr.next());
			}
		}
		if( requiredRolePrivileges != null)
		{
			for( Iterator itr = requiredRolePrivileges.values().iterator();
				 itr.hasNext();)
			{
				list.add( itr.next());
			}
		}
		return list;
	}"
https://github.com/apache/derby/tree/eea0d50c8d732cad9ba563ddfa786b7028eb092f//java/engine/org/apache/derby/impl/sql/compile/CreateIndexNode.java,bindStatement,close,"public void bindStatement() throws StandardException
	{
		CompilerContext			cc = getCompilerContext();
		SchemaDescriptor		sd;
		int						columnCount;

		sd = getSchemaDescriptor();

		td = getTableDescriptor(tableName);

		//throw an exception if user is attempting to create an index on a temporary table
		if (td.getTableType() == TableDescriptor.GLOBAL_TEMPORARY_TABLE_TYPE)
		{
				throw StandardException.newException(SQLState.LANG_NOT_ALLOWED_FOR_DECLARED_GLOBAL_TEMP_TABLE);
		}

		//If total number of indexes on the table so far is more than 32767, then we need to throw an exception
		if (td.getTotalNumberOfIndexes() > Limits.DB2_MAX_INDEXES_ON_TABLE)
		{
			throw StandardException.newException(SQLState.LANG_TOO_MANY_INDEXES_ON_TABLE,
				String.valueOf(td.getTotalNumberOfIndexes()),
				tableName,
				String.valueOf(Limits.DB2_MAX_INDEXES_ON_TABLE));
		}

		/* Validate the column name list */
		verifyAndGetUniqueNames();

		columnCount = columnNames.length;
		boundColumnIDs = new int[ columnCount ];

		// Verify that the columns exist
		for (int i = 0; i < columnCount; i++)
		{
			ColumnDescriptor			columnDescriptor;

			columnDescriptor = td.getColumnDescriptor(columnNames[i]);
			if (columnDescriptor == null)
			{
				throw StandardException.newException(SQLState.LANG_COLUMN_NOT_FOUND_IN_TABLE,
															columnNames[i],
															tableName);
			}
			boundColumnIDs[ i ] = columnDescriptor.getPosition();

			// Don't allow a column to be created on a non-orderable type
			if ( ! columnDescriptor.getType().getTypeId().
												orderable(getClassFactory()))
			{
				throw StandardException.newException(SQLState.LANG_COLUMN_NOT_ORDERABLE_DURING_EXECUTION,
					columnDescriptor.getType().getTypeId().getSQLTypeName());
			}
		}

		/* Check for number of key columns to be less than 16 to match DB2 */
		if (columnCount > 16)
			throw StandardException.newException(SQLState.LANG_TOO_MANY_INDEX_KEY_COLS);

		/* See if the index already exists in this schema.
		 * NOTE: We still need to check at execution time
		 * since the index name is only unique to the schema,
		 * not the table.
		 */
//  		if (dd.getConglomerateDescriptor(indexName.getTableName(), sd, false) != null)
//  		{
//  			throw StandardException.newException(SQLState.LANG_OBJECT_ALREADY_EXISTS_IN_OBJECT,
//  												 ""Index"",
//  												 indexName.getTableName(),
//  												 ""schema"",
//  												 sd.getSchemaName());
//  		}

		/* Statement is dependent on the TableDescriptor */
		getCompilerContext().createDependency(td);

	}"
https://github.com/apache/derby/tree/eea0d50c8d732cad9ba563ddfa786b7028eb092f//java/engine/org/apache/derby/impl/sql/compile/CreateSequenceNode.java,bindStatement,close,"public void bindStatement() throws StandardException {
        CompilerContext cc = getCompilerContext();

        // implicitly create the schema if it does not exist.
        // this method also compiles permissions checks
        SchemaDescriptor sd = getSchemaDescriptor();

        // set the default schema name if the user did not explicitly specify a schema
        if (_sequenceName.getSchemaName() == null) {
            _sequenceName.setSchemaName(sd.getSchemaName());
        }

        if (_dataType.getTypeId().equals(TypeId.SMALLINT_ID)) {
            if (_minValue.longValue() < Short.MIN_VALUE || _minValue.longValue() >= Short.MAX_VALUE) {
                throw StandardException.newException(
                        SQLState.LANG_SEQ_ARG_OUT_OF_DATATYPE_RANGE,
                        ""MINVALUE"",
                        ""SMALLINT"",
                        Short.MIN_VALUE + """",
                        Short.MAX_VALUE + """");
            }
            if (_maxValue.longValue() <= Short.MIN_VALUE || _maxValue.longValue() > Short.MAX_VALUE) {
                throw StandardException.newException(
                        SQLState.LANG_SEQ_ARG_OUT_OF_DATATYPE_RANGE,
                        ""MAXVALUE"",
                        ""SMALLINT"",
                        Short.MIN_VALUE + """",
                        Short.MAX_VALUE + """");
            }
        } else if (_dataType.getTypeId().equals(TypeId.INTEGER_ID)) {
            if (_minValue.longValue() < Integer.MIN_VALUE || _minValue.longValue() >= Integer.MAX_VALUE) {
                throw StandardException.newException(
                        SQLState.LANG_SEQ_ARG_OUT_OF_DATATYPE_RANGE,
                        ""MINVALUE"",
                        ""INTEGER"",
                        Integer.MIN_VALUE + """",
                        Integer.MAX_VALUE + """");
            }
            if (_maxValue.longValue() <= Integer.MIN_VALUE || _maxValue.longValue() > Integer.MAX_VALUE) {
                throw StandardException.newException(
                        SQLState.LANG_SEQ_ARG_OUT_OF_DATATYPE_RANGE,
                        ""MAXVALUE"",
                        ""INTEGER"",
                        Integer.MIN_VALUE + """",
                        Integer.MAX_VALUE + """");
            }
        } else {
            // BIGINT
            if (_minValue.longValue() < Long.MIN_VALUE || _minValue.longValue() >= Long.MAX_VALUE) {
                throw StandardException.newException(
                        SQLState.LANG_SEQ_ARG_OUT_OF_DATATYPE_RANGE,
                        ""MINVALUE"",
                        ""BIGINT"",
                        Long.MIN_VALUE + """",
                        Long.MAX_VALUE + """");
            }
            if (_maxValue.longValue() <= Long.MIN_VALUE || _maxValue.longValue() > Long.MAX_VALUE) {
                throw StandardException.newException(
                        SQLState.LANG_SEQ_ARG_OUT_OF_DATATYPE_RANGE,
                        ""MAXVALUE"",
                        ""BIGINT"",
                        Long.MIN_VALUE + """",
                        Long.MAX_VALUE + """");
            }
        }

        if (_minValue.longValue() >= _maxValue.longValue()) {
            throw StandardException.newException(
                    SQLState.LANG_SEQ_MIN_EXCEEDS_MAX,
                    _minValue.toString(),
                    _maxValue.toString());
        }

        if (_initialValue.longValue() < _minValue.longValue() || _initialValue.longValue() > _maxValue.longValue()) {
             throw StandardException.newException(
                     SQLState.LANG_SEQ_INVALID_START,
                     _initialValue.toString(),
                     _minValue.toString(),
                     _maxValue.toString());
        }       

        if (_stepValue.longValue() == 0L) {
            throw StandardException.newException(
                    SQLState.LANG_SEQ_INCREMENT_ZERO);
        }

    }"
https://github.com/apache/derby/tree/eea0d50c8d732cad9ba563ddfa786b7028eb092f//java/engine/org/apache/derby/impl/sql/compile/CreateSequenceNode.java,bindStatement,open,"public void bindStatement() throws StandardException {
        CompilerContext cc = getCompilerContext();

        // implicitly create the schema if it does not exist.
        // this method also compiles permissions checks
        SchemaDescriptor sd = getSchemaDescriptor();

        // set the default schema name if the user did not explicitly specify a schema
        if (_sequenceName.getSchemaName() == null) {
            _sequenceName.setSchemaName(sd.getSchemaName());
        }

        if (_dataType.getTypeId().equals(TypeId.SMALLINT_ID)) {
            if (_minValue.longValue() < Short.MIN_VALUE || _minValue.longValue() >= Short.MAX_VALUE) {
                throw StandardException.newException(
                        SQLState.LANG_SEQ_ARG_OUT_OF_DATATYPE_RANGE,
                        ""MINVALUE"",
                        ""SMALLINT"",
                        Short.MIN_VALUE + """",
                        Short.MAX_VALUE + """");
            }
            if (_maxValue.longValue() <= Short.MIN_VALUE || _maxValue.longValue() > Short.MAX_VALUE) {
                throw StandardException.newException(
                        SQLState.LANG_SEQ_ARG_OUT_OF_DATATYPE_RANGE,
                        ""MAXVALUE"",
                        ""SMALLINT"",
                        Short.MIN_VALUE + """",
                        Short.MAX_VALUE + """");
            }
        } else if (_dataType.getTypeId().equals(TypeId.INTEGER_ID)) {
            if (_minValue.longValue() < Integer.MIN_VALUE || _minValue.longValue() >= Integer.MAX_VALUE) {
                throw StandardException.newException(
                        SQLState.LANG_SEQ_ARG_OUT_OF_DATATYPE_RANGE,
                        ""MINVALUE"",
                        ""INTEGER"",
                        Integer.MIN_VALUE + """",
                        Integer.MAX_VALUE + """");
            }
            if (_maxValue.longValue() <= Integer.MIN_VALUE || _maxValue.longValue() > Integer.MAX_VALUE) {
                throw StandardException.newException(
                        SQLState.LANG_SEQ_ARG_OUT_OF_DATATYPE_RANGE,
                        ""MAXVALUE"",
                        ""INTEGER"",
                        Integer.MIN_VALUE + """",
                        Integer.MAX_VALUE + """");
            }
        } else {
            // BIGINT
            if (_minValue.longValue() < Long.MIN_VALUE || _minValue.longValue() >= Long.MAX_VALUE) {
                throw StandardException.newException(
                        SQLState.LANG_SEQ_ARG_OUT_OF_DATATYPE_RANGE,
                        ""MINVALUE"",
                        ""BIGINT"",
                        Long.MIN_VALUE + """",
                        Long.MAX_VALUE + """");
            }
            if (_maxValue.longValue() <= Long.MIN_VALUE || _maxValue.longValue() > Long.MAX_VALUE) {
                throw StandardException.newException(
                        SQLState.LANG_SEQ_ARG_OUT_OF_DATATYPE_RANGE,
                        ""MAXVALUE"",
                        ""BIGINT"",
                        Long.MIN_VALUE + """",
                        Long.MAX_VALUE + """");
            }
        }

        if (_minValue.longValue() >= _maxValue.longValue()) {
            throw StandardException.newException(
                    SQLState.LANG_SEQ_MIN_EXCEEDS_MAX,
                    _minValue.toString(),
                    _maxValue.toString());
        }

        if (_initialValue.longValue() < _minValue.longValue() || _initialValue.longValue() > _maxValue.longValue()) {
             throw StandardException.newException(
                     SQLState.LANG_SEQ_INVALID_START,
                     _initialValue.toString(),
                     _minValue.toString(),
                     _maxValue.toString());
        }       

        if (_stepValue.longValue() == 0L) {
            throw StandardException.newException(
                    SQLState.LANG_SEQ_INCREMENT_ZERO);
        }

    }"
https://github.com/apache/derby/tree/eea0d50c8d732cad9ba563ddfa786b7028eb092f//java/engine/org/apache/derby/impl/sql/compile/CreateSequenceNode.java,bindStatement,open,"public void bindStatement() throws StandardException {
        CompilerContext cc = getCompilerContext();

        // implicitly create the schema if it does not exist.
        // this method also compiles permissions checks
        SchemaDescriptor sd = getSchemaDescriptor();

        // set the default schema name if the user did not explicitly specify a schema
        if (_sequenceName.getSchemaName() == null) {
            _sequenceName.setSchemaName(sd.getSchemaName());
        }

        if (_dataType.getTypeId().equals(TypeId.SMALLINT_ID)) {
            if (_minValue.longValue() < Short.MIN_VALUE || _minValue.longValue() >= Short.MAX_VALUE) {
                throw StandardException.newException(
                        SQLState.LANG_SEQ_ARG_OUT_OF_DATATYPE_RANGE,
                        ""MINVALUE"",
                        ""SMALLINT"",
                        Short.MIN_VALUE + """",
                        Short.MAX_VALUE + """");
            }
            if (_maxValue.longValue() <= Short.MIN_VALUE || _maxValue.longValue() > Short.MAX_VALUE) {
                throw StandardException.newException(
                        SQLState.LANG_SEQ_ARG_OUT_OF_DATATYPE_RANGE,
                        ""MAXVALUE"",
                        ""SMALLINT"",
                        Short.MIN_VALUE + """",
                        Short.MAX_VALUE + """");
            }
        } else if (_dataType.getTypeId().equals(TypeId.INTEGER_ID)) {
            if (_minValue.longValue() < Integer.MIN_VALUE || _minValue.longValue() >= Integer.MAX_VALUE) {
                throw StandardException.newException(
                        SQLState.LANG_SEQ_ARG_OUT_OF_DATATYPE_RANGE,
                        ""MINVALUE"",
                        ""INTEGER"",
                        Integer.MIN_VALUE + """",
                        Integer.MAX_VALUE + """");
            }
            if (_maxValue.longValue() <= Integer.MIN_VALUE || _maxValue.longValue() > Integer.MAX_VALUE) {
                throw StandardException.newException(
                        SQLState.LANG_SEQ_ARG_OUT_OF_DATATYPE_RANGE,
                        ""MAXVALUE"",
                        ""INTEGER"",
                        Integer.MIN_VALUE + """",
                        Integer.MAX_VALUE + """");
            }
        } else {
            // BIGINT
            if (_minValue.longValue() < Long.MIN_VALUE || _minValue.longValue() >= Long.MAX_VALUE) {
                throw StandardException.newException(
                        SQLState.LANG_SEQ_ARG_OUT_OF_DATATYPE_RANGE,
                        ""MINVALUE"",
                        ""BIGINT"",
                        Long.MIN_VALUE + """",
                        Long.MAX_VALUE + """");
            }
            if (_maxValue.longValue() <= Long.MIN_VALUE || _maxValue.longValue() > Long.MAX_VALUE) {
                throw StandardException.newException(
                        SQLState.LANG_SEQ_ARG_OUT_OF_DATATYPE_RANGE,
                        ""MAXVALUE"",
                        ""BIGINT"",
                        Long.MIN_VALUE + """",
                        Long.MAX_VALUE + """");
            }
        }

        if (_minValue.longValue() >= _maxValue.longValue()) {
            throw StandardException.newException(
                    SQLState.LANG_SEQ_MIN_EXCEEDS_MAX,
                    _minValue.toString(),
                    _maxValue.toString());
        }

        if (_initialValue.longValue() < _minValue.longValue() || _initialValue.longValue() > _maxValue.longValue()) {
             throw StandardException.newException(
                     SQLState.LANG_SEQ_INVALID_START,
                     _initialValue.toString(),
                     _minValue.toString(),
                     _maxValue.toString());
        }       

        if (_stepValue.longValue() == 0L) {
            throw StandardException.newException(
                    SQLState.LANG_SEQ_INCREMENT_ZERO);
        }

    }"
https://github.com/apache/derby/tree/eea0d50c8d732cad9ba563ddfa786b7028eb092f//java/engine/org/apache/derby/impl/sql/compile/CreateTableNode.java,bindStatement,open,"public void bindStatement() throws StandardException
	{
		DataDictionary	dataDictionary = getDataDictionary();
		int numPrimaryKeys = 0;
		int numCheckConstraints = 0;
		int numReferenceConstraints = 0;
		int numUniqueConstraints = 0;
        int numGenerationClauses = 0;

        SchemaDescriptor sd = getSchemaDescriptor
            ( tableType != TableDescriptor.GLOBAL_TEMPORARY_TABLE_TYPE, true);

		if (queryExpression != null)
		{
			FromList fromList = (FromList) getNodeFactory().getNode(
					C_NodeTypes.FROM_LIST,
					getNodeFactory().doJoinOrderOptimization(),
					getContextManager());
			
			CompilerContext cc = getCompilerContext();
			ProviderList prevAPL = cc.getCurrentAuxiliaryProviderList();
			ProviderList apl = new ProviderList();
			
			try
			{
				cc.setCurrentAuxiliaryProviderList(apl);
				cc.pushCurrentPrivType(Authorizer.SELECT_PRIV);
				
				/* Bind the tables in the queryExpression */
				queryExpression =
					queryExpression.bindNonVTITables(dataDictionary, fromList);
				queryExpression = queryExpression.bindVTITables(fromList);
				
				/* Bind the expressions under the resultSet */
				queryExpression.bindExpressions(fromList);
				
				/* Bind the query expression */
				queryExpression.bindResultColumns(fromList);
				
				/* Reject any untyped nulls in the RCL */
				/* e.g. CREATE TABLE t1 (x) AS VALUES NULL WITH NO DATA */
				queryExpression.bindUntypedNullsToResultColumns(null);
			}
			finally
			{
				cc.popCurrentPrivType();
				cc.setCurrentAuxiliaryProviderList(prevAPL);
			}
			
			/* If there is an RCL for the table definition then copy the
			 * names to the queryExpression's RCL after verifying that
			 * they both have the same size.
			 */
			ResultColumnList qeRCL = queryExpression.getResultColumns();
			
			if (resultColumns != null)
			{
				if (resultColumns.size() != qeRCL.visibleSize())
				{
					throw StandardException.newException(
							SQLState.LANG_TABLE_DEFINITION_R_C_L_MISMATCH,
							getFullName());
				}
				qeRCL.copyResultColumnNames(resultColumns);
			}
			
			int schemaCollationType = sd.getCollationType();
	    
			/* Create table element list from columns in query expression */
			tableElementList = new TableElementList();
			
			for (int index = 0; index < qeRCL.size(); index++)
			{
				ResultColumn rc = (ResultColumn) qeRCL.elementAt(index);
				if (rc.isGenerated()) 
				{
					continue;
				}
				/* Raise error if column name is system generated. */
				if (rc.isNameGenerated())
				{
					throw StandardException.newException(
							SQLState.LANG_TABLE_REQUIRES_COLUMN_NAMES);
				}

				DataTypeDescriptor dtd = rc.getExpression().getTypeServices();
				if ((dtd != null) && !dtd.isUserCreatableType())
				{
					throw StandardException.newException(
							SQLState.LANG_INVALID_COLUMN_TYPE_CREATE_TABLE,
							dtd.getFullSQLTypeName(),
							rc.getName());
				}
				//DERBY-2879  CREATE TABLE AS <subquery> does not maintain the 
				//collation for character types. 
				//eg for a territory based collation database
				//create table t as select tablename from sys.systables with no data;
				//Derby at this point does not support for a table's character 
				//columns to have a collation different from it's schema's
				//collation. Which means that in a territory based database, 
				//the query above will cause table t's character columns to
				//have collation of UCS_BASIC but the containing schema of t
				//has collation of territory based. This is not supported and
				//hence we will throw an exception below for the query above in
				//a territory based database. 
				if (dtd.getTypeId().isStringTypeId() && 
						dtd.getCollationType() != schemaCollationType)
				{
					throw StandardException.newException(
							SQLState.LANG_CAN_NOT_CREATE_TABLE,
							dtd.getCollationName(),
							DataTypeDescriptor.getCollationName(schemaCollationType));
				}

				ColumnDefinitionNode column = (ColumnDefinitionNode) getNodeFactory().getNode
                    ( C_NodeTypes.COLUMN_DEFINITION_NODE, rc.getName(), null, rc.getType(), null, getContextManager() );
				tableElementList.addTableElement(column);
			}
		} else {
			//Set the collation type and collation derivation of all the 
			//character type columns. Their collation type will be same as the 
			//collation of the schema they belong to. Their collation 
			//derivation will be ""implicit"". 
			//Earlier we did this in makeConstantAction but that is little too 
			//late (DERBY-2955)
			//eg 
			//CREATE TABLE STAFF9 (EMPNAME CHAR(20),
			//  CONSTRAINT STAFF9_EMPNAME CHECK (EMPNAME NOT LIKE 'T%'))
			//For the query above, when run in a territory based db, we need 
			//to have the correct collation set in bind phase of create table 
			//so that when LIKE is handled in LikeEscapeOperatorNode, we have 
			//the correct collation set for EMPNAME otherwise it will throw an 
			//exception for 'T%' having collation of territory based and 
			//EMPNAME having the default collation of UCS_BASIC
			tableElementList.setCollationTypesOnCharacterStringColumns(
				getSchemaDescriptor(
					tableType != TableDescriptor.GLOBAL_TEMPORARY_TABLE_TYPE,
					true));
		}

		tableElementList.validate(this, dataDictionary, (TableDescriptor) null);

		/* Only 1012 columns allowed per table */
		if (tableElementList.countNumberOfColumns() > Limits.DB2_MAX_COLUMNS_IN_TABLE)
		{
			throw StandardException.newException(SQLState.LANG_TOO_MANY_COLUMNS_IN_TABLE_OR_VIEW,
				String.valueOf(tableElementList.countNumberOfColumns()),
				getRelativeName(),
				String.valueOf(Limits.DB2_MAX_COLUMNS_IN_TABLE));
		}

		numPrimaryKeys = tableElementList.countConstraints(
								DataDictionary.PRIMARYKEY_CONSTRAINT);

		/* Only 1 primary key allowed per table */
		if (numPrimaryKeys > 1)
		{
			throw StandardException.newException(SQLState.LANG_TOO_MANY_PRIMARY_KEY_CONSTRAINTS, getRelativeName());
		}

		/* Check the validity of all check constraints */
		numCheckConstraints = tableElementList.countConstraints(
									DataDictionary.CHECK_CONSTRAINT);

		numReferenceConstraints = tableElementList.countConstraints(
									DataDictionary.FOREIGNKEY_CONSTRAINT);

		numUniqueConstraints = tableElementList.countConstraints(
									DataDictionary.UNIQUE_CONSTRAINT);

        numGenerationClauses = tableElementList.countGenerationClauses();

		//temp tables can't have primary key or check or foreign key or unique constraints defined on them
		if ((tableType == TableDescriptor.GLOBAL_TEMPORARY_TABLE_TYPE) &&
			(numPrimaryKeys > 0 || numCheckConstraints > 0 || numReferenceConstraints > 0 || numUniqueConstraints > 0))
				throw StandardException.newException(SQLState.LANG_NOT_ALLOWED_FOR_DECLARED_GLOBAL_TEMP_TABLE);

		//each of these constraints have a backing index in the back. We need to make sure that a table never has more
		//more than 32767 indexes on it and that is why this check.
		if ((numPrimaryKeys + numReferenceConstraints + numUniqueConstraints) > Limits.DB2_MAX_INDEXES_ON_TABLE)
		{
			throw StandardException.newException(SQLState.LANG_TOO_MANY_INDEXES_ON_TABLE, 
				String.valueOf(numPrimaryKeys + numReferenceConstraints + numUniqueConstraints),
				getRelativeName(),
				String.valueOf(Limits.DB2_MAX_INDEXES_ON_TABLE));
		}

		if ( (numCheckConstraints > 0) || (numGenerationClauses > 0) || (numReferenceConstraints > 0) )
		{
			/* In order to check the validity of the check constraints and
			 * generation clauses
			 * we must goober up a FromList containing a single table,
			 * the table being created, with an RCL containing the
			 * new columns and their types.  This will allow us to
			 * bind the constraint definition trees against that
			 * FromList.  When doing this, we verify that there are
			 * no nodes which can return non-deterministic results.
			 */
			FromList fromList = makeFromList( null, tableElementList, true );
            FormatableBitSet    generatedColumns = new FormatableBitSet();

			/* Now that we've finally goobered stuff up, bind and validate
			 * the check constraints and generation clauses.
			 */
			if  (numGenerationClauses > 0) { tableElementList.bindAndValidateGenerationClauses( sd, fromList, generatedColumns, null ); }
			if  (numCheckConstraints > 0) { tableElementList.bindAndValidateCheckConstraints(fromList); }
            if ( numReferenceConstraints > 0) { tableElementList.validateForeignKeysOnGenerationClauses( fromList, generatedColumns ); }
		}

        if ( numPrimaryKeys > 0 ) { tableElementList.validatePrimaryKeyNullability(); }
	}"
https://github.com/apache/derby/tree/eea0d50c8d732cad9ba563ddfa786b7028eb092f//java/engine/org/apache/derby/impl/sql/compile/CreateTriggerNode.java,justTheRequiredColumns,open,"private int[] justTheRequiredColumns(int[] columnsArrary) {
		int countOfColsRefedInArray = 0;
		int numberOfColsInTriggerTable = triggerTableDescriptor.getNumberOfColumns();

		//Count number of non -1 entries
		for (int i=0; i < numberOfColsInTriggerTable; i++) {
			if (columnsArrary[i] != -1)
				countOfColsRefedInArray++;
		}

		if (countOfColsRefedInArray > 0){
			int[] tempArrayOfNeededColumns = new int[countOfColsRefedInArray];
			int j=0;
			for (int i=0; i < numberOfColsInTriggerTable; i++) {
				if (columnsArrary[i] != -1)
					tempArrayOfNeededColumns[j++] = columnsArrary[i];
			}
			return tempArrayOfNeededColumns;
		} else
			return null;
	}"
https://github.com/apache/derby/tree/eea0d50c8d732cad9ba563ddfa786b7028eb092f//java/engine/org/apache/derby/impl/sql/compile/DMLModStatementNode.java,bindRowScopedExpression,close,"static void	bindRowScopedExpression
	(
		NodeFactory			nodeFactory,
        ContextManager    contextManager,
		TableDescriptor		targetTableDescriptor,
		ResultColumnList	sourceRCL,
		ValueNode			expression
    )
		throws StandardException
	{

		TableName	targetTableName = makeTableName
            (nodeFactory, contextManager, targetTableDescriptor.getSchemaName(), targetTableDescriptor.getName());

		/* We now have the expression as a query tree.  Now, we prepare
		 * to bind that query tree to the source's RCL.  That way, the
		 * generated code for the expression will be evaluated against the
		 * source row to be inserted into the target table or
		 * against the after portion of the source row for the update
		 * into the target table.
		 *		o  Goober up a new FromList which has a single table,
		 *		   a goobered up FromBaseTable for the target table
		 *		   which has the source's RCL as it RCL.
		 *		   (This allows the ColumnReferences in the expression
		 *		   tree to be bound to the right RCs.)
		 *
	 	 * Note that in some circumstances we may not actually verify
		 * the expression against the source RCL but against a temp
		 * row source used for deferred processing because of a trigger.
		 * In this case, the caller of bindConstraints (UpdateNode)
		 * has chosen to pass in the correct RCL to bind against.
		 */
		FromList fakeFromList =
			(FromList) nodeFactory.getNode(
							C_NodeTypes.FROM_LIST,
							nodeFactory.doJoinOrderOptimization(),
							contextManager);
		FromBaseTable table = (FromBaseTable)
			nodeFactory.getNode(
				C_NodeTypes.FROM_BASE_TABLE,
				targetTableName,
				null,
				sourceRCL,
				null,
				contextManager);
		table.setTableNumber(0);
		fakeFromList.addFromTable(table);

		// Now we can do the bind.
		expression = expression.bindExpression(
										fakeFromList,
										(SubqueryList) null,
										(Vector) null);
	}"
https://github.com/apache/derby/tree/eea0d50c8d732cad9ba563ddfa786b7028eb092f//java/engine/org/apache/derby/impl/sql/compile/DMLModStatementNode.java,parseCheckConstraint,close,"public	ValueNode	parseCheckConstraint
	(
		String				checkConstraintText,
		TableDescriptor		td
    )
		throws StandardException
	{
		Parser						p;
		ValueNode					checkTree;
		LanguageConnectionContext	lcc = getLanguageConnectionContext();
		CompilerContext 			compilerContext = getCompilerContext();

		/* Get a Statement to pass to the parser */

		/* We're all set up to parse. We have to build a compile SQL statement
		 * before we can parse - we just have a WHERE clause right now.
		 * So, we goober up a SELECT * FROM table WHERE checkDefs.
		 */
		String select = ""SELECT * FROM "" +
			            td.getQualifiedName() +
			            "" WHERE "" +
			            checkConstraintText;
		
		/*
		** Get a new compiler context, so the parsing of the select statement
		** doesn't mess up anything in the current context (it could clobber
		** the ParameterValueSet, for example).
		*/
		CompilerContext newCC = lcc.pushCompilerContext();

		p = newCC.getParser();
				
		/* Finally, we can call the parser */
		// Since this is always nested inside another SQL statement, so topLevel flag
		// should be false
		Visitable qt = p.parseStatement(select);
		if (SanityManager.DEBUG)
		{
			if (! (qt instanceof CursorNode))
			{
				SanityManager.THROWASSERT(
					""qt expected to be instanceof CursorNode, not "" +
					qt.getClass().getName());
			}
			CursorNode cn = (CursorNode) qt;
			if (! (cn.getResultSetNode() instanceof SelectNode))
			{
				SanityManager.THROWASSERT(
					""cn.getResultSetNode() expected to be instanceof SelectNode, not "" +
					cn.getResultSetNode().getClass().getName());
			}
		}

		checkTree = ((SelectNode) ((CursorNode) qt).getResultSetNode()).getWhereClause();

		lcc.popCompilerContext(newCC);

		return	checkTree;
	}"
https://github.com/apache/derby/tree/eea0d50c8d732cad9ba563ddfa786b7028eb092f//java/engine/org/apache/derby/impl/sql/compile/DMLModStatementNode.java,parseGenerationClause,close,"public	ValueNode	parseGenerationClause
	(
     String				clauseText,
     TableDescriptor    td
    )
		throws StandardException
	{
		Parser						p;
		ValueNode					clauseTree;
		LanguageConnectionContext	lcc = getLanguageConnectionContext();
		CompilerContext 			compilerContext = getCompilerContext();

		/* Get a Statement to pass to the parser */

		/* We're all set up to parse. We have to build a compilable SQL statement
		 * before we can parse -  So, we goober up a VALUES defaultText.
		 */
		String select = ""SELECT "" + clauseText + "" FROM "" + td.getQualifiedName();
		
		/*
		** Get a new compiler context, so the parsing of the select statement
		** doesn't mess up anything in the current context (it could clobber
		** the ParameterValueSet, for example).
		*/
		CompilerContext newCC = lcc.pushCompilerContext();

		p = newCC.getParser();
				
		/* Finally, we can call the parser */
		// Since this is always nested inside another SQL statement, so topLevel flag
		// should be false
		Visitable qt = p.parseStatement(select);
		if (SanityManager.DEBUG)
		{
			if (! (qt instanceof CursorNode))
			{
				SanityManager.THROWASSERT(
					""qt expected to be instanceof CursorNode, not "" +
					qt.getClass().getName());
			}
			CursorNode cn = (CursorNode) qt;
			if (! (cn.getResultSetNode() instanceof SelectNode))
			{
				SanityManager.THROWASSERT(
					""cn.getResultSetNode() expected to be instanceof SelectNode, not "" +
					cn.getResultSetNode().getClass().getName());
			}
		}

		clauseTree = ((ResultColumn) 
							((CursorNode) qt).getResultSetNode().getResultColumns().elementAt(0)).
									getExpression();

		lcc.popCompilerContext(newCC);

		return	clauseTree;
	}"
https://github.com/apache/derby/tree/eea0d50c8d732cad9ba563ddfa786b7028eb092f//java/engine/org/apache/derby/impl/sql/compile/DMLModStatementNode.java,getReadColMap,open,"public static int[] getReadColMap(int column_map_length,FormatableBitSet readColsBitSet)
	{
		if (readColsBitSet == null) return null;

        int partial_col_cnt = 0;
        int column_map[] = new int[column_map_length];
		int readColsBitSetSize = readColsBitSet.size();

        for (int base_index = 0; base_index < column_map.length; base_index++)
        {
			if (readColsBitSetSize > base_index && readColsBitSet.get(base_index+1))
				column_map[base_index] = partial_col_cnt++;
			else
				// this column map offset entry should never be referenced.
				column_map[base_index] = -1;
		}

        return(column_map);
	}"
https://github.com/apache/derby/tree/eea0d50c8d732cad9ba563ddfa786b7028eb092f//java/engine/org/apache/derby/impl/sql/compile/DeleteNode.java,getEmptyDeleteNode,open,"private StatementNode getEmptyDeleteNode(String schemaName, String targetTableName)
        throws StandardException
    {

        ValueNode whereClause = null;

        TableName tableName = new TableName();
        tableName.init(schemaName , targetTableName);

        NodeFactory nodeFactory = getNodeFactory();
        FromList   fromList = (FromList) nodeFactory.getNode(C_NodeTypes.FROM_LIST, getContextManager());
        FromTable fromTable = (FromTable) nodeFactory.getNode(
                                                    C_NodeTypes.FROM_BASE_TABLE,
                                                    tableName,
                                                    null,
                                                    ReuseFactory.getInteger(FromBaseTable.DELETE),
                                                    null,
                                                    getContextManager());

		//we would like to use references index & table scan instead of 
		//what optimizer says for the dependent table scan.
		Properties targetProperties = new FormatableProperties();
		targetProperties.put(""index"", ""null"");
		((FromBaseTable) fromTable).setTableProperties(targetProperties);

        fromList.addFromTable(fromTable);
        SelectNode resultSet = (SelectNode) nodeFactory.getNode(
                                                     C_NodeTypes.SELECT_NODE,
                                                     null,
                                                     null,   /* AGGREGATE list */
                                                     fromList, /* FROM list */
                                                     whereClause, /* WHERE clause */
                                                     null, /* GROUP BY list */
                                                     null, /* having clause */
													 null, /* windows */
													 getContextManager());

        return (StatementNode) nodeFactory.getNode(
                                                    C_NodeTypes.DELETE_NODE,
                                                    tableName,
                                                    resultSet,
                                                    getContextManager());

    }"
https://github.com/apache/derby/tree/eea0d50c8d732cad9ba563ddfa786b7028eb092f//java/engine/org/apache/derby/impl/sql/compile/DeleteNode.java,getEmptyUpdateNode,open,"private StatementNode getEmptyUpdateNode(String schemaName, 
											 String targetTableName,
											 ColumnDescriptorList cdl)
        throws StandardException
    {

        ValueNode whereClause = null;

        TableName tableName = new TableName();
        tableName.init(schemaName , targetTableName);

        NodeFactory nodeFactory = getNodeFactory();
        FromList   fromList = (FromList) nodeFactory.getNode(C_NodeTypes.FROM_LIST, getContextManager());
        FromTable fromTable = (FromTable) nodeFactory.getNode(
                                                    C_NodeTypes.FROM_BASE_TABLE,
                                                    tableName,
                                                    null,
                                                    ReuseFactory.getInteger(FromBaseTable.DELETE),
                                                    null,
                                                    getContextManager());


		//we would like to use references index & table scan instead of 
		//what optimizer says for the dependent table scan.
		Properties targetProperties = new FormatableProperties();
		targetProperties.put(""index"", ""null"");
		((FromBaseTable) fromTable).setTableProperties(targetProperties);

        fromList.addFromTable(fromTable);

        SelectNode resultSet = (SelectNode) nodeFactory.getNode(
                                                     C_NodeTypes.SELECT_NODE,
                                                     getSetClause(tableName, cdl),
                                                     null,   /* AGGREGATE list */
                                                     fromList, /* FROM list */
                                                     whereClause, /* WHERE clause */
                                                     null, /* GROUP BY list */
													 null, /* having clause */
													 null, /* windows */
                                                     getContextManager());

        return (StatementNode) nodeFactory.getNode(
                                                    C_NodeTypes.UPDATE_NODE,
                                                    tableName,
                                                    resultSet,
                                                    getContextManager());

    }"
https://github.com/apache/derby/tree/eea0d50c8d732cad9ba563ddfa786b7028eb092f//java/engine/org/apache/derby/impl/sql/compile/DeleteNode.java,generate,open,"public void generate(ActivationClassBuilder acb,
								MethodBuilder mb)
							throws StandardException
	{

		// If the DML is on the temporary table, generate the code to
		// mark temporary table as modified in the current UOW. After
		// DERBY-827 this must be done in execute() since
		// createResultSet() will only be called once.
		generateCodeForTemporaryTable(acb);

		/* generate the parameters */
		if(!isDependentTable)
			generateParameterValueSet(acb);

		acb.pushGetResultSetFactoryExpression(mb); 
		acb.newRowLocationScanResultSetName();
		resultSet.generate(acb, mb); // arg 1

		String resultSetGetter;
		int argCount;
		String parentResultSetId;

		// Base table
		if (targetTableDescriptor != null)
		{
			/* Create the declaration for the scan ResultSet which generates the
			 * RowLocations to be deleted.
	 		 * Note that the field cannot be static because there
			 * can be multiple activations of the same activation class,
			 * and they can't share this field.  Only exprN fields can
			 * be shared (or, more generally, read-only fields).
			 * RESOLVE - Need to deal with the type of the field.
			 */

			acb.newFieldDeclaration(Modifier.PRIVATE, 
									ClassName.CursorResultSet, 
									acb.getRowLocationScanResultSetName());

			if(cascadeDelete || isDependentTable)
			{
				resultSetGetter = ""getDeleteCascadeResultSet"";
				argCount = 4;
			}		
			else
			{
				resultSetGetter = ""getDeleteResultSet"";
				argCount = 1;
			}
			
		} else {
			argCount = 1;
			resultSetGetter = ""getDeleteVTIResultSet"";
		}

		if(isDependentTable)
		{
			mb.push(acb.addItem(makeConstantAction()));
		
		}else
		{
			if(cascadeDelete)
			{
				mb.push(-1); //root table.
			}
		}		

		String		resultSetArrayType = ClassName.ResultSet + ""[]"";
		if(cascadeDelete)
		{
			parentResultSetId = targetTableDescriptor.getSchemaName() +
			                       ""."" + targetTableDescriptor.getName();
			// Generate the code to build the array
			LocalField arrayField =
				acb.newFieldDeclaration(Modifier.PRIVATE, resultSetArrayType);
			mb.pushNewArray(ClassName.ResultSet, dependentNodes.length);  // new ResultSet[size]
			mb.setField(arrayField);
			for(int index=0 ; index <  dependentNodes.length ; index++)
			{

				dependentNodes[index].setRefActionInfo(fkIndexConglomNumbers[index],
													   fkColArrays[index],
													   parentResultSetId,
													   true);
				mb.getField(arrayField); // first arg (resultset array reference)
				/*beetle:5360 : if too many statements are added  to a  method, 
				 *size of method can hit  65k limit, which will
				 *lead to the class format errors at load time.
				 *To avoid this problem, when number of statements added 
				 *to a method is > 2048, remaing statements are added to  a new function
				 *and called from the function which created the function.
				 *See Beetle 5135 or 4293 for further details on this type of problem.
				*/
				if(mb.statementNumHitLimit(10))
				{
					MethodBuilder dmb = acb.newGeneratedFun(ClassName.ResultSet, Modifier.PRIVATE);
					dependentNodes[index].generate(acb,dmb); //generates the resultset expression
					dmb.methodReturn();
					dmb.complete();
					/* Generate the call to the new method */
					mb.pushThis(); 
					//second arg will be generated by this call
					mb.callMethod(VMOpcode.INVOKEVIRTUAL, (String) null, dmb.getName(), ClassName.ResultSet, 0);
				}else
				{
					dependentNodes[index].generate(acb,mb); //generates the resultset expression
				}

				mb.setArrayElement(index);
			}	
			mb.getField(arrayField); // fourth argument - array reference
		}
		else
		{
			if(isDependentTable)
			{
				mb.pushNull(resultSetArrayType); //No dependent tables for this table
			}
		}


		if(cascadeDelete || isDependentTable)
		{
			parentResultSetId = targetTableDescriptor.getSchemaName() +
			                       ""."" + targetTableDescriptor.getName();
			mb.push(parentResultSetId);

		}
		mb.callMethod(VMOpcode.INVOKEINTERFACE, (String) null, resultSetGetter, ClassName.ResultSet, argCount);


		if(!isDependentTable && cascadeDelete)
		{
			int numResultSets = acb.getRowCount();
			if(numResultSets > 0)
			{
				//generate activation.raParentResultSets = new NoPutResultSet[size]
				MethodBuilder constructor = acb.getConstructor();
				constructor.pushThis();
				constructor.pushNewArray(ClassName.CursorResultSet, numResultSets);
				constructor.putField(ClassName.BaseActivation,
									 ""raParentResultSets"",
									 ClassName.CursorResultSet + ""[]"");
				constructor.endStatement();
			}
		}
	}"
https://github.com/apache/derby/tree/eea0d50c8d732cad9ba563ddfa786b7028eb092f//java/engine/org/apache/derby/impl/sql/compile/DeleteNode.java,optimizeStatement,open,"public void optimizeStatement() throws StandardException
	{
		if(cascadeDelete)
		{
			for(int index=0 ; index < dependentNodes.length ; index++)
			{
				dependentNodes[index].optimizeStatement();
			}
		}

		super.optimizeStatement();
	}"
https://github.com/apache/derby/tree/eea0d50c8d732cad9ba563ddfa786b7028eb092f//java/engine/org/apache/derby/impl/sql/compile/DistinctNode.java,optimizeIt,close,"public CostEstimate optimizeIt(Optimizer optimizer,
									OptimizablePredicateList predList,
									CostEstimate outerCost,
									RowOrdering rowOrdering)
			throws StandardException
	{
		CostEstimate childCost =
			((Optimizable) childResult).optimizeIt(optimizer,
									predList,
									outerCost,
									rowOrdering);

		return super.optimizeIt(optimizer, predList, outerCost, rowOrdering);
	}"
https://github.com/apache/derby/tree/eea0d50c8d732cad9ba563ddfa786b7028eb092f//java/engine/org/apache/derby/impl/sql/compile/DropAliasNode.java,aliasTypeName,open,"private static String aliasTypeName( char actualType)
	{
		String	typeName = null;

		switch ( actualType )
		{
			case AliasInfo.ALIAS_TYPE_AGGREGATE_AS_CHAR:
				typeName = ""DERBY AGGREGATE"";
				break;
			case AliasInfo.ALIAS_TYPE_PROCEDURE_AS_CHAR:
				typeName = ""PROCEDURE"";
				break;
			case AliasInfo.ALIAS_TYPE_FUNCTION_AS_CHAR:
				typeName = ""FUNCTION"";
				break;
			case AliasInfo.ALIAS_TYPE_SYNONYM_AS_CHAR:
				typeName = ""SYNONYM"";
				break;
			case AliasInfo.ALIAS_TYPE_UDT_AS_CHAR:
				typeName = ""TYPE"";
				break;
		}
		return typeName;
	}"
https://github.com/apache/derby/tree/eea0d50c8d732cad9ba563ddfa786b7028eb092f//java/engine/org/apache/derby/impl/sql/compile/FromBaseTable.java,isOneRowResultSet,close,"public boolean isOneRowResultSet()	throws StandardException
	{
		// EXISTS FBT will only return a single row
		if (existsBaseTable)
		{
			return true;
		}

		/* For hash join, we need to consider both the qualification
		 * and hash join predicates and we consider them against all
		 * conglomerates since we are looking for any uniqueness
		 * condition that holds on the columns in the hash table, 
		 * otherwise we just consider the predicates in the 
		 * restriction list and the conglomerate being scanned.

		 */
		AccessPath ap = getTrulyTheBestAccessPath();
		JoinStrategy trulyTheBestJoinStrategy = ap.getJoinStrategy();
		PredicateList pl;

		if (trulyTheBestJoinStrategy.isHashJoin())
		{
			pl = (PredicateList) getNodeFactory().getNode(
											C_NodeTypes.PREDICATE_LIST,
											getContextManager());
			if (storeRestrictionList != null)
			{
				pl.nondestructiveAppend(storeRestrictionList);
			}
			if (nonStoreRestrictionList != null)
			{
				pl.nondestructiveAppend(nonStoreRestrictionList);
			}
			return isOneRowResultSet(pl);
		}
		else
		{
			return isOneRowResultSet(getTrulyTheBestAccessPath().
										getConglomerateDescriptor(),
									 restrictionList);
		}
	}"
https://github.com/apache/derby/tree/eea0d50c8d732cad9ba563ddfa786b7028eb092f//java/engine/org/apache/derby/impl/sql/compile/FromBaseTable.java,setRefActionInfo,open,"public void setRefActionInfo(long fkIndexConglomId, 
								 int[]fkColArray, 
								 String parentResultSetId,
								 boolean dependentScan)
	{


		this.fkIndexConglomId = fkIndexConglomId;
		this.fkColArray = fkColArray;
		this.raParentResultSetId = parentResultSetId;
		this.raDependentScan = dependentScan;
	}"
https://github.com/apache/derby/tree/eea0d50c8d732cad9ba563ddfa786b7028eb092f//java/engine/org/apache/derby/impl/sql/compile/FromBaseTable.java,mapTableAsVTI,close,"private ResultSetNode mapTableAsVTI(
            TableDescriptor td,
            String correlationName,
            ResultColumnList resultColumns,
            Properties tableProperties,
            ContextManager cm)
        throws StandardException {


        // The fact that we pass a non-null table descriptor to the following
        // call is an indication that we are mapping to a no-argument VTI. Since
        // we have the table descriptor we do not need to pass in a TableName.
        // See NewInvocationNode for more.
        QueryTreeNode newNode = (QueryTreeNode) getNodeFactory().getNode(
                C_NodeTypes.NEW_INVOCATION_NODE,
                null, // TableName
                td, // TableDescriptor
                Collections.EMPTY_LIST,
                Boolean.FALSE,
                cm);

        QueryTreeNode vtiNode;

        if (correlationName != null) {
            vtiNode = (QueryTreeNode) getNodeFactory().getNode(
                    C_NodeTypes.FROM_VTI,
                    newNode,
                    correlationName,
                    resultColumns,
                    tableProperties,
                    cm);
        } else {
            TableName exposedName = newNode.makeTableName(td.getSchemaName(),
                    td.getDescriptorName());

            vtiNode = (QueryTreeNode) getNodeFactory().getNode(
                    C_NodeTypes.FROM_VTI,
                    newNode,
                    correlationName,
                    resultColumns,
                    tableProperties,
                    exposedName,
                    cm);
        }

        return (ResultSetNode) vtiNode;
    }"
https://github.com/apache/derby/tree/eea0d50c8d732cad9ba563ddfa786b7028eb092f//java/engine/org/apache/derby/impl/sql/compile/FromBaseTable.java,verifyProperties,open,"public void verifyProperties(DataDictionary dDictionary)
		throws StandardException
	{
		if (tableProperties == null)
		{
			return;
		}
		/* Check here for:
		 *		invalid properties key
		 *		index and constraint properties
		 *		non-existent index
		 *		non-existent constraint
		 *		invalid joinStrategy
		 *		invalid value for hashInitialCapacity
		 *		invalid value for hashLoadFactor
		 *		invalid value for hashMaxCapacity
		 */
		boolean indexSpecified = false;
		boolean constraintSpecified = false;
		ConstraintDescriptor consDesc = null;
		Enumeration e = tableProperties.keys();

			StringUtil.SQLEqualsIgnoreCase(tableDescriptor.getSchemaName(), 
										   ""SYS"");
		while (e.hasMoreElements())
		{
			String key = (String) e.nextElement();
			String value = (String) tableProperties.get(key);

			if (key.equals(""index""))
			{
				// User only allowed to specify 1 of index and constraint, not both
				if (constraintSpecified)
				{
					throw StandardException.newException(SQLState.LANG_BOTH_FORCE_INDEX_AND_CONSTRAINT_SPECIFIED, 
								getBaseTableName());
				}
				indexSpecified = true;

				/* Validate index name - NULL means table scan */
				if (! StringUtil.SQLToUpperCase(value).equals(""NULL""))
				{
					ConglomerateDescriptor cd = null;
					ConglomerateDescriptor[] cds = tableDescriptor.getConglomerateDescriptors();

					for (int index = 0; index < cds.length; index++)
					{
						cd = cds[index];
						String conglomerateName = cd.getConglomerateName();
						if (conglomerateName != null)
						{
							if (conglomerateName.equals(value))
							{
								break;
							}
						}
						// Not a match, clear cd
						cd = null;
					}

					// Throw exception if user specified index not found
					if (cd == null)
					{
						throw StandardException.newException(SQLState.LANG_INVALID_FORCED_INDEX1, 
										value, getBaseTableName());
					}
					/* Query is dependent on the ConglomerateDescriptor */
					getCompilerContext().createDependency(cd);
				}
			}
			else if (key.equals(""constraint""))
			{
				// User only allowed to specify 1 of index and constraint, not both
				if (indexSpecified)
				{
					throw StandardException.newException(SQLState.LANG_BOTH_FORCE_INDEX_AND_CONSTRAINT_SPECIFIED, 
								getBaseTableName());
				}
				constraintSpecified = true;

				if (! StringUtil.SQLToUpperCase(value).equals(""NULL""))
				{
					consDesc = 
						dDictionary.getConstraintDescriptorByName(
									tableDescriptor, (SchemaDescriptor)null, value,
									false);

					/* Throw exception if user specified constraint not found
					 * or if it does not have a backing index.
					 */
					if ((consDesc == null) || ! consDesc.hasBackingIndex())
					{
						throw StandardException.newException(SQLState.LANG_INVALID_FORCED_INDEX2, 
										value, getBaseTableName());
					}

					/* Query is dependent on the ConstraintDescriptor */
					getCompilerContext().createDependency(consDesc);
				}
			}
			else if (key.equals(""joinStrategy""))
			{
				userSpecifiedJoinStrategy = StringUtil.SQLToUpperCase(value);
			}
			else if (key.equals(""hashInitialCapacity""))
			{
				initialCapacity = getIntProperty(value, key);

				// verify that the specified value is valid
				if (initialCapacity <= 0)
				{
					throw StandardException.newException(SQLState.LANG_INVALID_HASH_INITIAL_CAPACITY, 
							String.valueOf(initialCapacity));
				}
			}
			else if (key.equals(""hashLoadFactor""))
			{
				try
				{
					loadFactor = Float.parseFloat(value);
				}
				catch (NumberFormatException nfe)
				{
					throw StandardException.newException(SQLState.LANG_INVALID_NUMBER_FORMAT_FOR_OVERRIDE, 
							value, key);
				}

				// verify that the specified value is valid
				if (loadFactor <= 0.0 || loadFactor > 1.0)
				{
					throw StandardException.newException(SQLState.LANG_INVALID_HASH_LOAD_FACTOR, 
							value);
				}
			}
			else if (key.equals(""hashMaxCapacity""))
			{
				maxCapacity = getIntProperty(value, key);

				// verify that the specified value is valid
				if (maxCapacity <= 0)
				{
					throw StandardException.newException(SQLState.LANG_INVALID_HASH_MAX_CAPACITY, 
							String.valueOf(maxCapacity));
				}
			}
			else if (key.equals(""bulkFetch""))
			{
				bulkFetch = getIntProperty(value, key);

				// verify that the specified value is valid
				if (bulkFetch <= 0)
				{
					throw StandardException.newException(SQLState.LANG_INVALID_BULK_FETCH_VALUE, 
							String.valueOf(bulkFetch));
				}
			
				// no bulk fetch on updatable scans
				if (forUpdate())
				{
					throw StandardException.newException(SQLState.LANG_INVALID_BULK_FETCH_UPDATEABLE);
				}
			}
			else
			{
				// No other ""legal"" values at this time
				throw StandardException.newException(SQLState.LANG_INVALID_FROM_TABLE_PROPERTY, key,
					""index, constraint, joinStrategy"");
			}
		}

		/* If user specified a non-null constraint name(DERBY-1707), then  
		 * replace it in the properties list with the underlying index name to 
		 * simplify the code in the optimizer.
		 * NOTE: The code to get from the constraint name, for a constraint
		 * with a backing index, to the index name is convoluted.  Given
		 * the constraint name, we can get the conglomerate id from the
		 * ConstraintDescriptor.  We then use the conglomerate id to get
		 * the ConglomerateDescriptor from the DataDictionary and, finally,
		 * we get the index name (conglomerate name) from the ConglomerateDescriptor.
		 */
		if (constraintSpecified && consDesc != null)
		{
			ConglomerateDescriptor cd = 
				dDictionary.getConglomerateDescriptor(
					consDesc.getConglomerateId());
			String indexName = cd.getConglomerateName();

			tableProperties.remove(""constraint"");
			tableProperties.put(""index"", indexName);
		}
	}"
https://github.com/apache/derby/tree/eea0d50c8d732cad9ba563ddfa786b7028eb092f//java/engine/org/apache/derby/impl/sql/compile/FromList.java,reOrder,close,"public void reOrder(int[] joinOrder)
	{
		int	posn;

		if (SanityManager.DEBUG)
		{
			if (joinOrder.length != size())
			{
				SanityManager.THROWASSERT(""In reOrder(), size of FromList is "" + size() + "" while size of joinOrder array is "" + joinOrder.length);
			}

			/*
			** Determine that the values in the list are unique and in range.
			** The easiest way to determine that they are unique is to add
			** them all up and see whether the result is what's expected
			** for that array size.
			*/
			int sum = 0;
			for (int i = 0; i < joinOrder.length; i++)
			{
				if (joinOrder[i] < 0 || joinOrder[i] > (joinOrder.length - 1))
				{
					SanityManager.THROWASSERT(""joinOrder["" + i + ""] == "" +
											joinOrder[i] +
											"" is out of range - must be between 0 and "" + 
											(joinOrder.length - 1) +
											"" inclusive."");
				}

				sum += joinOrder[i];
			}

			/*
			** The sum of all integers from 0 through n is (n * (n - 1)) / 2.
			*/
			if (sum != ( ( joinOrder.length * (joinOrder.length - 1) ) / 2) )
			{
				String arrayVals = """";
				for (int i = 0; i < joinOrder.length; i++)
					arrayVals = arrayVals + joinOrder[i] + "" "";
				SanityManager.THROWASSERT(""joinOrder array has some duplicate value: "" + arrayVals);
			}
		}

		/* Form a list that's in the order we want */
		QueryTreeNode[] orderedFL = new FromTable[joinOrder.length];
		for (posn = 0; posn < joinOrder.length; posn++)
		{
			/*
			** Get the element at the i'th join order position from the
			** current list and make it the next element of orderedList.
			*/
			orderedFL[posn] = elementAt(joinOrder[posn]);
		}

		/* Now orderedList has been built, so set this list to the same order */
		for (posn = 0; posn < joinOrder.length; posn++)
		{
			setElementAt(orderedFL[posn], posn);
		}
	}"
https://github.com/apache/derby/tree/eea0d50c8d732cad9ba563ddfa786b7028eb092f//java/engine/org/apache/derby/impl/sql/compile/FromVTI.java,getVTICosting,open,"private VTICosting  getVTICosting()
        throws StandardException
    {
        if ( !isDerbyStyleTableFunction ) { return (version2) ? (VTICosting) ps : (VTICosting) rs; }
        
        String              className = methodCall.getJavaClassName();
        Class               vtiClass = lookupClass( className );
        
        try {
            Constructor         constructor = vtiClass.getConstructor( new Class[] {} );
            VTICosting          result = (VTICosting) constructor.newInstance( null );

            return result;
        }
        catch (Throwable t)
        {
            throw StandardException.unexpectedUserException( t );
        }
    }"
https://github.com/apache/derby/tree/eea0d50c8d732cad9ba563ddfa786b7028eb092f//java/engine/org/apache/derby/impl/sql/compile/FromVTI.java,getNewInstance,open,"private Object getNewInstance()
        throws StandardException
    {
		NewInvocationNode   constructor = (NewInvocationNode) methodCall;
		Class[]  paramTypeClasses = constructor.getMethodParameterClasses();
		Object[] paramObjects = null;

		if (paramTypeClasses != null)
		{
			paramObjects = new Object[paramTypeClasses.length];

			for (int index = 0; index < paramTypeClasses.length; index++)
			{
				Class paramClass = paramTypeClasses[index];

				paramObjects[index] = methodParms[index].getConstantValueAsObject();

				// As-per the JDBC spec SMALLINT and TINYINT map to java.lang.Integer
				// as objects. This means if getConstantValueAsObject() has returned an
				// Integer obejct in these cases, whereas Java method calling requires
				// Short or Byte object.
				if ((paramObjects[index] != null) && paramClass.isPrimitive()) {

					if (paramClass.equals(Short.TYPE)) {
						paramObjects[index] =
							new Short(((Integer) paramObjects[index]).shortValue());
					} else if (paramClass.equals(Byte.TYPE)) {
						paramObjects[index] =
							new Byte(((Integer) paramObjects[index]).byteValue());
					}
				}

				// Pass defaults for unknown primitive values
				if (paramObjects[index] == null && 
					paramClass.isPrimitive())
				{
					if (paramClass.equals(Integer.TYPE))
					{
						paramObjects[index] = new Integer(0);
					}
					else if (paramClass.equals(Short.TYPE))
					{
						paramObjects[index] = new Short((short) 0);
					}
					else if (paramClass.equals(Byte.TYPE))
					{
						paramObjects[index] = new Byte((byte) 0);
					}
					else if (paramClass.equals(Long.TYPE))
					{
						paramObjects[index] = new Long((long) 0);
					}
					else if (paramClass.equals(Float.TYPE))
					{
						paramObjects[index] = new Float((float) 0);
					}
					else if (paramClass.equals(Double.TYPE))
					{
						paramObjects[index] = new Double((double) 0);
					}
					else if (paramClass.equals(Boolean.TYPE))
					{
						paramObjects[index] = Boolean.FALSE;
					}
					else if (paramClass.equals(Character.TYPE))
					{
						paramObjects[index] = new Character(Character.MIN_VALUE);
					}
				}
			}
		}
		else
		{
			paramTypeClasses = new Class[0];
			paramObjects = new Object[0];
		}

        try
        {
            ClassInspector classInspector = getClassFactory().getClassInspector();
            String javaClassName = methodCall.getJavaClassName();
            Constructor constr = classInspector.getClass(javaClassName).getConstructor(paramTypeClasses);

            return constr.newInstance(paramObjects);
        }
		catch(Throwable t)
		{
            if( t instanceof InvocationTargetException)
            {
                InvocationTargetException ite = (InvocationTargetException) t;
                Throwable wrappedThrowable = ite.getTargetException();
                if( wrappedThrowable instanceof StandardException)
                    throw (StandardException) wrappedThrowable;
            }
			throw StandardException.unexpectedUserException(t);
		}
    }"
https://github.com/apache/derby/tree/eea0d50c8d732cad9ba563ddfa786b7028eb092f//java/engine/org/apache/derby/impl/sql/compile/GroupByNode.java,optimizeIt,close,"public CostEstimate optimizeIt(
							Optimizer optimizer,
							OptimizablePredicateList predList,
							CostEstimate outerCost,
							RowOrdering rowOrdering)
			throws StandardException
	{
		// RESOLVE: NEED TO FACTOR IN THE COST OF GROUPING (SORTING) HERE
		CostEstimate childCost = ((Optimizable) childResult).optimizeIt(
													optimizer,
													predList,
													outerCost,
													rowOrdering);

		CostEstimate retval = super.optimizeIt(
												optimizer,
												predList,
												outerCost,
												rowOrdering
											  );

		return retval;
	}"
https://github.com/apache/derby/tree/eea0d50c8d732cad9ba563ddfa786b7028eb092f//java/engine/org/apache/derby/impl/sql/compile/HalfOuterJoinNode.java,LOJ_reorderable,open,"public boolean LOJ_reorderable(int numTables)
		throws StandardException
	{
		boolean anyChange = false;

		ResultSetNode logicalLeftResultSet;  // row-preserving side
		ResultSetNode logicalRightResultSet; // null-producing side

		// Figure out which is the row-preserving side and which is
		// null-producing side.
		if (rightOuterJoin)
		{ // right outer join
			logicalLeftResultSet  = rightResultSet;
			logicalRightResultSet = leftResultSet;
		}
		else 
		{
			logicalLeftResultSet  = leftResultSet;
			logicalRightResultSet = rightResultSet;
		}
		
		// Redundantly normalize the ON predicate (it will also be called in preprocess()).
		super.normExpressions();

        // This is a very simple OJ of base tables. Do nothing.
		if (logicalLeftResultSet instanceof FromBaseTable &&
			logicalRightResultSet instanceof FromBaseTable)
			return anyChange;

        // Recursively check if we can reordering OJ, and build the table
		// references. Note that joins may have been reordered and therefore the
		// table references need to be recomputed.
		if (logicalLeftResultSet instanceof HalfOuterJoinNode)
		{
			anyChange =	((HalfOuterJoinNode)logicalLeftResultSet).LOJ_reorderable(numTables) || anyChange;
		}
		else if (!(logicalLeftResultSet instanceof FromBaseTable))
        {// left operand must be either a base table or another OJ
			// In principle, we don't care about the left operand.  However, we
			// need to re-bind the resultColumns.  If the left operand is a
			// view, we may have to re-bind the where clause etc...
			// We ran into difficulty for the following query:
			//  create view v8 (cv, bv, av) as (select c, b, a from t union select f, e, d from s);
			//  select * from v8 left outer join (s left outer join r on (f = i)) on (e=v8.bv);
			return anyChange;
		}

		if (logicalRightResultSet instanceof HalfOuterJoinNode)
		{
			anyChange = ((HalfOuterJoinNode)logicalRightResultSet).LOJ_reorderable(numTables) || anyChange;
		}
		else if (!(logicalRightResultSet instanceof FromBaseTable))
        {// right operand must be either a base table or another OJ
			return anyChange;
		}

        // It is much easier to do OJ reordering if there is no ROJ.
		// However, we ran into some problem downstream when we transform an ROJ
		// into LOJ -- transformOuterJoin() didn't expect ROJ to be transformed
		// into LOJ alread.  So, we skip optimizing ROJ at the moment.
		if (rightOuterJoin || (logicalRightResultSet instanceof HalfOuterJoinNode && 
							   ((HalfOuterJoinNode)logicalRightResultSet).rightOuterJoin))
		{
			return LOJ_bindResultColumns(anyChange);
		}

        // Build the data structure for testing/doing OJ reordering.  Fill in
        // the table references on row-preserving and null-producing sides.  It
        // may be possible that either operand is a complex view.

        JBitSet RPReferencedTableMap; // Row-preserving
        JBitSet NPReferencedTableMap; // Null-producing

		RPReferencedTableMap = logicalLeftResultSet.LOJgetReferencedTables(numTables);
		NPReferencedTableMap = logicalRightResultSet.LOJgetReferencedTables(numTables);

		if ((RPReferencedTableMap == null || NPReferencedTableMap == null) &&
			anyChange)
		{
			return LOJ_bindResultColumns(anyChange);
		}


        // Check if logical right operand is another OJ... so we may be able
        // to push the join.
        if (logicalRightResultSet instanceof HalfOuterJoinNode)
		{
            // Get the row-preserving map of the  child OJ
            JBitSet  nestedChildOJRPRefTableMap =
                ((HalfOuterJoinNode)logicalRightResultSet).
                LOJgetRPReferencedTables(numTables);

            // Checks that top has p(t1,t2)
            if ( ! isNullRejecting(
                         joinClause,
                         RPReferencedTableMap,
                         nestedChildOJRPRefTableMap)) {
                // No, give up.
                return LOJ_bindResultColumns(anyChange);
            }

            // Get the null-producing map of the child OJ
            JBitSet  nestedChildOJNPRefTableMap =
                ((HalfOuterJoinNode)logicalRightResultSet).
                LOJgetNPReferencedTables(numTables);

            // Checks that right child has p(t2,t3)
            if ( isNullRejecting(
                         ((HalfOuterJoinNode)logicalRightResultSet).joinClause,
                         nestedChildOJRPRefTableMap,
                         nestedChildOJNPRefTableMap)) {
                // Push the current OJ into the next level For safety, check
                // the JoinNode data members: they should null or empty list
                // before we proceed.
                if (super.subqueryList.size() != 0 ||
                    ((JoinNode)logicalRightResultSet).
                        subqueryList.size() != 0 ||
                    super.joinPredicates.size() != 0 ||
                    ((JoinNode)logicalRightResultSet).
                        joinPredicates.size() != 0 ||
                    super.usingClause != null ||
                    ((JoinNode)logicalRightResultSet).
                        usingClause != null) {

                    return LOJ_bindResultColumns(anyChange); //  get out of here
                }
                anyChange = true; // we are reordering the OJs.

                ResultSetNode tmp = logicalLeftResultSet;
                ResultSetNode LChild, RChild;

                //            this OJ
                //            /      \
                //  logicalLeftRS   LogicalRightRS
                //                   /     \
                //                LChild  RChild
                // becomes
                //
                //               this OJ
                //               /      \
                //     LogicalRightRS   RChild
                //           /     \
                // logicalLeftRS LChild <<< we need to be careful about this
                //                          order as the ""LogicalRightRS
                //                          may be a ROJ
                //

                // handle the lower level OJ node
                LChild = ((HalfOuterJoinNode)logicalRightResultSet).
                    leftResultSet;
                RChild = ((HalfOuterJoinNode)logicalRightResultSet).
                    rightResultSet;

                ((HalfOuterJoinNode)logicalRightResultSet).
                    rightResultSet = LChild;
                ((HalfOuterJoinNode)logicalRightResultSet).
                    leftResultSet  = tmp;

                // switch the ON clause
                {
                    ValueNode vn = joinClause;
                    joinClause =
                        ((HalfOuterJoinNode)logicalRightResultSet).joinClause;
                    ((HalfOuterJoinNode)logicalRightResultSet).joinClause = vn;
                }

                // No need to switch HalfOuterJoinNode data members for now
                // because we are handling only OJ.
                // boolean local_rightOuterJoin = rightOuterJoin;
                // boolean local_transformed    = transformed;
                // rightOuterJoin = ((HalfOuterJoinNode)logicalRightResultSet).
                //     rightOuterJoin;
                // transformed = ((HalfOuterJoinNode)logicalRightResultSet).
                //     transformed;
                // ((HalfOuterJoinNode)logicalRightResultSet).rightOuterJoin =
                //     local_rightOuterJoin;
                // ((HalfOuterJoinNode)logicalRightResultSet).transformed =
                //     local_transformed;

                FromList localFromList = (FromList) getNodeFactory().getNode(
                    C_NodeTypes.FROM_LIST,
                    getNodeFactory().doJoinOrderOptimization(),
                    getContextManager());

                // switch OJ nodes: by handling the current OJ node
                leftResultSet  = logicalRightResultSet;
                rightResultSet = RChild;

                // rebuild the result columns and re-bind column references
                ((HalfOuterJoinNode)leftResultSet).resultColumns = null;
                 // localFromList is empty:
                ((JoinNode)leftResultSet).bindResultColumns(localFromList);

                // left operand must be another OJ, so recurse.
                boolean localChange = ((HalfOuterJoinNode)leftResultSet).
                    LOJ_reorderable(numTables);
            }
        }

        return LOJ_bindResultColumns(anyChange);
    }"
https://github.com/apache/derby/tree/eea0d50c8d732cad9ba563ddfa786b7028eb092f//java/engine/org/apache/derby/impl/sql/compile/LikeEscapeOperatorNode.java,bindExpression,close,"public ValueNode bindExpression(
    FromList        fromList, 
    SubqueryList    subqueryList,
    Vector          aggregateVector) 
        throws StandardException
    {
        super.bindExpression(fromList, subqueryList, aggregateVector);

        String pattern = null;

        // pattern must be a string or a parameter

        if (!(leftOperand.requiresTypeFromContext()) && 
             !(leftOperand.getTypeId().isStringTypeId()))
        {
            throw StandardException.newException(
                SQLState.LANG_DB2_FUNCTION_INCOMPATIBLE, ""LIKE"", ""FUNCTION"");
        }

        // escape must be a string or a parameter
        if ((rightOperand != null) && 
            !(rightOperand.requiresTypeFromContext()) && 
            !(rightOperand.getTypeId().isStringTypeId()))
        {
            throw StandardException.newException(
                SQLState.LANG_DB2_FUNCTION_INCOMPATIBLE, ""LIKE"", ""FUNCTION"");
        }

        // deal with operand parameters

        /* 
        *  Is there a ? parameter on the left? ie. ""? like 'Derby'""
        *
        *  Do left first because its length is always maximum;
        *  a parameter on the right copies its length from
        *  the left, since it won't match if it is any longer than it.
        */
        if (receiver.requiresTypeFromContext())
        {
            receiver.setType(
                new DataTypeDescriptor(
                    TypeId.getBuiltInTypeId(Types.VARCHAR), true));
            //check if this parameter can pick up it's collation from pattern
            //or escape clauses in that order. If not, then it will take it's
            //collation from the compilation schema.
            if (!leftOperand.requiresTypeFromContext()) {
                receiver.setCollationInfo(leftOperand.getTypeServices());

            } else if (rightOperand != null && !rightOperand.requiresTypeFromContext()) {
                receiver.setCollationInfo(rightOperand.getTypeServices());          	
            } else {
    			receiver.setCollationUsingCompilationSchema();            	
            }
        }

        /* 
         *  Is there a ? parameter for the PATTERN of LIKE? ie. ""column like ?""
         *  
         *  Copy from the receiver -- legal if both are parameters,
         *  both will be max length.
         *  REMIND: should nullability be copied, or set to true?
         */
        if (leftOperand.requiresTypeFromContext())
        {
            /*
            * Set the pattern to the type of the left parameter, if
            * the left is a string, otherwise set it to be VARCHAR. 
            */
            if (receiver.getTypeId().isStringTypeId())
            {
                leftOperand.setType(receiver.getTypeServices());
            }
            else
            {
                leftOperand.setType(
                    new DataTypeDescriptor(
                        TypeId.getBuiltInTypeId(Types.VARCHAR), true));
            }
			//collation of ? operand should be picked up from the context.
            //By the time we come here, receiver will have correct collation
            //set on it and hence we can rely on it to get correct collation
            //for the other ? in LIKE clause
            leftOperand.setCollationInfo(receiver.getTypeServices());          	
        }

        /* 
         *  Is there a ? parameter for the ESCAPE of LIKE?
         *  Copy from the receiver -- legal if both are parameters,
         *  both will be max length.  nullability is set to true.
         */

        if (rightOperand != null && rightOperand.requiresTypeFromContext())
        {
            /*
             * Set the pattern to the type of the left parameter, if
             * the left is a string, otherwise set it to be VARCHAR. 
             */
            if (receiver.getTypeId().isStringTypeId())
            {
                rightOperand.setType(receiver.getTypeServices());
            }
            else
            {
                rightOperand.setType(
                    new DataTypeDescriptor(
                        TypeId.getBuiltInTypeId(Types.VARCHAR), true));
            }
			//collation of ? operand should be picked up from the context.
            //By the time we come here, receiver will have correct collation
            //set on it and hence we can rely on it to get correct collation
            //for the other ? in LIKE clause
            rightOperand.setCollationInfo(receiver.getTypeServices());    	
        }

        bindToBuiltIn();

        TypeCompiler receiverTC = receiver.getTypeCompiler();
        TypeCompiler leftTC     = leftOperand.getTypeCompiler();

        /* The receiver must be a string type
        */
        if (! receiver.getTypeId().isStringTypeId())
        {
            throw StandardException.newException(
                SQLState.LANG_DB2_FUNCTION_INCOMPATIBLE, ""LIKE"", ""FUNCTION"");
        }

        /* If either the left or right operands are non-string types,
         * then we generate an implicit cast to VARCHAR.
         */
        if (!leftOperand.getTypeId().isStringTypeId())
        {
            leftOperand = castArgToString(leftOperand);
            leftTC      = leftOperand.getTypeCompiler();
        }

        if (rightOperand != null)
        {
            rightOperand = castArgToString(rightOperand);
        }

        /* 
         * Remember whether or not the right side (the like pattern) is a string 
         * constant.  We need to remember here so that we can transform LIKE 
         * 'constant' into = 'constant' for non unicode based collation columns.
         */
        boolean leftConstant = (leftOperand instanceof CharConstantNode);
        if (leftConstant)
        {
            pattern = ((CharConstantNode) leftOperand).getString();
        }

        boolean rightConstant = (rightOperand instanceof CharConstantNode);

        if (rightConstant)
        {
            escape = ((CharConstantNode) rightOperand).getString();
            if (escape.length() != 1)
            {
                throw StandardException.newException(
                    SQLState.LANG_INVALID_ESCAPE_CHARACTER, escape);
            }
        }
        else if (rightOperand == null)
        {
            // No Escape clause: Let optimization continue for the = case below
            rightConstant = true;
        }

        /* If we are comparing a UCS_BASIC char with a terriotry based char 
         * then we generate a cast above the receiver to force preprocess to
         * not attempt any of the > <= optimizations since there is no
         * way to determine the 'next' character for the <= operand.
         *
         * TODO-COLLATE - probably need to do something about different 
         *                collation types here.
         */

        // The left and the pattern of the LIKE must be same collation type
        // and derivation.
        if (!receiver.getTypeServices().compareCollationInfo(
        		leftOperand.getTypeServices()))
        {
            // throw error.
            throw StandardException.newException(
                        SQLState.LANG_LIKE_COLLATION_MISMATCH, 
                        receiver.getTypeServices().getSQLstring(),
                        receiver.getTypeServices().getCollationName(),
                        leftOperand.getTypeServices().getSQLstring(),
                        leftOperand.getTypeServices().getCollationName());
        }

        /* If the left side of LIKE is a ColumnReference and right side is a 
         * string constant without a wildcard (eg. column LIKE 'Derby') then we 
         * transform the LIKE into the equivalent LIKE AND =.  
         * If we have an escape clause it also must be a constant 
         * (eg. column LIKE 'Derby' ESCAPE '%').
         *
         * These types of transformations are normally done at preprocess time, 
         * but we make an exception and do this one at bind time because we 
         * transform a NOT LIKE 'a' into (a LIKE 'a') = false prior to 
         * preprocessing.  
         *
         * The transformed tree will become:
         *
         *        AND
         *       /   \
         *     LIKE   =
         */

        if ((receiver instanceof ColumnReference) && 
            leftConstant                          && 
            rightConstant)
        {
            if (Like.isOptimizable(pattern))
            {
                String newPattern = null;

                /*
                 * If our pattern has no pattern chars (after stripping them out
                 * for the ESCAPE case), we are good to apply = to this match
                 */

                if (escape != null)
                {
                    /* we return a new pattern stripped of ESCAPE chars */
                    newPattern =
                        Like.stripEscapesNoPatternChars(
                            pattern, escape.charAt(0));
                }
                else if (pattern.indexOf('_') == -1 && 
                         pattern.indexOf('%') == -1)
                {
                    // no pattern characters.
                    newPattern = pattern;
                }

                if (newPattern != null)
                {
                    // met all conditions, transform LIKE into a ""LIKE and =""

                    ValueNode leftClone = receiver.getClone();

                    // Remember that we did xform, see preprocess()
                    addedEquals = true;

                    // create equals node of the form (eg. column like 'Derby' :
                    //       =
                    //     /   \
                    //  column  'Derby'
                    BinaryComparisonOperatorNode equals = 
                        (BinaryComparisonOperatorNode) getNodeFactory().getNode(
                            C_NodeTypes.BINARY_EQUALS_OPERATOR_NODE,
                            leftClone, 
                            (ValueNode) getNodeFactory().getNode(
                                C_NodeTypes.CHAR_CONSTANT_NODE,
                                newPattern,
                                getContextManager()),
                            getContextManager());

                    // Set forQueryRewrite to bypass comparability checks
                    equals.setForQueryRewrite(true);

                    equals = (BinaryComparisonOperatorNode) 
                        equals.bindExpression(
                            fromList, subqueryList, aggregateVector);

                    // create new and node and hook in ""equals"" the new ""=' node
                    //
                    //        AND
                    //       /   \
                    //     LIKE   = 
                    //           / \
                    //       column 'Derby'

                    AndNode newAnd = 
                        (AndNode) getNodeFactory().getNode(
                                    C_NodeTypes.AND_NODE,
                                    this,
                                    equals,
                                    getContextManager());

                    finishBindExpr();
                    newAnd.postBindFixup();

                    return newAnd;
                }
            }
        }

        finishBindExpr();

        return this;
    }"
https://github.com/apache/derby/tree/eea0d50c8d732cad9ba563ddfa786b7028eb092f//java/engine/org/apache/derby/impl/sql/compile/LockTableNode.java,bindStatement,close,"public void bindStatement() throws StandardException
	{
		CompilerContext			cc = getCompilerContext();
		ConglomerateDescriptor	cd;
		DataDictionary			dd = getDataDictionary();
		SchemaDescriptor		sd;

		String schemaName = tableName.getSchemaName();
		sd = getSchemaDescriptor(schemaName);

		// Users are not allowed to lock system tables
		if (sd.isSystemSchema())
		{
			throw StandardException.newException(SQLState.LANG_NO_USER_DDL_IN_SYSTEM_SCHEMA, 
							statementToString(), schemaName);
		}

		lockTableDescriptor = getTableDescriptor(tableName.getTableName(), sd);

		if (lockTableDescriptor == null)
		{
			// Check if the reference is for a synonym.
			TableName synonymTab = resolveTableToSynonym(tableName);
			if (synonymTab == null)
				throw StandardException.newException(SQLState.LANG_TABLE_NOT_FOUND, tableName);
			tableName = synonymTab;
			sd = getSchemaDescriptor(tableName.getSchemaName());

			lockTableDescriptor = getTableDescriptor(synonymTab.getTableName(), sd);
			if (lockTableDescriptor == null)
				throw StandardException.newException(SQLState.LANG_TABLE_NOT_FOUND, tableName);
		}

		//throw an exception if user is attempting to lock a temporary table
		if (lockTableDescriptor.getTableType() == TableDescriptor.GLOBAL_TEMPORARY_TABLE_TYPE)
		{
				throw StandardException.newException(SQLState.LANG_NOT_ALLOWED_FOR_DECLARED_GLOBAL_TEMP_TABLE);
		}

		conglomerateNumber = lockTableDescriptor.getHeapConglomerateId();

		/* Get the base conglomerate descriptor */
		cd = lockTableDescriptor.getConglomerateDescriptor(conglomerateNumber);

		/* Statement is dependent on the TableDescriptor and ConglomerateDescriptor */
		cc.createDependency(lockTableDescriptor);
		cc.createDependency(cd);

		if (isPrivilegeCollectionRequired())
		{
			// need SELECT privilege to perform lock table statement.
			cc.pushCurrentPrivType(Authorizer.SELECT_PRIV);
			cc.addRequiredTablePriv(lockTableDescriptor);
			cc.popCurrentPrivType();
		}
	}"
https://github.com/apache/derby/tree/eea0d50c8d732cad9ba563ddfa786b7028eb092f//java/engine/org/apache/derby/impl/sql/compile/LockTableNode.java,referencesSessionSchema,open,"public boolean referencesSessionSchema()
		throws StandardException
	{
		//If lock table is on a SESSION schema table, then return true. 
		return isSessionSchema(lockTableDescriptor.getSchemaName());
	}"
https://github.com/apache/derby/tree/eea0d50c8d732cad9ba563ddfa786b7028eb092f//java/engine/org/apache/derby/impl/sql/compile/MethodCallNode.java,resolveMethodCall,open,"protected void resolveMethodCall
        (
         String javaClassName,
         boolean staticMethod
         ) 
        throws StandardException
	{
		// only allow direct method calls through routines and internal SQL.
		if (routineInfo == null && !internalCall)
		{
			// See if we are being executed in an internal context
			if ((getCompilerContext().getReliability() & CompilerContext.INTERNAL_SQL_ILLEGAL) != 0) {
				throw StandardException.newException(SQLState.LANG_SYNTAX_ERROR,  javaClassName + (staticMethod ? ""::"" : ""."") + methodName);
			}
		}

		int			count = signature.length;

		ClassInspector classInspector = getClassFactory().getClassInspector();

		
		String[]		parmTypeNames;
		String[]		primParmTypeNames = null;
		boolean[]		isParam = getIsParam();

		boolean hasDynamicResultSets = hasVarargs() ?
            false :
            (routineInfo != null) && (count != 0) && (count != methodParms.length);

        /*
        ** Find the matching method that is public.
        */
        int signatureOffset = methodName.indexOf('(');
        	
        // support Java signatures by checking if the method name contains a '('
        if (signatureOffset != -1) {
            parmTypeNames = parseValidateSignature(methodName, signatureOffset, hasDynamicResultSets);
            methodName = methodName.substring(0, signatureOffset);
            
            // If the signature is specified then Derby resolves to exactly
            // that method. Setting this flag to false disables the method
            // resolution from automatically optionally repeating the last
            // parameter as needed.
            hasDynamicResultSets = false;
        }
        else
        {
            parmTypeNames = getObjectSignature();
        }

        // the actual type of the trailing Java varargs arg is an array
        if ( hasVarargs() )
        {
            parmTypeNames[ count - 1 ] = parmTypeNames[ count - 1 ] + ""[]"";
        }

        try
        {
            method = classInspector.findPublicMethod
                (
                 javaClassName,
                 methodName,
                 parmTypeNames,
                 null,
                 isParam,
                 staticMethod,
                 hasDynamicResultSets,
                 hasVarargs()
                 );

            // DB2 LUW does not support Java object types for SMALLINT, INTEGER, BIGINT, REAL, DOUBLE
            // and these are the only types that can map to a primitive or an object type according
            // to SQL part 13. So we never have a second chance match.
            // Also if the DDL specified a signature, then no alternate resolution
            if (signatureOffset == -1 && routineInfo == null) {

                /* If no match, then retry with combinations of object and
                 * primitive types.
                 */
                if (method == null)
                {
                    primParmTypeNames = getPrimitiveSignature(false);

                    method = classInspector.findPublicMethod
                        (
                         javaClassName,
                         methodName,
                         parmTypeNames,
                         primParmTypeNames,
                         isParam,
                         staticMethod,
                         hasDynamicResultSets,
                         hasVarargs()
                         );
                }
            }
        }
        catch (ClassNotFoundException e)
        {
            /*
            ** If one of the classes couldn't be found, just act like the
            ** method couldn't be found.  The error lists all the class names,
            ** which should give the user enough info to diagnose the problem.
            */
            method = null;
        }
		/* Throw exception if no matching signature found */
		if (method == null)
		{
			throwNoMethodFound(javaClassName, parmTypeNames, primParmTypeNames);
		}

		String	typeName = classInspector.getType(method);
		actualMethodReturnType = typeName;

		if (routineInfo == null) {

			/* void methods are only okay for CALL Statements */
			if (typeName.equals(""void""))
			{
				if (!forCallStatement)
					throw StandardException.newException(SQLState.LANG_VOID_METHOD_CALL);
			}
		}
		else
		{
			String promoteName = null;
			TypeDescriptorImpl returnType = (TypeDescriptorImpl) routineInfo.getReturnType();
			String requiredType;
			if (returnType == null)
			{
				// must have a void method for a procedure call.
				requiredType = ""void"";
			}
			else
			{
				TypeId returnTypeId = TypeId.getBuiltInTypeId(returnType.getJDBCTypeId());

				if (
				    returnType.isRowMultiSet() &&
				    ( routineInfo.getParameterStyle() == RoutineAliasInfo.PS_DERBY_JDBC_RESULT_SET )
				)
				{
				    requiredType = ResultSet.class.getName();
				}
                else if ( returnType.getTypeId().userType() )
                {
                    requiredType = ((UserDefinedTypeIdImpl) returnType.getTypeId()).getClassName();
                }
				else
				{
			 		requiredType = returnTypeId.getCorrespondingJavaTypeName();

					if (!requiredType.equals(typeName)) {
						switch (returnType.getJDBCTypeId()) {
						case java.sql.Types.BOOLEAN:
						case java.sql.Types.SMALLINT:
						case java.sql.Types.INTEGER:
						case java.sql.Types.BIGINT:
						case java.sql.Types.REAL:
						case java.sql.Types.DOUBLE:
							TypeCompiler tc = getTypeCompiler(returnTypeId);
							requiredType = tc.getCorrespondingPrimitiveTypeName();
							if (!routineInfo.calledOnNullInput() && routineInfo.getParameterCount() != 0)
							{
								promoteName = returnTypeId.getCorrespondingJavaTypeName();
							}
							break;
						}
					}
				}
			}

            boolean foundCorrectType;
            if ( ResultSet.class.getName().equals( requiredType )  )
            {
                // allow subtypes of ResultSet too
                try {
                    Class actualType = classInspector.getClass( typeName );

                    foundCorrectType = ResultSet.class.isAssignableFrom( actualType );
                }
                catch (ClassNotFoundException cnfe) { foundCorrectType = false; }
            }
            else{ foundCorrectType = requiredType.equals(typeName); }

			if (!foundCorrectType)
			{
				throwNoMethodFound(requiredType + "" "" + javaClassName, parmTypeNames, primParmTypeNames);
			}

			// for a returns null on null input with a primitive
			// type we need to promote to an object so we can return null.
			if (promoteName != null)
				typeName = promoteName;
			//propogate collation type from RoutineAliasInfo to
			// MethodCallNode DERBY-2972
                        if (routineInfo.getReturnType() != null)
                            setCollationType(routineInfo.getReturnType().getCollationType());     
                }
	 	setJavaTypeName( typeName );
                
		methodParameterTypes = classInspector.getParameterTypes(method);

        String methodParameter = null;
        
		for (int i = 0; i < methodParameterTypes.length; i++)
		{
			methodParameter = methodParameterTypes[i];

			if (routineInfo != null) {
				if (i < routineInfo.getParameterCount()) {
					int parameterMode = routineInfo.getParameterModes()[ getRoutineArgIdx( i ) ];

					switch (parameterMode) {
					case JDBC30Translation.PARAMETER_MODE_IN:
						break;
					case JDBC30Translation.PARAMETER_MODE_IN_OUT:
						// we need to see if the type of the array is
						// primitive, not the array itself.
						methodParameter = stripOneArrayLevel( methodParameter );
						break;

					case JDBC30Translation.PARAMETER_MODE_OUT:
						// value is not obtained *from* parameter.
						continue;
					}
				}
			}

            //
            // Strip off the array type if this is a varargs arg. We are only interested in
            // whether we need to cast to the cell type.
            //
            if ( hasVarargs() && (i >= getFirstVarargIdx()) )
            {
                methodParameter = stripOneArrayLevel( methodParameter );
            }

			if (ClassInspector.primitiveType(methodParameter))
            {
                // varargs may be omitted, so there may not be an invocation argument
                // corresponding to the vararg
                if ( i < methodParms.length )
                {
                    methodParms[i].castToPrimitive(true);
                }
            }
		}

        // the last routine parameter may have been a varargs. if so,
        // casting may be needed on the trailing varargs
        if ( hasVarargs() )
        {
            int     firstVarargIdx = getFirstVarargIdx();
            int     trailingVarargCount = methodParms.length - firstVarargIdx;

            // the first vararg was handled in the preceding loop
            for ( int i = 1; i < trailingVarargCount; i++ )
            {
                if (ClassInspector.primitiveType(methodParameter))
                {
                    methodParms[ i + firstVarargIdx ].castToPrimitive(true);
                }
            }
        }

		/* Set type info for any null parameters */
		if ( someParametersAreNull() )
		{
			setNullParameterInfo(methodParameterTypes);
		}


    
		/* bug 4450 - if the callable statement is ? = call form, generate the metadata
		infor for the return parameter. We don't really need that info in order to
		execute the callable statement. But with jdbc3.0, this information should be
		made available for return parameter through ParameterMetaData class.
		Parser sets a flag in compilercontext if ? = call. If the flag is set,
		we generate the metadata info for the return parameter and reset the flag
		in the compilercontext for future call statements*/
		DataTypeDescriptor dts = DataTypeDescriptor.getSQLDataTypeDescriptor(typeName);
		if (getCompilerContext().getReturnParameterFlag()) {
			getCompilerContext().getParameterTypes()[0] = dts;
		}
    }"
https://github.com/apache/derby/tree/eea0d50c8d732cad9ba563ddfa786b7028eb092f//java/engine/org/apache/derby/impl/sql/compile/MethodCallNode.java,generateVarargs,open,"private void    generateVarargs
        ( ExpressionClassBuilder acb, MethodBuilder mb )
        throws StandardException
    {
        // the vararg is the last declared arg of the Java method. it is always
        // an array type. right now we only support vararg static methods.
        // if we have to support vararg constructors in the future, then this code
        // will need adjustment.
        int         firstVarargIdx = getFirstVarargIdx();
        String      arrayType = methodParameterTypes[ firstVarargIdx ];
        String      cellType = stripOneArrayLevel( arrayType );
        String      varargType = cellType;

        // must strip another array level off of out and in/out parameters
        if ( routineInfo != null )
        {
            if ( routineInfo.getParameterModes()[ firstVarargIdx ] != JDBC30Translation.PARAMETER_MODE_IN )
            {
                varargType = stripOneArrayLevel( varargType );
            }
        }

        int         varargCount = methodParms.length - firstVarargIdx;
        if ( varargCount < 0 ) { varargCount = 0; }

        // allocate an array to hold the varargs
		LocalField arrayField = acb.newFieldDeclaration( Modifier.PRIVATE, arrayType );
		MethodBuilder cb = acb.getConstructor();
		cb.pushNewArray( cellType, varargCount );
		cb.setField( arrayField );

        // now put the arguments into the array
        for ( int i = 0; i < varargCount; i++ )
        {
			mb.getField( arrayField ); // push the array onto the stack
            // evaluate the parameter and push it onto the stack
            generateAndCastOneParameter( acb, mb, i + firstVarargIdx, cellType );
            mb.setArrayElement( i ); // move the parameter into the array, pop the stack
        }
        
        // push the array onto the stack. it is the last parameter to the varargs routine.
        mb.getField( arrayField );
    }"
https://github.com/apache/derby/tree/eea0d50c8d732cad9ba563ddfa786b7028eb092f//java/engine/org/apache/derby/impl/sql/compile/MethodCallNode.java,throwNoMethodFound,close,"void throwNoMethodFound(String receiverTypeName,
									  String[] parmTypeNames,
									  String[] primParmTypeNames)
		throws StandardException
	{
		/* Put the parameter type names into a single string */
		StringBuffer	parmTypes = new StringBuffer();
        boolean hasVarargs = hasVarargs();
        int     firstVarargIdx = getFirstVarargIdx();
        int     paramCount = signature.length;
		for (int i = 0; i < paramCount; i++)
		{
			if (i != 0) { parmTypes.append("", ""); }
            boolean isVararg = isVararg( i );

			/* RESOLVE - shouldn't be using hard coded strings for output */
            String  parmType = parmTypeNames[ i ];
            if ( parmTypeNames [i ].length() == 0 ) { parmType = ""UNTYPED""; }
            else if ( isVararg ) { parmType = getVarargTypeName( parmType ); }

            parmTypes.append( parmType );

			if ((primParmTypeNames != null) &&
				! primParmTypeNames[i].equals(parmTypeNames[i]))  // has primitive
            {
                String  primTypeName = primParmTypeNames[ i ];
                if ( isVararg ) { primTypeName = getVarargTypeName( primTypeName ); }
				parmTypes.append(""("" + primTypeName + "")"");
            }
		}

		throw StandardException.newException(SQLState.LANG_NO_METHOD_FOUND, 
												receiverTypeName,
												methodName,
											 	parmTypes);
	}"
https://github.com/apache/derby/tree/eea0d50c8d732cad9ba563ddfa786b7028eb092f//java/engine/org/apache/derby/impl/sql/compile/MethodCallNode.java,getMethodParameterClasses,open,"public	Class[]	getMethodParameterClasses() 
	{ 
		ClassInspector ci = getClassFactory().getClassInspector();

		Class[]	parmTypeClasses = new Class[methodParms.length];
		for (int i = 0; i < methodParms.length; i++)
		{
			String className = methodParameterTypes[i];
			try
			{
				parmTypeClasses[i] = ci.getClass(className);
			}
			catch (ClassNotFoundException cnfe)
			{
				/* We should never get this exception since we verified 
				 * that the classes existed at bind time.  Just return null.
				 */
				if (SanityManager.DEBUG)
				{
					SanityManager.THROWASSERT(""Unexpected exception"", cnfe);
				}
				return null;
			}
		}

		return parmTypeClasses;
	}"
https://github.com/apache/derby/tree/eea0d50c8d732cad9ba563ddfa786b7028eb092f//java/engine/org/apache/derby/impl/sql/compile/MethodCallNode.java,resolveMethodCall,open,"protected void resolveMethodCall
        (
         String javaClassName,
         boolean staticMethod
         ) 
        throws StandardException
	{
		// only allow direct method calls through routines and internal SQL.
		if (routineInfo == null && !internalCall)
		{
			// See if we are being executed in an internal context
			if ((getCompilerContext().getReliability() & CompilerContext.INTERNAL_SQL_ILLEGAL) != 0) {
				throw StandardException.newException(SQLState.LANG_SYNTAX_ERROR,  javaClassName + (staticMethod ? ""::"" : ""."") + methodName);
			}
		}

		int			count = signature.length;

		ClassInspector classInspector = getClassFactory().getClassInspector();

		
		String[]		parmTypeNames;
		String[]		primParmTypeNames = null;
		boolean[]		isParam = getIsParam();

		boolean hasDynamicResultSets = hasVarargs() ?
            false :
            (routineInfo != null) && (count != 0) && (count != methodParms.length);

        /*
        ** Find the matching method that is public.
        */
        int signatureOffset = methodName.indexOf('(');
        	
        // support Java signatures by checking if the method name contains a '('
        if (signatureOffset != -1) {
            parmTypeNames = parseValidateSignature(methodName, signatureOffset, hasDynamicResultSets);
            methodName = methodName.substring(0, signatureOffset);
            
            // If the signature is specified then Derby resolves to exactly
            // that method. Setting this flag to false disables the method
            // resolution from automatically optionally repeating the last
            // parameter as needed.
            hasDynamicResultSets = false;
        }
        else
        {
            parmTypeNames = getObjectSignature();
        }

        // the actual type of the trailing Java varargs arg is an array
        if ( hasVarargs() )
        {
            parmTypeNames[ count - 1 ] = parmTypeNames[ count - 1 ] + ""[]"";
        }

        try
        {
            method = classInspector.findPublicMethod
                (
                 javaClassName,
                 methodName,
                 parmTypeNames,
                 null,
                 isParam,
                 staticMethod,
                 hasDynamicResultSets,
                 hasVarargs()
                 );

            // DB2 LUW does not support Java object types for SMALLINT, INTEGER, BIGINT, REAL, DOUBLE
            // and these are the only types that can map to a primitive or an object type according
            // to SQL part 13. So we never have a second chance match.
            // Also if the DDL specified a signature, then no alternate resolution
            if (signatureOffset == -1 && routineInfo == null) {

                /* If no match, then retry with combinations of object and
                 * primitive types.
                 */
                if (method == null)
                {
                    primParmTypeNames = getPrimitiveSignature(false);

                    method = classInspector.findPublicMethod
                        (
                         javaClassName,
                         methodName,
                         parmTypeNames,
                         primParmTypeNames,
                         isParam,
                         staticMethod,
                         hasDynamicResultSets,
                         hasVarargs()
                         );
                }
            }
        }
        catch (ClassNotFoundException e)
        {
            /*
            ** If one of the classes couldn't be found, just act like the
            ** method couldn't be found.  The error lists all the class names,
            ** which should give the user enough info to diagnose the problem.
            */
            method = null;
        }
		/* Throw exception if no matching signature found */
		if (method == null)
		{
			throwNoMethodFound(javaClassName, parmTypeNames, primParmTypeNames);
		}

		String	typeName = classInspector.getType(method);
		actualMethodReturnType = typeName;

		if (routineInfo == null) {

			/* void methods are only okay for CALL Statements */
			if (typeName.equals(""void""))
			{
				if (!forCallStatement)
					throw StandardException.newException(SQLState.LANG_VOID_METHOD_CALL);
			}
		}
		else
		{
			String promoteName = null;
			TypeDescriptorImpl returnType = (TypeDescriptorImpl) routineInfo.getReturnType();
			String requiredType;
			if (returnType == null)
			{
				// must have a void method for a procedure call.
				requiredType = ""void"";
			}
			else
			{
				TypeId returnTypeId = TypeId.getBuiltInTypeId(returnType.getJDBCTypeId());

				if (
				    returnType.isRowMultiSet() &&
				    ( routineInfo.getParameterStyle() == RoutineAliasInfo.PS_DERBY_JDBC_RESULT_SET )
				)
				{
				    requiredType = ResultSet.class.getName();
				}
                else if ( returnType.getTypeId().userType() )
                {
                    requiredType = ((UserDefinedTypeIdImpl) returnType.getTypeId()).getClassName();
                }
				else
				{
			 		requiredType = returnTypeId.getCorrespondingJavaTypeName();

					if (!requiredType.equals(typeName)) {
						switch (returnType.getJDBCTypeId()) {
						case java.sql.Types.BOOLEAN:
						case java.sql.Types.SMALLINT:
						case java.sql.Types.INTEGER:
						case java.sql.Types.BIGINT:
						case java.sql.Types.REAL:
						case java.sql.Types.DOUBLE:
							TypeCompiler tc = getTypeCompiler(returnTypeId);
							requiredType = tc.getCorrespondingPrimitiveTypeName();
							if (!routineInfo.calledOnNullInput() && routineInfo.getParameterCount() != 0)
							{
								promoteName = returnTypeId.getCorrespondingJavaTypeName();
							}
							break;
						}
					}
				}
			}

            boolean foundCorrectType;
            if ( ResultSet.class.getName().equals( requiredType )  )
            {
                // allow subtypes of ResultSet too
                try {
                    Class actualType = classInspector.getClass( typeName );

                    foundCorrectType = ResultSet.class.isAssignableFrom( actualType );
                }
                catch (ClassNotFoundException cnfe) { foundCorrectType = false; }
            }
            else{ foundCorrectType = requiredType.equals(typeName); }

			if (!foundCorrectType)
			{
				throwNoMethodFound(requiredType + "" "" + javaClassName, parmTypeNames, primParmTypeNames);
			}

			// for a returns null on null input with a primitive
			// type we need to promote to an object so we can return null.
			if (promoteName != null)
				typeName = promoteName;
			//propogate collation type from RoutineAliasInfo to
			// MethodCallNode DERBY-2972
                        if (routineInfo.getReturnType() != null)
                            setCollationType(routineInfo.getReturnType().getCollationType());     
                }
	 	setJavaTypeName( typeName );
                
		methodParameterTypes = classInspector.getParameterTypes(method);

        String methodParameter = null;
        
		for (int i = 0; i < methodParameterTypes.length; i++)
		{
			methodParameter = methodParameterTypes[i];

			if (routineInfo != null) {
				if (i < routineInfo.getParameterCount()) {
					int parameterMode = routineInfo.getParameterModes()[ getRoutineArgIdx( i ) ];

					switch (parameterMode) {
					case JDBC30Translation.PARAMETER_MODE_IN:
						break;
					case JDBC30Translation.PARAMETER_MODE_IN_OUT:
						// we need to see if the type of the array is
						// primitive, not the array itself.
						methodParameter = stripOneArrayLevel( methodParameter );
						break;

					case JDBC30Translation.PARAMETER_MODE_OUT:
						// value is not obtained *from* parameter.
						continue;
					}
				}
			}

            //
            // Strip off the array type if this is a varargs arg. We are only interested in
            // whether we need to cast to the cell type.
            //
            if ( hasVarargs() && (i >= getFirstVarargIdx()) )
            {
                methodParameter = stripOneArrayLevel( methodParameter );
            }

			if (ClassInspector.primitiveType(methodParameter))
            {
                // varargs may be omitted, so there may not be an invocation argument
                // corresponding to the vararg
                if ( i < methodParms.length )
                {
                    methodParms[i].castToPrimitive(true);
                }
            }
		}

        // the last routine parameter may have been a varargs. if so,
        // casting may be needed on the trailing varargs
        if ( hasVarargs() )
        {
            int     firstVarargIdx = getFirstVarargIdx();
            int     trailingVarargCount = methodParms.length - firstVarargIdx;

            // the first vararg was handled in the preceding loop
            for ( int i = 1; i < trailingVarargCount; i++ )
            {
                if (ClassInspector.primitiveType(methodParameter))
                {
                    methodParms[ i + firstVarargIdx ].castToPrimitive(true);
                }
            }
        }

		/* Set type info for any null parameters */
		if ( someParametersAreNull() )
		{
			setNullParameterInfo(methodParameterTypes);
		}


    
		/* bug 4450 - if the callable statement is ? = call form, generate the metadata
		infor for the return parameter. We don't really need that info in order to
		execute the callable statement. But with jdbc3.0, this information should be
		made available for return parameter through ParameterMetaData class.
		Parser sets a flag in compilercontext if ? = call. If the flag is set,
		we generate the metadata info for the return parameter and reset the flag
		in the compilercontext for future call statements*/
		DataTypeDescriptor dts = DataTypeDescriptor.getSQLDataTypeDescriptor(typeName);
		if (getCompilerContext().getReturnParameterFlag()) {
			getCompilerContext().getParameterTypes()[0] = dts;
		}
    }"
https://github.com/apache/derby/tree/eea0d50c8d732cad9ba563ddfa786b7028eb092f//java/engine/org/apache/derby/impl/sql/compile/NumericTypeCompiler.java,getScale,close,"private int getScale(String operator,
							DataTypeDescriptor leftType,
							DataTypeDescriptor rightType)
	{
		// Only meaningful for decimal
		if (getStoredFormatIdFromTypeId() != StoredFormatIds.DECIMAL_TYPE_ID)
		{
			return leftType.getScale();
		}

		long val;

		long lscale = (long)leftType.getScale();
		long rscale = (long)rightType.getScale();
		long lprec = (long)leftType.getPrecision();
		long rprec = (long)rightType.getPrecision();

		/*
		** Retain greatest scale, take sum of left
		** of decimal
		*/
		if (TypeCompiler.TIMES_OP.equals(operator))
		{	
			val = lscale + rscale;
		}
		else if (TypeCompiler.DIVIDE_OP.equals(operator))
		{
			/*
			** Take max left scale + right precision - right scale + 1, 
			** or 4, whichever is biggest 
			*/
			LanguageConnectionContext lcc = (LanguageConnectionContext)
				(ContextService.getContext(LanguageConnectionContext.CONTEXT_ID)); 

			// Scale: 31 - left precision + left scale - right scale
				val = Math.max(NumberDataValue.MAX_DECIMAL_PRECISION_SCALE - lprec + lscale - rscale, 0);

		}
		else if (TypeCompiler.AVG_OP.equals(operator))
		{
			val = Math.max(Math.max(lscale, rscale),
						NumberDataValue.MIN_DECIMAL_DIVIDE_SCALE);
		}
		/*
		** SUM, -, + all take max(lscale,rscale)
		*/
		else
		{
			val = Math.max(lscale, rscale);
		}

		if (val > Integer.MAX_VALUE)
		{
			val = Integer.MAX_VALUE;
		}
		val = Math.min(NumberDataValue.MAX_DECIMAL_PRECISION_SCALE, val);
		return (int)val;
	}"
https://github.com/apache/derby/tree/eea0d50c8d732cad9ba563ddfa786b7028eb092f//java/engine/org/apache/derby/impl/sql/compile/NumericTypeCompiler.java,getPrecision,open,"private int getPrecision(String operator,
							DataTypeDescriptor leftType,
							DataTypeDescriptor rightType)
	{
		// Only meaningful for decimal
		if (getStoredFormatIdFromTypeId() != StoredFormatIds.DECIMAL_TYPE_ID)
		{
			return leftType.getPrecision();
		}

		long lscale = (long)leftType.getScale();
		long rscale = (long)rightType.getScale();
		long lprec = (long)leftType.getPrecision();
		long rprec = (long)rightType.getPrecision();
		long val;

		/*
		** Null means datatype merge.  Take the maximum
	 	** left of decimal digits plus the scale.
		*/
		if (operator == null)
		{
			val = this.getScale(operator, leftType, rightType) +
					Math.max(lprec - lscale, rprec - rscale);
		}
		else if (operator.equals(TypeCompiler.TIMES_OP))
		{
			val = lprec + rprec;
		}
		else if (operator.equals(TypeCompiler.SUM_OP))
		{
			val = lprec - lscale + rprec - rscale + 
						this.getScale(operator, leftType, rightType);
		}
		else if (operator.equals(TypeCompiler.DIVIDE_OP))
		{
			val = Math.min(NumberDataValue.MAX_DECIMAL_PRECISION_SCALE,
						   this.getScale(operator, leftType, rightType) + lprec - lscale + rprec);
		}
		/*
		** AVG, -, +
		*/
		else
		{
			/*
			** Take max scale and max left of decimal
			** plus one.
			*/
			val = this.getScale(operator, leftType, rightType) +
					Math.max(lprec - lscale, rprec - rscale) + 1;

			if (val > Limits.DB2_MAX_DECIMAL_PRECISION_SCALE)
			// then, like DB2, just set it to the max possible.
				val = Limits.DB2_MAX_DECIMAL_PRECISION_SCALE;
		}

		if (val > Integer.MAX_VALUE)
		{
			val = Integer.MAX_VALUE;
		}
		val = Math.min(NumberDataValue.MAX_DECIMAL_PRECISION_SCALE, val);
		return (int)val;
	}"
https://github.com/apache/derby/tree/eea0d50c8d732cad9ba563ddfa786b7028eb092f//java/engine/org/apache/derby/impl/sql/compile/OptimizerImpl.java,ruleBasedCostOptimizable,close,"private void ruleBasedCostOptimizable(Optimizable optimizable,
											TableDescriptor td,
											ConglomerateDescriptor cd,
											OptimizablePredicateList predList,
											CostEstimate outerCost)
				throws StandardException
	{
		/* CHOOSE BEST CONGLOMERATE HERE */
		ConglomerateDescriptor	conglomerateDescriptor = null;
		ConglomerateDescriptor	bestConglomerateDescriptor = null;
		AccessPath bestAp = optimizable.getBestAccessPath();
		int lockMode = optimizable.getCurrentAccessPath().getLockMode();


		/*
		** If the current conglomerate better than the best so far?
		** The pecking order is:
		**		o  covering index useful for predicates
		**			(if there are predicates)
		**		o  index useful for predicates (if there are predicates)
		**		o  covering index
		**		o  table scan
		*/

		/*
		** If there is more than one conglomerate descriptor
		** choose any index that is potentially useful.
		*/
		if (predList != null &&
			predList.useful(optimizable, cd))
		{
			/*
			** Do not let a non-covering matching index scan supplant a
			** covering matching index scan.
			*/
			boolean newCoveringIndex = optimizable.isCoveringIndex(cd);
			if ( ( ! bestAp.getCoveringIndexScan()) ||
			    bestAp.getNonMatchingIndexScan() ||
				newCoveringIndex )
			{
				bestAp.setCostEstimate(
					estimateTotalCost(
									predList,
									cd,
									outerCost,
									optimizable
									)
								);
				bestAp.setConglomerateDescriptor(cd);
				bestAp.setNonMatchingIndexScan(false);
				bestAp.setCoveringIndexScan(newCoveringIndex);

				bestAp.setLockMode(optimizable.getCurrentAccessPath().getLockMode());

				optimizable.rememberJoinStrategyAsBest(bestAp);
			}

			return;
		}

		/* Remember the ""last"" covering index.
		 * NOTE - Since we don't have costing, we just go for the
		 * last one since that's as good as any
		 */
		if (optimizable.isCoveringIndex(cd))
		{
			bestAp.setCostEstimate(
								estimateTotalCost(predList,
													cd,
													outerCost,
													optimizable)
								);
			bestAp.setConglomerateDescriptor(cd);
			bestAp.setNonMatchingIndexScan(true);
			bestAp.setCoveringIndexScan(true);

			bestAp.setLockMode(optimizable.getCurrentAccessPath().getLockMode());

			optimizable.rememberJoinStrategyAsBest(bestAp);
			return;
		}

		/*
		** If this is the heap, and the best conglomerate so far is a
		** non-covering, non-matching index scan, pick the heap.
		*/
		if ( ( ! bestAp.getCoveringIndexScan()) &&
			 bestAp.getNonMatchingIndexScan() &&
			 ( ! cd.isIndex() )
		   )
		{
			bestAp.setCostEstimate(
									estimateTotalCost(predList,
														cd,
														outerCost,
														optimizable)
									);

			bestAp.setConglomerateDescriptor(cd);

			bestAp.setLockMode(optimizable.getCurrentAccessPath().getLockMode());

			optimizable.rememberJoinStrategyAsBest(bestAp);

			/*
			** No need to set non-matching index scan and covering
			** index scan, as these are already correct.
			*/
			return;
		}


		/*
		** If all else fails, and no conglomerate has been picked yet,
		** pick this one.
		*/
		bestConglomerateDescriptor = bestAp.getConglomerateDescriptor();
		if (bestConglomerateDescriptor == null)
		{
			bestAp.setCostEstimate(
									estimateTotalCost(predList,
									 					cd,
														outerCost,
														optimizable)
									);

			bestAp.setConglomerateDescriptor(cd);

			/*
			** We have determined above that this index is neither covering
			** nor matching.
			*/
			bestAp.setCoveringIndexScan(false);
			bestAp.setNonMatchingIndexScan(cd.isIndex());

			bestAp.setLockMode(optimizable.getCurrentAccessPath().getLockMode());

			optimizable.rememberJoinStrategyAsBest(bestAp);
		}

		return;
	}"
https://github.com/apache/derby/tree/eea0d50c8d732cad9ba563ddfa786b7028eb092f//java/engine/org/apache/derby/impl/sql/compile/OrderByList.java,isInOrderPrefix,close,"boolean isInOrderPrefix(ResultColumnList sourceRCL)
	{
		boolean inOrderPrefix = true;
		int rclSize = sourceRCL.size();

		if (SanityManager.DEBUG)
		{
			if (size() > sourceRCL.size())
			{
				SanityManager.THROWASSERT(
					""size() ("" + size() + 
					"") expected to be <= sourceRCL.size() ("" +
					sourceRCL.size() + "")"");
			}
		}

		int size = size();
		for (int index = 0; index < size; index++)
		{
			if (((OrderByColumn) elementAt(index)).getResultColumn() !=
				(ResultColumn) sourceRCL.elementAt(index))
			{
				return false;
			}
		}
		return true;
	}"
https://github.com/apache/derby/tree/eea0d50c8d732cad9ba563ddfa786b7028eb092f//java/engine/org/apache/derby/impl/sql/compile/OrderByList.java,estimateCost,open,"public void estimateCost(double estimatedInputRows,
								RowOrdering rowOrdering,
								CostEstimate resultCost)
					throws StandardException
	{
		/*
		** Do a bunch of set-up the first time: get the SortCostController,
		** the template row, the ColumnOrdering array, and the estimated
		** row size.
		*/
		if (scc == null)
		{
			scc = getCompilerContext().getSortCostController();

			resultRow =
				resultToSort.getResultColumns().buildEmptyRow().getRowArray();
			columnOrdering = getColumnOrdering();
			estimatedRowSize =
						resultToSort.getResultColumns().getTotalColumnSize();
		}

		long inputRows = (long) estimatedInputRows;
		long exportRows = inputRows;
		double sortCost;

		sortCost = scc.getSortCost(
									(DataValueDescriptor[]) resultRow,
									columnOrdering,
									false,
									inputRows,
									exportRows,
									estimatedRowSize
									);

		resultCost.setCost(sortCost, estimatedInputRows, estimatedInputRows);
	}"
https://github.com/apache/derby/tree/eea0d50c8d732cad9ba563ddfa786b7028eb092f//java/engine/org/apache/derby/impl/sql/compile/ParameterNode.java,generateExpression,open,"public void generateExpression(ExpressionClassBuilder acb,
											MethodBuilder mb)
									throws StandardException
	{
		/* If we were given a specific ValueNode to generate then
		 * just use that.  See, in particular, the preprocess method
		 * of InListOperatorNode.
		 */
		if (valToGenerate != null)
		{
			valToGenerate.generateExpression(acb, mb);
			return;
		}

		DataTypeDescriptor dtd = getTypeServices();
		if ((dtd != null) && dtd.getTypeId().isXMLTypeId()) {
		// We're a parameter that corresponds to an XML column/target,
		// which we don't allow.  We throw the error here instead of
		// in ""bindExpression"" because at the time of bindExpression,
		// we don't know yet what the type is going to be (only when
		// the node that points to this parameter calls
		// ""setType"" do we figure out the type).
			throw StandardException.newException(
				SQLState.LANG_ATTEMPT_TO_BIND_XML);
		}

        /* Generate the return value */

        mb.pushThis();
        mb.push(parameterNumber); // arg

        mb.callMethod(VMOpcode.INVOKEVIRTUAL, ClassName.BaseActivation, ""getParameter"",
                      ClassName.DataValueDescriptor, 1);

		// For some types perform host variable checking
		// to match DB2/JCC where if a host variable is too
		// big it is not accepted, regardless of any trailing padding.

		switch (dtd.getJDBCTypeId()) {
		case Types.BINARY:
		case Types.VARBINARY:
		case Types.LONGVARBINARY:
		case Types.BLOB:
			mb.dup();
			mb.push(dtd.getMaximumWidth());
			mb.callMethod(VMOpcode.INVOKEINTERFACE, (String) null, ""checkHostVariable"",
                      ""void"", 1);
			break;

		default:
			break;
		}

        /* Cast the result to its specific interface */
        mb.cast(getTypeCompiler().interfaceName());
	}"
https://github.com/apache/derby/tree/eea0d50c8d732cad9ba563ddfa786b7028eb092f//java/engine/org/apache/derby/impl/sql/compile/QueryTreeNode.java,bindRowMultiSet,close,"public DataTypeDescriptor bindRowMultiSet( DataTypeDescriptor originalDTD ) throws StandardException
    {
        if ( !originalDTD.getCatalogType().isRowMultiSet() ) { return originalDTD; }

        RowMultiSetImpl originalMultiSet = (RowMultiSetImpl) originalDTD.getTypeId().getBaseTypeId();
        String[] columnNames = originalMultiSet.getColumnNames();
        TypeDescriptor[] columnTypes = originalMultiSet.getTypes();
        int columnCount = columnTypes.length;

        for ( int i = 0; i < columnCount; i++ )
        {
            columnTypes[ i ] = bindUserCatalogType( columnTypes[ i ] );
        }

        return originalDTD;
    }"
https://github.com/apache/derby/tree/eea0d50c8d732cad9ba563ddfa786b7028eb092f//java/engine/org/apache/derby/impl/sql/compile/ResultColumn.java,compareTo,open,"public int compareTo(Object other)
	{
		ResultColumn otherResultColumn = (ResultColumn) other;

		return this.getColumnPosition() - otherResultColumn.getColumnPosition();
	}"
https://github.com/apache/derby/tree/eea0d50c8d732cad9ba563ddfa786b7028eb092f//java/engine/org/apache/derby/impl/sql/compile/ResultColumnList.java,populate,close,"public	void	populate
	(
		TableDescriptor	table,
		int[]			columnIDs
	)
		throws StandardException
	{
		if ( columnIDs == null ) { return; }

		int						count = columnIDs.length;
		TableName				tableName = makeTableName( table.getSchemaName(), table.getName() );
		String					columnName;
		int						columnPosition;
		ResultColumn			rc;

		for ( int i = 0; i < count; i++ )
		{
			columnPosition = columnIDs[ i ];
			columnName = table.getColumnDescriptor( columnPosition ).getColumnName();

			rc = makeColumnFromName( columnName );

			addResultColumn( rc );
		}

	}"
https://github.com/apache/derby/tree/eea0d50c8d732cad9ba563ddfa786b7028eb092f//java/engine/org/apache/derby/impl/sql/compile/ResultColumnList.java,setUnionResultExpression,close,"public void	setUnionResultExpression(ResultColumnList otherRCL,
                                         int tableNumber,
                                         int level,
                                         String operatorName)
		throws StandardException
	{
		TableName		dummyTN;

		if (SanityManager.DEBUG)
		{
			if (visibleSize() != otherRCL.visibleSize())
			{
				SanityManager.THROWASSERT(
							""visibleSize() = ("" +
							visibleSize() +
							"") is expected to equal otherRCL.visibleSize ("" +
							otherRCL.visibleSize() +
							"")"");
			}

            // Generated grouping columns and unselected ORDER BY columns
            // should have been removed for the RCL of a SetOperatorNode, so
            // that size and visible size are equal (DERBY-3764).
            SanityManager.ASSERT(size() == visibleSize(),
                                 ""size() and visibleSize() should be equal"");
		}

		/* Make a dummy TableName to be shared by all new CRs */
		dummyTN = (TableName) getNodeFactory().getNode(
										C_NodeTypes.TABLE_NAME,
										null,
										null,
										getContextManager());

		ContextManager cm = getContextManager();

		int size = visibleSize();
		for (int index = 0; index < size; index++)
		{
			boolean		 nullableResult;
			ColumnReference newCR;
			ResultColumn thisRC = (ResultColumn) elementAt(index);
			ResultColumn otherRC = (ResultColumn) otherRCL.elementAt(index);
			ValueNode	 thisExpr = thisRC.getExpression();
			ValueNode	 otherExpr = otherRC.getExpression();

			// If there is one row that is not 'autoincrement', the Union should
			// not be 'autoincrement'.
			if (!otherRC.isAutoincrementGenerated() && thisRC.isAutoincrementGenerated())
			{
				thisRC.resetAutoincrementGenerated();
			}
			/*
			** If there are ? parameters in the ResultColumnList of a row
			** in a table constructor, their types will not be set.  Just skip
			** these - their types will be set later.  Each ? parameter will
			** get the type of the first non-? in its column, so it can't
			** affect the final dominant type.  It's possible that all the
			** rows for a particular column will have ? parameters - this is
			** an error condition that will be caught later.
			*/
			TypeId thisTypeId = thisExpr.getTypeId();
			if (thisTypeId == null)
				continue;

			TypeId otherTypeId = otherExpr.getTypeId();
			if (otherTypeId == null)
				continue;

			/* 
			** Check type compatability.
			*/
			ClassFactory cf = getClassFactory();
			if ( !unionCompatible( thisExpr, otherExpr ) )
			{
				throw StandardException.newException(SQLState.LANG_NOT_UNION_COMPATIBLE, 
                                                     thisTypeId.getSQLTypeName(),
                                                     otherTypeId.getSQLTypeName(),
                                                     operatorName);
			}

			DataTypeDescriptor resultType = thisExpr.getTypeServices().getDominantType(
												otherExpr.getTypeServices(),
												cf);

			newCR = (ColumnReference) getNodeFactory().getNode(
										C_NodeTypes.COLUMN_REFERENCE,
										thisRC.getName(),
										dummyTN,
										getContextManager());
			newCR.setType(resultType);
			/* Set the tableNumber and nesting levels in newCR.
			 * If thisExpr is not a CR, then newCR cannot be
			 * correlated, hence source and nesting levels are
			 * the same.
			 */
			if (thisExpr instanceof ColumnReference)
			{
				newCR.copyFields((ColumnReference) thisExpr);
			}
			else
			{
				newCR.setNestingLevel(level);
				newCR.setSourceLevel(level);
			}
			newCR.setTableNumber(tableNumber);
			thisRC.setExpression(newCR);
			thisRC.setType(
				thisRC.getTypeServices().getDominantType(
					otherRC.getTypeServices(), cf));

			/* DB2 requires both sides of union to have same name for the result to
			 * have that name. Otherwise, leave it or set it to a generated name */
			if (thisRC.getName() != null && !thisRC.isNameGenerated() &&
				otherRC.getName() != null)
			{
				/* Result name needs to be changed */
				if (otherRC.isNameGenerated())
				{
					thisRC.setName(otherRC.getName());
					thisRC.setNameGenerated(true);
				}
 				else if (!thisRC.getName().equals(otherRC.getName()))
				{
					/* Both sides have user specified names that don't match */
					thisRC.setName(null);
					thisRC.guaranteeColumnName();
					thisRC.setNameGenerated(true);
				}
			}
		}
	}"
https://github.com/apache/derby/tree/eea0d50c8d732cad9ba563ddfa786b7028eb092f//java/engine/org/apache/derby/impl/sql/compile/ResultColumnList.java,hasConsistentTypeInfo,open,"public boolean hasConsistentTypeInfo() throws StandardException
	{
		boolean isConsistent = true;

		if (SanityManager.DEBUG)
		{
		int size = size();
		for (int index = 0; index < size; index++)
			{
				ResultColumn	rc = (ResultColumn) elementAt(index);
				ValueNode	 	expr = rc.getExpression();
				DataTypeDescriptor rcDTS = rc.getTypeServices();
				DataTypeDescriptor exDTS = expr.getTypeServices();

				if (rcDTS == null || exDTS == null)
				{
					isConsistent = false;
					break;
				}

				if (rcDTS.getClass().getName() !=
					exDTS.getClass().getName())
				{
					isConsistent = false;
					break;
				}
			}
		}

		return isConsistent;
	}"
https://github.com/apache/derby/tree/eea0d50c8d732cad9ba563ddfa786b7028eb092f//java/engine/org/apache/derby/impl/sql/compile/ResultColumnList.java,commonCodeForUpdatableByCursor,open,"private void commonCodeForUpdatableByCursor(Vector updateColumns, boolean dealingWithSelectResultColumnList)
	{
		/*
		** If there is no update column list, or the list is empty, then it means that
		** all the columns which have a base table associated with them are updatable.
		*/
		if ( (updateColumns == null) || (updateColumns.size() == 0) )
		{
			markUpdatableByCursor();
		}
		else
		{
			int				ucSize = updateColumns.size();
			ResultColumn	resultColumn;
			String columnName;

			for (int index = 0; index < ucSize; index++)
			{
				columnName = (String) updateColumns.get(index);

				resultColumn = getResultColumn(columnName);
				if (SanityManager.DEBUG)
				{
					if (resultColumn == null && !dealingWithSelectResultColumnList)
					{
						SanityManager.THROWASSERT(""No result column found with name "" +
							columnName);
					}
				}
				//Following if means the column specified in FOR UPDATE clause is not
				//part of the select list
				if (resultColumn == null && dealingWithSelectResultColumnList)
					continue;
				resultColumn.markUpdatableByCursor();
			}
		}
	}"
https://github.com/apache/derby/tree/eea0d50c8d732cad9ba563ddfa786b7028eb092f//java/engine/org/apache/derby/impl/sql/compile/ResultColumnList.java,getStreamStorableColIds,open,"public int[] getStreamStorableColIds(int heapColCount) throws StandardException
	{
		//@#$
		//System.out.println(""getStreamStorableColids"");

		int ssCount = 0;
		boolean[] isSS = new boolean[heapColCount];//Should be table length.
		int size = size();

		for (int index = 0; index < size; index++)
		{
			ResultColumn rc = (ResultColumn) elementAt(index);

			if (rc.getTypeId().streamStorable())
			{
                //System.out.println(""    streamStorable=true"");
				ColumnDescriptor cd = rc.getTableColumnDescriptor();
				isSS[cd.getPosition()-1] = true;
			}
		}

		for (int ix=0;ix<isSS.length;ix++) if (isSS[ix]) ssCount++;

		if (ssCount==0)return null;

		int[] result = new int[ssCount];
		int resultOffset=0;
		for (int heapOffset=0;heapOffset<isSS.length;heapOffset++)
		{
			if (isSS[heapOffset])
				result[resultOffset++]=heapOffset;
		}

		return result;
	}"
https://github.com/apache/derby/tree/eea0d50c8d732cad9ba563ddfa786b7028eb092f//java/engine/org/apache/derby/impl/sql/compile/ResultSetNode.java,parseDefault,close,"public	ValueNode	parseDefault
	(
		String				defaultText
    )
		throws StandardException
	{
		Parser						p;
		ValueNode					defaultTree;
		LanguageConnectionContext	lcc = getLanguageConnectionContext();
		CompilerContext 			compilerContext = getCompilerContext();

		/* Get a Statement to pass to the parser */

		/* We're all set up to parse. We have to build a compilable SQL statement
		 * before we can parse -  So, we goober up a VALUES defaultText.
		 */
		String values = ""VALUES "" + defaultText;
		
		/*
		** Get a new compiler context, so the parsing of the select statement
		** doesn't mess up anything in the current context (it could clobber
		** the ParameterValueSet, for example).
		*/
		CompilerContext newCC = lcc.pushCompilerContext();

		p = newCC.getParser();
				
		/* Finally, we can call the parser */
		// Since this is always nested inside another SQL statement, so topLevel flag
		// should be false
		Visitable qt = p.parseStatement(values);
		if (SanityManager.DEBUG)
		{
			if (! (qt instanceof CursorNode))
			{
				SanityManager.THROWASSERT(
					""qt expected to be instanceof CursorNode, not "" +
					qt.getClass().getName());
			}
			CursorNode cn = (CursorNode) qt;
			if (! (cn.getResultSetNode() instanceof RowResultSetNode))
			{
				SanityManager.THROWASSERT(
					""cn.getResultSetNode() expected to be instanceof RowResultSetNode, not "" +
					cn.getResultSetNode().getClass().getName());
			}
		}

		defaultTree = ((ResultColumn) 
							((CursorNode) qt).getResultSetNode().getResultColumns().elementAt(0)).
									getExpression();

		lcc.popCompilerContext(newCC);

		return	defaultTree;
	}"
https://github.com/apache/derby/tree/eea0d50c8d732cad9ba563ddfa786b7028eb092f//java/engine/org/apache/derby/impl/sql/compile/SelectNode.java,genProjectRestrict,close,"public ResultSetNode genProjectRestrict(int origFromListSize)
				throws StandardException
	{
        boolean[] eliminateSort = new boolean[orderByLists.length];

		ResultSetNode		prnRSN;

		prnRSN = (ResultSetNode) getNodeFactory().getNode(
								C_NodeTypes.PROJECT_RESTRICT_NODE,
								fromList.elementAt(0),	/* Child ResultSet */
								resultColumns,		/* Projection */
								whereClause,			/* Restriction */
								wherePredicates,/* Restriction as PredicateList */
								selectSubquerys,/* Subquerys in Projection */
								whereSubquerys,	/* Subquerys in Restriction */
								null,
								getContextManager()	 );

		/*
		** If we have aggregates OR a select list we want
		** to generate a GroupByNode.  In the case of a
		** scalar aggregate we have no grouping columns.
		**
		** JRESOLVE: what about correlated aggregates from another
		** block.
		*/ 
		if (((selectAggregates != null) && (selectAggregates.size() > 0)) 
			|| (groupByList != null))
		{
			Vector aggs = selectAggregates;
			if (havingAggregates != null && !havingAggregates.isEmpty()) {
				havingAggregates.addAll(selectAggregates);
				aggs = havingAggregates;
			}
			GroupByNode gbn = (GroupByNode) getNodeFactory().getNode(
												C_NodeTypes.GROUP_BY_NODE,
												prnRSN,
												groupByList,
												aggs,
												havingClause,
												havingSubquerys,
												null,
												new Integer(nestingLevel),
												getContextManager());
			gbn.considerPostOptimizeOptimizations(originalWhereClause != null);
			gbn.assignCostEstimate(optimizer.getOptimizedCost());

			groupByList = null;
			prnRSN  = gbn.getParent();

			// Remember whether or not we can eliminate the sort.
            for (int i=0; i < eliminateSort.length; i++ ) {
                eliminateSort[i] = eliminateSort[i] || gbn.getIsInSortedOrder();
            }
		}


		if (windows != null) {

			// Now we add a window result set wrapped in a PRN on top of what
			// we currently have.

			if (windows.size() > 1) {
				throw StandardException.newException(
					SQLState.LANG_WINDOW_LIMIT_EXCEEDED);
			}

			WindowNode wn = (WindowNode)windows.elementAt(0);

			WindowResultSetNode wrsn =
				(WindowResultSetNode)getNodeFactory().getNode(
					C_NodeTypes.WINDOW_RESULTSET_NODE,
					prnRSN,
					wn,
					windowFuncCalls,
					new Integer(nestingLevel),
					getContextManager());

			prnRSN = wrsn.getParent();
			wrsn.assignCostEstimate(optimizer.getOptimizedCost());
		}


		// if it is distinct, that must also be taken care of.
		if (isDistinct)
		{
			// We first verify that a distinct is valid on the
			// RCL.
			resultColumns.verifyAllOrderable();

			/* See if we can push duplicate elimination into the store
			 * via a hash scan.  This is possible iff:
			 *	o  A single table query
			 *	o  We haven't merged the order by and distinct sorts.
			 *	   (Results do not have to be in a particular order.)
			 *	o  All entries in the select's RCL are ColumnReferences.
			 *	o  No predicates (This is because we currently do not
			 *	   differentiate between columns referenced in the select
			 *	   list and columns referenced in other clauses.  In other
			 *	   words, the store will do duplicate elimination based on
			 *	   all referenced columns.)
			 *	   RESOLVE - We can change this to be all referenced columns
			 *	   have to be in the select list.  In that case, we need to
			 *	   refine which predicates are allowed.  Basically, all predicates
			 *	   must have been pushed down to the index/table scan.(If we make
			 *	   this change, then we need to verify that non of the columns in
			 *	   the predicates are correlated columns.)
			 *	o  NOTE: The implementation of isPossibleDistinctScan() will return
			 *	   false if there is an IndexRowToBaseRow above the 
			 *	   FromBaseTable.  This is because all of a table's columns must come
			 *	   from the same conglomerate in order to get consistent data.
			 */
			boolean distinctScanPossible = false;
			if (origFromListSize == 1 && !orderByAndDistinctMerged)
			{
				boolean simpleColumns = true;
				HashSet distinctColumns = new HashSet();
				int size = resultColumns.size();
				for (int i = 1; i <= size; i++) {
					BaseColumnNode bc = resultColumns.getResultColumn(i).getBaseColumnNode();
					if (bc == null) {
						simpleColumns = false;
						break;
					}
					distinctColumns.add(bc);
				}
				if (simpleColumns && prnRSN.isPossibleDistinctScan(distinctColumns)) {
					prnRSN.markForDistinctScan();
					distinctScanPossible = true;
				}
			}

			if (!distinctScanPossible)
			{
				/* We can't do a distinct scan. Determine if we can filter out 
				 * duplicates without a sorter. 
				 */
				boolean inSortedOrder = isOrderedResult(resultColumns, prnRSN, !(orderByAndDistinctMerged));
				prnRSN = (ResultSetNode) getNodeFactory().getNode(
											C_NodeTypes.DISTINCT_NODE,
											prnRSN,
											new Boolean(inSortedOrder),
											null,
											getContextManager());
				prnRSN.costEstimate = costEstimate.cloneMe();

                // Remember whether or not we can eliminate the sort.
                for (int i=0; i < eliminateSort.length; i++) {
                    eliminateSort[i] = eliminateSort[i] || inSortedOrder;
                }
			}
		}

		/* Generate the OrderByNode if a sort is still required for
		 * the order by.
		 */

        for (int i=0; i < orderByLists.length; i++) {
            if (orderByLists[i] != null)
            {
                if (orderByLists[i].getSortNeeded())
                {
                    prnRSN = (ResultSetNode) getNodeFactory().getNode(
                            C_NodeTypes.ORDER_BY_NODE,
                            prnRSN,
                            orderByLists[i],
                            null,
                            getContextManager());
                    prnRSN.costEstimate = costEstimate.cloneMe();
                }

                // There may be columns added to the select projection list
                // a query like:
                // select a, b from t group by a,b order by a+b
                // the expr a+b is added to the select list.
                int orderBySelect = this.getResultColumns().getOrderBySelect();
                if (orderBySelect > 0)
                {
                    // Keep the same RCL on top, since there may be references
                    // to its result columns above us, i.e. in this query:
                    //
                    // select sum(j),i from t group by i having i
                    //             in (select i from t order by j)
                    //
                    ResultColumnList topList = prnRSN.getResultColumns();
                    ResultColumnList newSelectList =
                        topList.copyListAndObjects();
                    prnRSN.setResultColumns(newSelectList);

                    topList.removeOrderByColumns();
                    topList.genVirtualColumnNodes(prnRSN, newSelectList);
                    prnRSN = (ResultSetNode) getNodeFactory().getNode(
                            C_NodeTypes.PROJECT_RESTRICT_NODE,
                            prnRSN,
                            topList,
                            null,
                            null,
                            null,
                            null,
                            null,
                            getContextManager());
                }
            }

            // Do this only after the main ORDER BY; any extra added by
            // IntersectOrExceptNode should sit on top of us.
            if (i == 0 && (offset != null || fetchFirst != null)) {
                // Keep the same RCL on top, since there may be references to
                // its result columns above us.
                ResultColumnList topList = prnRSN.getResultColumns();
                ResultColumnList newSelectList = topList.copyListAndObjects();
                prnRSN.setResultColumns(newSelectList);
                topList.genVirtualColumnNodes(prnRSN, newSelectList);
                prnRSN = (ResultSetNode)getNodeFactory().getNode(
                        C_NodeTypes.ROW_COUNT_NODE,
                        prnRSN,
                        topList,
                        offset,
                        fetchFirst,
                        Boolean.valueOf( hasJDBClimitClause ),
                        getContextManager());
            }
        }


		if (wasGroupBy &&
			resultColumns.numGeneratedColumnsForGroupBy() > 0 &&
			windows == null) // windows handling already added a PRN which
							 // obviates this.
		{
			// This case takes care of columns generated for group by's which 
			// will need to be removed from the final projection. Note that the
			// GroupByNode does remove generated columns but in certain cases
			// we dispense with a group by and replace it with a distinct instead.
			// So in a query like:
			// select c1 from t group by c1, c2
			// we would have added c2 to the projection list which will have to be 
			// projected out.
			//

			// Keep the same RCL on top, since there may be
			// references to its result columns above us, e.g. in this query:
			//
			// select sum(j),i from t group by i having i
			//             in (select i from t group by i,j )
			//
			ResultColumnList topList = prnRSN.getResultColumns();
			ResultColumnList newSelectList = topList.copyListAndObjects();
			prnRSN.setResultColumns(newSelectList);

			topList.removeGeneratedGroupingColumns();
			topList.genVirtualColumnNodes(prnRSN, newSelectList);
			prnRSN = (ResultSetNode) getNodeFactory().getNode(
						C_NodeTypes.PROJECT_RESTRICT_NODE,
						prnRSN,
						topList,
						null,
						null,
						null,
						null,
						null,
						getContextManager());
		}

        for (int i=0; i < orderByLists.length; i++) {
            if (!(orderByLists[i] != null && orderByLists[i].getSortNeeded()) &&
                orderByQuery)
            {
                // Remember whether or not we can eliminate the sort.
                eliminateSort[i] = true;
            }

            /* If we were able to eliminate the sort during optimization then
             * we must tell the underlying tree.  At minimum, this means no
             * group fetch on an index under an IndexRowToBaseRow since that
             * that could lead to incorrect results.  (Bug 2347.)
             */
            if (eliminateSort[i])
            {
                prnRSN.adjustForSortElimination(orderByLists[i]);
            }

            /* Set the cost of this node in the generated node */
            prnRSN.costEstimate = costEstimate.cloneMe();
        }

		return prnRSN;
	}"
https://github.com/apache/derby/tree/eea0d50c8d732cad9ba563ddfa786b7028eb092f//java/engine/org/apache/derby/impl/sql/compile/SelectNode.java,bindExpressions,open,"public void bindExpressions(FromList fromListParam)
					throws StandardException
	{
		int fromListParamSize = fromListParam.size();
		int fromListSize = fromList.size();
		int numDistinctAggs;

		if (SanityManager.DEBUG)
		SanityManager.ASSERT(fromList != null && resultColumns != null,
			""Both fromList and resultColumns are expected to be non-null"");

        if (orderByLists[0] != null) {
            orderByLists[0].pullUpOrderByColumns(this);
        }

		/* NOTE - a lot of this code would be common to bindTargetExpression(),
		 * so we use a private boolean to share the code instead of duplicating
		 * it.  bindTargetExpression() is responsible for toggling the boolean.
		 */
		if (! bindTargetListOnly)
		{
			/* Bind the expressions in FromSubquerys, JoinNodes, etc. */
			fromList.bindExpressions( fromListParam );
		}

		selectSubquerys = (SubqueryList) getNodeFactory().getNode(
											C_NodeTypes.SUBQUERY_LIST,
											getContextManager());
		selectAggregates = new Vector();

		/* Splice our FromList on to the beginning of fromListParam, before binding
		 * the expressions, for correlated column resolution.
		 */
		for (int index = 0; index < fromListSize; index++)
		{
			fromListParam.insertElementAt(fromList.elementAt(index), index);
		}

		// In preparation for resolving window references in expressions, we
		// make the FromList carry the set of explicit window definitions.
		//
		// E.g. ""select row_number () from r, .. from t window r as ()""
		//
		// Here the expression ""row_number () from r"" needs to be bound to r's
		// definition. Window functions can also in-line window specifications,
		// no resolution is necessary. See also
		// WindowFunctionNode.bindExpression.

		fromListParam.setWindows(windows);

		resultColumns.bindExpressions(fromListParam, 
									  selectSubquerys,
									  selectAggregates);

		/* We're done if we're only binding the target list.
		 * (After we restore the fromList, of course.)
		 */
		if (bindTargetListOnly)
		{
			for (int index = 0; index < fromListSize; index++)
			{
				fromListParam.removeElementAt(0);
			}
			return;
		}

		whereAggregates = new Vector();
		whereSubquerys = (SubqueryList) getNodeFactory().getNode(
												C_NodeTypes.SUBQUERY_LIST,
												getContextManager());
        
        CompilerContext cc = getCompilerContext();
        
		if (whereClause != null)
		{
			cc.pushCurrentPrivType( Authorizer.SELECT_PRIV);

            int previousReliability = orReliability( CompilerContext.WHERE_CLAUSE_RESTRICTION );
			whereClause = whereClause.bindExpression(fromListParam, 
										whereSubquerys,
										whereAggregates);
            cc.setReliability( previousReliability );
			
			/* RESOLVE - Temporarily disable aggregates in the HAVING clause.
			** (We may remove them in the parser anyway.)
			** RESOLVE - Disable aggregates in the WHERE clause.  Someday
			** Aggregates will be allowed iff they are in a subquery
			** of the having clause and they correlate to an outer
			** query block.  For now, aggregates are not supported
			** in the WHERE clause at all.
			** Note: a similar check is made in JoinNode.
			*/
			if (whereAggregates.size() > 0)
			{
				throw StandardException.newException(SQLState.LANG_NO_AGGREGATES_IN_WHERE_CLAUSE);
			}

			/* If whereClause is a parameter, (where ?/where -?/where +?), then we should catch it and throw exception
			 */
			if (whereClause.isParameterNode())
				throw StandardException.newException(SQLState.LANG_UNTYPED_PARAMETER_IN_WHERE_CLAUSE );
			
			whereClause = whereClause.checkIsBoolean();
			getCompilerContext().popCurrentPrivType();

			checkNoWindowFunctions(whereClause, ""WHERE"");
		}

		if (havingClause != null)
        {
            int previousReliability = orReliability( CompilerContext.HAVING_CLAUSE_RESTRICTION );

			havingAggregates = new Vector();
			havingSubquerys = (SubqueryList) getNodeFactory().getNode(
					C_NodeTypes.SUBQUERY_LIST,
					getContextManager());
			havingClause.bindExpression(
					fromListParam, havingSubquerys, havingAggregates);
			havingClause = havingClause.checkIsBoolean();
			checkNoWindowFunctions(havingClause, ""HAVING"");
            
            cc.setReliability( previousReliability );
		}
		
		/* Restore fromList */
		for (int index = 0; index < fromListSize; index++)
		{
			fromListParam.removeElementAt(0);
		}

		if (SanityManager.DEBUG) {
		SanityManager.ASSERT(fromListParam.size() == fromListParamSize,
			""fromListParam.size() = "" + fromListParam.size() +
			"", expected to be restored to "" + fromListParamSize);
		SanityManager.ASSERT(fromList.size() == fromListSize,
			""fromList.size() = "" + fromList.size() +
			"", expected to be restored to "" + fromListSize);
		}

		/* If query is grouped, bind the group by list. */
		if (groupByList != null)
		{
			Vector gbAggregateVector = new Vector();

			groupByList.bindGroupByColumns(this,
										   gbAggregateVector);

			/*
			** There should be no aggregates in the Group By list.
			** We don't expect any, but just to be on the safe side
			** we will check under sanity.
			*/
			if (SanityManager.DEBUG)
			{
				SanityManager.ASSERT(gbAggregateVector.size() == 0,
						""Unexpected Aggregate vector generated by Group By clause"");
			}

			checkNoWindowFunctions(groupByList, ""GROUP BY"");
		}
		/* If ungrouped query with aggregates in SELECT list, verify
		 * that all result columns are valid aggregate expressions -
		 * no column references outside of an aggregate.
		 * If grouped query with aggregates in SELECT list, verify that all
		 * result columns are either grouping expressions or valid
		 * grouped aggregate expressions - the only column references
		 * allowed outside of an aggregate are columns in expressions in 
		 * the group by list.
		 */
		if (groupByList != null || selectAggregates.size() > 0)
		{

  			VerifyAggregateExpressionsVisitor visitor = 
  				new VerifyAggregateExpressionsVisitor(groupByList);
			resultColumns.accept(visitor);
		}       

		/*
		** RESOLVE: for now, only one distinct aggregate is supported
		** in the select list.
		*/
		numDistinctAggs = numDistinctAggregates(selectAggregates);
		if (groupByList == null && numDistinctAggs > 1)
		{
			throw StandardException.newException(SQLState.LANG_USER_AGGREGATE_MULTIPLE_DISTINCTS);
		}

        if (orderByLists[0] != null) {
            orderByLists[0].bindOrderByColumns(this);
        }

        bindOffsetFetch(offset, fetchFirst);
    }"
https://github.com/apache/derby/tree/eea0d50c8d732cad9ba563ddfa786b7028eb092f//java/engine/org/apache/derby/impl/sql/compile/SetRoleNode.java,activationKind,close,"int activationKind()
    {
        Vector parameterList = getCompilerContext().getParameterList();
        /*
        ** We need parameters only for those that have parameters.
        */
        if (type == StatementType.SET_ROLE_DYNAMIC) {
            return StatementNode.NEED_PARAM_ACTIVATION;
        } else {
            return StatementNode.NEED_NOTHING_ACTIVATION;
        }
    }"
https://github.com/apache/derby/tree/eea0d50c8d732cad9ba563ddfa786b7028eb092f//java/engine/org/apache/derby/impl/sql/compile/SetSchemaNode.java,activationKind,close,"int activationKind()
	{
		Vector parameterList = getCompilerContext().getParameterList();
		/*
		** We need parameters 
		** only for those that have parameters.
		*/
		if (type == StatementType.SET_SCHEMA_DYNAMIC)
		{
			return StatementNode.NEED_PARAM_ACTIVATION;
		}
		else
		{
			return StatementNode.NEED_NOTHING_ACTIVATION;
		}
	}"
https://github.com/apache/derby/tree/eea0d50c8d732cad9ba563ddfa786b7028eb092f//java/engine/org/apache/derby/impl/sql/compile/SpecialFunctionNode.java,bindExpression,open,"public ValueNode bindExpression(FromList fromList, SubqueryList subqueryList,
							Vector	aggregateVector)
					throws StandardException
	{		DataTypeDescriptor dtd;
		int nodeType = getNodeType();
		switch (nodeType)
		{
		case C_NodeTypes.USER_NODE:
		case C_NodeTypes.CURRENT_USER_NODE:
		case C_NodeTypes.SYSTEM_USER_NODE:
			switch (nodeType)
			{
				case C_NodeTypes.USER_NODE: sqlName = ""USER""; break;
				case C_NodeTypes.CURRENT_USER_NODE: sqlName = ""CURRENT_USER""; break;
				case C_NodeTypes.SYSTEM_USER_NODE: sqlName = ""SYSTEM_USER""; break;
			}
            methodName = ""getCurrentUserId"";
			methodType = ""java.lang.String"";
            
			//SQL spec Section 6.4 Syntax Rule 4 says that the collation type 
			//of these functions will be the collation of character set 
			//SQL_IDENTIFIER. In Derby's case, that will mean, the collation of
			//these functions will be UCS_BASIC. The collation derivation will 
			//be implicit. 
            dtd = DataDictionary.TYPE_SYSTEM_IDENTIFIER;
			break;

        case C_NodeTypes.SESSION_USER_NODE:
            methodName = ""getSessionUserId"";
            methodType = ""java.lang.String"";
            sqlName = ""SESSION_USER"";
            dtd = DataDictionary.TYPE_SYSTEM_IDENTIFIER;
            break;

		case C_NodeTypes.CURRENT_SCHEMA_NODE:
			sqlName = ""CURRENT SCHEMA"";
			methodName = ""getCurrentSchemaName"";
			methodType = ""java.lang.String"";
			
			//This is a Derby specific function but its collation type will
			//be based on the same rules as for SESSION_USER/CURRENT_USER etc. 
			//ie there collation type will be UCS_BASIC. The collation 
			//derivation will be implicit. 
            dtd = DataDictionary.TYPE_SYSTEM_IDENTIFIER;
			break;

		case C_NodeTypes.CURRENT_ROLE_NODE:
			sqlName = ""CURRENT_ROLE"";
			methodName = ""getCurrentRoleIdDelimited"";
			methodType = ""java.lang.String"";
			dtd = DataTypeDescriptor.getBuiltInDataTypeDescriptor(
				// size: 2+(2*128) start and end text quote plus max # of
				// escapes
				Types.VARCHAR, true, 2+(2*128)); 
			//SQL spec Section 6.4 Syntax Rule 4 says that the collation type
			//of these functions will be the collation of character set
			//SQL_IDENTIFIER. In Derby's case, that will mean, the collation of
			//these functions will be UCS_BASIC. The collation derivation will
			//be implicit. (set by default)
			break;

		case C_NodeTypes.IDENTITY_VAL_NODE:
			sqlName = ""IDENTITY_VAL_LOCAL"";
			methodName = ""getIdentityValue"";
			methodType = ""java.lang.Long"";
			dtd = DataTypeDescriptor.getSQLDataTypeDescriptor(""java.math.BigDecimal"", 31, 0, true, 31);
			break;

		case C_NodeTypes.CURRENT_ISOLATION_NODE:
			sqlName = ""CURRENT ISOLATION"";
			methodName = ""getCurrentIsolationLevelStr"";
			methodType = ""java.lang.String"";
			dtd = DataTypeDescriptor.getBuiltInDataTypeDescriptor(Types.CHAR, 2);
			//This is a Derby specific function but it's collation type will
			//be based on the same rules as for SESSION_USER/CURRENT_USER etc. 
			//ie there collation type will be UCS_BASIC. The collation 
			//derivation will be implicit. (set by default).
			break;
		default:
			if (SanityManager.DEBUG)
			{
				SanityManager.THROWASSERT(""Invalid type for SpecialFunctionNode "" + nodeType);
			}
			dtd = null;
			break;
		}

		checkReliability(sqlName, CompilerContext.USER_ILLEGAL );
		setType(dtd);

		return this;
	}"
https://github.com/apache/derby/tree/eea0d50c8d732cad9ba563ddfa786b7028eb092f//java/engine/org/apache/derby/impl/sql/compile/SpecialFunctionNode.java,generateExpression,open,"public void generateExpression(ExpressionClassBuilder acb,
											MethodBuilder mb)
									throws StandardException
	{
		mb.pushThis();
		mb.callMethod(VMOpcode.INVOKEINTERFACE, ClassName.Activation, ""getLanguageConnectionContext"",
											 ClassName.LanguageConnectionContext, 0);
		int argCount = 0;

		if (methodName.equals(""getCurrentRoleIdDelimited"") ||
                methodName.equals(""getCurrentSchemaName"") ||
                methodName.equals(""getCurrentUserId"")) {

			acb.pushThisAsActivation(mb);
			argCount++;
		}

		mb.callMethod(VMOpcode.INVOKEINTERFACE,
					  (String) null, methodName, methodType, argCount);

		String fieldType = getTypeCompiler().interfaceName();
		LocalField field = acb.newFieldDeclaration(Modifier.PRIVATE, fieldType);

		acb.generateDataValue(mb, getTypeCompiler(), 
				getTypeServices().getCollationType(), field);
	}"
https://github.com/apache/derby/tree/eea0d50c8d732cad9ba563ddfa786b7028eb092f//java/engine/org/apache/derby/impl/sql/compile/SpecialFunctionNode.java,isEquivalent,open,"protected boolean isEquivalent(ValueNode o)
	{
		if (isSameNodeType(o))
		{
			SpecialFunctionNode other = (SpecialFunctionNode)o;
			return methodName.equals(other.methodName);
		}
		return false;
	}"
https://github.com/apache/derby/tree/eea0d50c8d732cad9ba563ddfa786b7028eb092f//java/engine/org/apache/derby/impl/sql/compile/SubqueryNode.java,changeToCorrespondingExpressionType,close,"private void changeToCorrespondingExpressionType()
		throws StandardException
	{
  		BinaryOperatorNode bcon = null;

  		switch (subqueryType)
  		{
  			case EQ_ANY_SUBQUERY:
  			case IN_SUBQUERY:
  				bcon = (BinaryOperatorNode) getNodeFactory().getNode(
  									C_NodeTypes.BINARY_EQUALS_OPERATOR_NODE,
  									leftOperand,
  									this,
  									getContextManager());
  				break;

  			case NE_ANY_SUBQUERY:
  				bcon = (BinaryOperatorNode) getNodeFactory().getNode(
  								C_NodeTypes.BINARY_NOT_EQUALS_OPERATOR_NODE,
  								leftOperand,
  								this,
  								getContextManager());
  				break;

  			case LE_ANY_SUBQUERY:
  				bcon = (BinaryOperatorNode) getNodeFactory().getNode(
  								C_NodeTypes.BINARY_LESS_EQUALS_OPERATOR_NODE,
  								leftOperand,
  								this,
  								getContextManager());
  				break;

  			case LT_ANY_SUBQUERY:
  				bcon = (BinaryOperatorNode) getNodeFactory().getNode(
  							C_NodeTypes.BINARY_LESS_THAN_OPERATOR_NODE,
  							leftOperand,
  							this,
  							getContextManager());
  				break;

  			case GE_ANY_SUBQUERY:
  				bcon = (BinaryOperatorNode) getNodeFactory().getNode(
  							C_NodeTypes.BINARY_GREATER_EQUALS_OPERATOR_NODE,
  							leftOperand,
  							this,
  							getContextManager());
  				break;

  			case GT_ANY_SUBQUERY:
  				bcon = (BinaryOperatorNode) getNodeFactory().getNode(
  								C_NodeTypes.BINARY_GREATER_THAN_OPERATOR_NODE,
  								leftOperand,
  								this,
  								getContextManager());
  				break;
  		}

  		// clean up the state of the tree to reflect a bound expression subquery
  		subqueryType = EXPRESSION_SUBQUERY;
  		setDataTypeServices(resultSet.getResultColumns());

  		parentComparisonOperator = (BinaryComparisonOperatorNode) bcon;
  		/* Set type info for the operator node */
  		parentComparisonOperator.bindComparisonOperator();
  		leftOperand = null;
   }"
https://github.com/apache/derby/tree/eea0d50c8d732cad9ba563ddfa786b7028eb092f//java/engine/org/apache/derby/impl/sql/compile/SubqueryNode.java,pushNewPredicate,close,"private UnaryComparisonOperatorNode pushNewPredicate(
				int numTables)
			throws StandardException
	{
		AndNode						andNode;
		BinaryComparisonOperatorNode bcoNode = null;
		JBitSet						tableMap;
		Predicate					predicate;
		ResultColumn				firstRC;
		ResultColumnList			resultColumns;
		UnaryComparisonOperatorNode	ucoNode = null;
		ValueNode					oldWhereClause;
		ValueNode					rightOperand;

		/* We have to ensure that the resultSet immediately under us has
		 * a PredicateList, otherwise we can't push the predicate down.
		 */
		resultSet = resultSet.ensurePredicateList(numTables);

		/* RESOLVE - once we understand how correlated columns will work, 
		 * we probably want to mark leftOperand as a correlated column
		 */
		resultColumns = resultSet.getResultColumns();

		/*
		** Create a new PR node.  Put it over the original subquery.  resulSet
		** is now the new PR.  We give the chance that things under the PR node
		** can be materialized.  See beetle 4373.
		*/
		ResultColumnList newRCL = resultColumns.copyListAndObjects();
		newRCL.genVirtualColumnNodes(resultSet, resultColumns);
		resultSet = (ResultSetNode) getNodeFactory().getNode(
										C_NodeTypes.PROJECT_RESTRICT_NODE,
										resultSet,	// child
										newRCL,			// result columns
										null,			// restriction
										null, 			// restriction list
										null,			// project subqueries
										null,			// restrict subqueries	
										null,
										getContextManager());
		resultColumns = newRCL;
	
		firstRC = (ResultColumn) resultColumns.elementAt(0);
		rightOperand = firstRC.getExpression();

		bcoNode = getNewJoinCondition(leftOperand, rightOperand);

		ValueNode andLeft = bcoNode;

		/* For NOT IN or ALL, and if either side of the comparison is nullable, and the
		 * subquery can not be flattened (because of that), we need to add IS NULL node
		 * on top of the nullables, such that the behavior is (beetle 5173):
		 *
		 *    (1) If we have nulls in right operand, no row is returned.
		 *    (2) If subquery result is empty before applying join predicate, every
		 *		  left row (including NULLs) is returned.
		 *	  (3) Otherwise, return {all left row} - {NULLs}
		 */
		if (isNOT_IN() || isALL())
		{
			boolean leftNullable = leftOperand.getTypeServices().isNullable();
			boolean rightNullable = rightOperand.getTypeServices().isNullable();
			if (leftNullable || rightNullable)
			{
				/* Create a normalized structure.
				 */
				BooleanConstantNode falseNode = (BooleanConstantNode) getNodeFactory().getNode(
												C_NodeTypes.BOOLEAN_CONSTANT_NODE,
												Boolean.FALSE,
												getContextManager());
				OrNode newOr = (OrNode) getNodeFactory().getNode(
												C_NodeTypes.OR_NODE,
												bcoNode,
												falseNode,
												getContextManager());
				newOr.postBindFixup();
				andLeft = newOr;

				if (leftNullable)
				{
					UnaryComparisonOperatorNode leftIsNull = (UnaryComparisonOperatorNode)
									getNodeFactory().getNode(
														C_NodeTypes.IS_NULL_NODE,
														leftOperand,
														getContextManager());
					leftIsNull.bindComparisonOperator();
					newOr = (OrNode) getNodeFactory().getNode(
													C_NodeTypes.OR_NODE,
													leftIsNull,
													andLeft,
													getContextManager());
					newOr.postBindFixup();
					andLeft = newOr;
				}
				if (rightNullable)
				{
					UnaryComparisonOperatorNode rightIsNull = (UnaryComparisonOperatorNode)
									getNodeFactory().getNode(
														C_NodeTypes.IS_NULL_NODE,
														rightOperand,
														getContextManager());
					rightIsNull.bindComparisonOperator();
					newOr = (OrNode) getNodeFactory().getNode(
													C_NodeTypes.OR_NODE,
													rightIsNull,
													andLeft,
													getContextManager());
					newOr.postBindFixup();
					andLeft = newOr;
				}
			}
		}

		/* Place an AndNode above the <BinaryComparisonOperator> */
		andNode = (AndNode) getNodeFactory().getNode(
													C_NodeTypes.AND_NODE,
													andLeft,
													getTrueNode(),
													getContextManager());

		/* Build the referenced table map for the new predicate */
		tableMap = new JBitSet(numTables);
		andNode.postBindFixup();

		/* Put the AndNode under a Predicate */
		predicate = (Predicate) getNodeFactory().getNode(
										C_NodeTypes.PREDICATE,
										andNode,
										tableMap,
										getContextManager());
		predicate.categorize();

		/* Push the new Predicate to the subquery's list */
		resultSet = resultSet.addNewPredicate(predicate);

		/* Clean up the leftOperand and subquery ResultColumn */
		leftOperand = null;
		firstRC.setType(getTypeServices());
		firstRC.setExpression(getTrueNode());

		/* Add the IS [NOT] NULL above the SubqueryNode */
		switch (subqueryType)
		{
			case IN_SUBQUERY:
			case EQ_ANY_SUBQUERY:
			case NE_ANY_SUBQUERY:
			case LE_ANY_SUBQUERY:
			case LT_ANY_SUBQUERY:
			case GE_ANY_SUBQUERY:
			case GT_ANY_SUBQUERY:
				ucoNode = (UnaryComparisonOperatorNode) 
									getNodeFactory().getNode(
												C_NodeTypes.IS_NOT_NULL_NODE,
												this,
												getContextManager());
				break;

			case NOT_IN_SUBQUERY:
			case EQ_ALL_SUBQUERY:
			case NE_ALL_SUBQUERY:
			case LE_ALL_SUBQUERY:
			case LT_ALL_SUBQUERY:
			case GE_ALL_SUBQUERY:
			case GT_ALL_SUBQUERY:
				ucoNode = (UnaryComparisonOperatorNode) 
									getNodeFactory().getNode(
													C_NodeTypes.IS_NULL_NODE,
													this,
													getContextManager());
				break;
		}
		ucoNode.bindComparisonOperator();
		return ucoNode;
	}"
https://github.com/apache/derby/tree/eea0d50c8d732cad9ba563ddfa786b7028eb092f//java/engine/org/apache/derby/impl/sql/compile/TableElementList.java,genConstraintActions,open,"void genConstraintActions(boolean forCreateTable,
				ConstraintConstantAction[] conActions,
				String tableName,
				SchemaDescriptor tableSd,
				DataDictionary dd)
		throws StandardException
	{
		int size = size();
		int conActionIndex = 0;
		for (int index = 0; index < size; index++)
		{
			String[]	columnNames = null;
			TableElementNode ten = (TableElementNode) elementAt(index);
			IndexConstantAction indexAction = null;

			if (! ten.hasConstraint())
			{
				continue;
			}

			if (ten instanceof ColumnDefinitionNode)
			{
				continue;
			}

			ConstraintDefinitionNode constraintDN = (ConstraintDefinitionNode) ten;

			if (constraintDN.getColumnList() != null)
			{
				columnNames = new String[constraintDN.getColumnList().size()];
				constraintDN.getColumnList().exportNames(columnNames);
			}

			int constraintType = constraintDN.getConstraintType();
			String constraintText = constraintDN.getConstraintText();

			/*
			** If the constraint is not named (e.g.
			** create table x (x int primary key)), then
			** the constraintSd is the same as the table.
			*/
			String constraintName = constraintDN.getConstraintMoniker();

			/* At execution time, we will generate a unique name for the backing
			 * index (for CREATE CONSTRAINT) and we will look up the conglomerate
			 * name (for DROP CONSTRAINT).
			 */
			if (constraintDN.requiresBackingIndex())
			{
                // implement unique constraints using a unique backing index 
                // unless it is soft upgrade in version before 10.4, or if 
                // constraint contains no nullable columns.  In 10.4 use 
                // ""unique with duplicate null"" backing index for constraints 
                // that contain at least one nullable column.

				if (constraintDN.constraintType ==
					DataDictionary.UNIQUE_CONSTRAINT && 
					(dd.checkVersion(
                         DataDictionary.DD_VERSION_DERBY_10_4, null))) 
                {
                    boolean contains_nullable_columns = 
                        areColumnsNullable(constraintDN, td);

                    // if all the columns are non nullable, continue to use
                    // a unique backing index.
                    boolean unique = 
                        !contains_nullable_columns;

                    // Only use a ""unique with duplicate nulls"" backing index
                    // for constraints with nullable columns.
                    boolean uniqueWithDuplicateNulls = 
                        contains_nullable_columns;

					indexAction = genIndexAction(
						forCreateTable,
						unique,
                        uniqueWithDuplicateNulls,
						null, constraintDN,
						columnNames, true, tableSd, tableName,
						constraintType, dd);
				} 
                else 
                {
					indexAction = genIndexAction(
						forCreateTable,
						constraintDN.requiresUniqueIndex(), false,
						null, constraintDN,
						columnNames, true, tableSd, tableName,
						constraintType, dd);
				}
			}

			if (constraintType == DataDictionary.DROP_CONSTRAINT)
			{
                if (SanityManager.DEBUG)
                {
                    // Can't drop constraints on a create table.
                    SanityManager.ASSERT(!forCreateTable);
                }
				conActions[conActionIndex] = 
					getGenericConstantActionFactory().
						getDropConstraintConstantAction(
												 constraintName, 
												 constraintDN.getDropSchemaName(), /// FiX
												 tableName,
												 td.getUUID(),
												 tableSd.getSchemaName(),
												 indexAction,
												 constraintDN.getDropBehavior(),
                                                 constraintDN.getVerifyType());
			}
			else
			{
				ProviderList apl = constraintDN.getAuxiliaryProviderList();
				ConstraintInfo refInfo = null;
				ProviderInfo[]	providerInfos = null;

				if (constraintDN instanceof FKConstraintDefinitionNode)
				{
					refInfo = ((FKConstraintDefinitionNode)constraintDN).getReferencedConstraintInfo();
				}				

				/* Create the ProviderInfos, if the constraint is dependent on any Providers */
				if (apl != null && apl.size() > 0)
				{
					/* Get all the dependencies for the current statement and transfer
					 * them to this view.
					 */
					DependencyManager dm = dd.getDependencyManager();
					providerInfos = dm.getPersistentProviderInfos(apl);
				}
				else
				{
					providerInfos = new ProviderInfo[0];
					// System.out.println(""TABLE ELEMENT LIST EMPTY"");
				}

				conActions[conActionIndex++] = 
					getGenericConstantActionFactory().
						getCreateConstraintConstantAction(
												 constraintName, 
											     constraintType,
                                                 forCreateTable,
												 tableName, 
												 ((td != null) ? td.getUUID() : (UUID) null),
												 tableSd.getSchemaName(),
												 columnNames,
												 indexAction,
												 constraintText,
												 true, 		// enabled
												 refInfo,
												 providerInfos);
			}
		}
	}"
https://github.com/apache/derby/tree/eea0d50c8d732cad9ba563ddfa786b7028eb092f//java/engine/org/apache/derby/impl/sql/compile/TableElementList.java,validate,open,"void validate(DDLStatementNode ddlStmt,
					     DataDictionary dd,
						 TableDescriptor td)
					throws StandardException
	{
 		this.td = td;
		int numAutoCols = 0;

		int			size = size();
		Hashtable	columnHT = new Hashtable(size + 2, (float) .999);
		Hashtable	constraintHT = new Hashtable(size + 2, (float) .999);
		//all the primary key/unique key constraints for this table
		Vector constraintsVector = new Vector();

		//special case for alter table (td is not null in case of alter table)
		if (td != null)
		{
			//In case of alter table, get the already existing primary key and unique
			//key constraints for this table. And then we will compare them with  new
			//primary key/unique key constraint column lists.
			ConstraintDescriptorList cdl = dd.getConstraintDescriptors(td);
			ConstraintDescriptor cd;

			if (cdl != null) //table does have some pre-existing constraints defined on it
			{
				for (int i=0; i<cdl.size();i++)
				{
					cd = cdl.elementAt(i);
					//if the constraint type is not primary key or unique key, ignore it.
					if (cd.getConstraintType() == DataDictionary.PRIMARYKEY_CONSTRAINT ||
					cd.getConstraintType() == DataDictionary.UNIQUE_CONSTRAINT)
						constraintsVector.addElement(cd);
				}
			}
		}

		int tableType = TableDescriptor.BASE_TABLE_TYPE;
		if (ddlStmt instanceof CreateTableNode)
			tableType = ((CreateTableNode)ddlStmt).tableType;

		for (int index = 0; index < size; index++)
		{
			TableElementNode tableElement = (TableElementNode) elementAt(index);

			if (tableElement instanceof ColumnDefinitionNode)
			{
				ColumnDefinitionNode cdn = (ColumnDefinitionNode) elementAt(index);
				if (tableType == TableDescriptor.GLOBAL_TEMPORARY_TABLE_TYPE &&
					(cdn.getType().getTypeId().isLongConcatableTypeId() ||
					cdn.getType().getTypeId().isUserDefinedTypeId()))
				{
					throw StandardException.newException(SQLState.LANG_LONG_DATA_TYPE_NOT_ALLOWED, cdn.getColumnName());
				}
				checkForDuplicateColumns(ddlStmt, columnHT, cdn.getColumnName());
				cdn.checkUserType(td);
				cdn.bindAndValidateDefault(dd, td);

				cdn.validateAutoincrement(dd, td, tableType);

				if (tableElement instanceof ModifyColumnNode)
				{
					ModifyColumnNode mcdn = (ModifyColumnNode)cdn;
					mcdn.checkExistingConstraints(td);
					mcdn.useExistingCollation(td);

				} else if (cdn.isAutoincrementColumn())
                { numAutoCols ++; }
			}
			else if (tableElement.getElementType() == TableElementNode.AT_DROP_COLUMN)
			{
				String colName = tableElement.getName();
				if (td.getColumnDescriptor(colName) == null)
				{
					throw StandardException.newException(
												SQLState.LANG_COLUMN_NOT_FOUND_IN_TABLE,
												colName,
												td.getQualifiedName());
				}
				break;
			}

			/* The rest of this method deals with validating constraints */
			if (! (tableElement.hasConstraint()))
			{
				continue;
			}

			ConstraintDefinitionNode cdn = (ConstraintDefinitionNode) tableElement;

			cdn.bind(ddlStmt, dd);

			//if constraint is primary key or unique key, add it to the vector
			if (cdn.getConstraintType() == DataDictionary.PRIMARYKEY_CONSTRAINT ||
			cdn.getConstraintType() == DataDictionary.UNIQUE_CONSTRAINT)
			{
				/* In case of create table, the vector can have only ConstraintDefinitionNode
				* elements. In case of alter table, it can have both ConstraintDefinitionNode
				* (for new constraints) and ConstraintDescriptor(for pre-existing constraints).
				*/

				Object destConstraint;
				String destName = null;
				String[] destColumnNames = null;

				for (int i=0; i<constraintsVector.size();i++)
				{

					destConstraint = constraintsVector.elementAt(i);
					if (destConstraint instanceof ConstraintDefinitionNode)
					{
						ConstraintDefinitionNode destCDN = (ConstraintDefinitionNode)destConstraint;
						destName = destCDN.getConstraintMoniker();
						destColumnNames = destCDN.getColumnList().getColumnNames();
					}
					else if (destConstraint instanceof ConstraintDescriptor)
					{
						//will come here only for pre-existing constraints in case of alter table
						ConstraintDescriptor destCD = (ConstraintDescriptor)destConstraint;
						destName = destCD.getConstraintName();
						destColumnNames = destCD.getColumnDescriptors().getColumnNames();
					}
					//check if there are multiple constraints with same set of columns
					if (columnsMatch(cdn.getColumnList().getColumnNames(), destColumnNames))
						throw StandardException.newException(SQLState.LANG_MULTIPLE_CONSTRAINTS_WITH_SAME_COLUMNS,
						cdn.getConstraintMoniker(), destName);
				}
				constraintsVector.addElement(cdn);
			}

			/* Make sure that there are no duplicate constraint names in the list */
            checkForDuplicateConstraintNames(ddlStmt, constraintHT, cdn.getConstraintMoniker());

			/* Make sure that the constraint we are trying to drop exists */
			if (cdn.getConstraintType() == DataDictionary.DROP_CONSTRAINT)
			{
				/*
				** If no schema descriptor, then must be an invalid
				** schema name.
				*/

				String dropConstraintName = cdn.getConstraintMoniker();

				if (dropConstraintName != null) {

					String dropSchemaName = cdn.getDropSchemaName();

					SchemaDescriptor sd = dropSchemaName == null ? td.getSchemaDescriptor() :
											getSchemaDescriptor(dropSchemaName);

					ConstraintDescriptor cd =
								dd.getConstraintDescriptorByName(
										td, sd, dropConstraintName,
										false);
					if (cd == null)
					{
						throw StandardException.newException(SQLState.LANG_DROP_NON_EXISTENT_CONSTRAINT,
								(sd.getSchemaName() + "".""+ dropConstraintName),
								td.getQualifiedName());
					}
					/* Statement is dependendent on the ConstraintDescriptor */
					getCompilerContext().createDependency(cd);
				}
			}

            // validation of primary key nullability moved to validatePrimaryKeyNullability().
            if (cdn.hasPrimaryKeyConstraint())
            {
                // for PRIMARY KEY, check that columns are unique
                verifyUniqueColumnList(ddlStmt, cdn);
            }
            else if (cdn.hasUniqueKeyConstraint())
            {
                // for UNIQUE, check that columns are unique
                verifyUniqueColumnList(ddlStmt, cdn);

                // unique constraints on nullable columns added in 10.4, 
                // disallow until database hard upgraded at least to 10.4.
                if (!dd.checkVersion(
                        DataDictionary.DD_VERSION_DERBY_10_4, null))
                {
                    checkForNullColumns(cdn, td);
                }
            }
            else if (cdn.hasForeignKeyConstraint())
            {
                // for FOREIGN KEY, check that columns are unique
                verifyUniqueColumnList(ddlStmt, cdn);
            }
		}

		/* Can have only one autoincrement column in DB2 mode */
		if (numAutoCols > 1)
			throw StandardException.newException(SQLState.LANG_MULTIPLE_AUTOINCREMENT_COLUMNS);

	}"
https://github.com/apache/derby/tree/eea0d50c8d732cad9ba563ddfa786b7028eb092f//java/engine/org/apache/derby/impl/sql/compile/TableElementList.java,validate,open,"void validate(DDLStatementNode ddlStmt,
					     DataDictionary dd,
						 TableDescriptor td)
					throws StandardException
	{
 		this.td = td;
		int numAutoCols = 0;

		int			size = size();
		Hashtable	columnHT = new Hashtable(size + 2, (float) .999);
		Hashtable	constraintHT = new Hashtable(size + 2, (float) .999);
		//all the primary key/unique key constraints for this table
		Vector constraintsVector = new Vector();

		//special case for alter table (td is not null in case of alter table)
		if (td != null)
		{
			//In case of alter table, get the already existing primary key and unique
			//key constraints for this table. And then we will compare them with  new
			//primary key/unique key constraint column lists.
			ConstraintDescriptorList cdl = dd.getConstraintDescriptors(td);
			ConstraintDescriptor cd;

			if (cdl != null) //table does have some pre-existing constraints defined on it
			{
				for (int i=0; i<cdl.size();i++)
				{
					cd = cdl.elementAt(i);
					//if the constraint type is not primary key or unique key, ignore it.
					if (cd.getConstraintType() == DataDictionary.PRIMARYKEY_CONSTRAINT ||
					cd.getConstraintType() == DataDictionary.UNIQUE_CONSTRAINT)
						constraintsVector.addElement(cd);
				}
			}
		}

		int tableType = TableDescriptor.BASE_TABLE_TYPE;
		if (ddlStmt instanceof CreateTableNode)
			tableType = ((CreateTableNode)ddlStmt).tableType;

		for (int index = 0; index < size; index++)
		{
			TableElementNode tableElement = (TableElementNode) elementAt(index);

			if (tableElement instanceof ColumnDefinitionNode)
			{
				ColumnDefinitionNode cdn = (ColumnDefinitionNode) elementAt(index);
				if (tableType == TableDescriptor.GLOBAL_TEMPORARY_TABLE_TYPE &&
					(cdn.getType().getTypeId().isLongConcatableTypeId() ||
					cdn.getType().getTypeId().isUserDefinedTypeId()))
				{
					throw StandardException.newException(SQLState.LANG_LONG_DATA_TYPE_NOT_ALLOWED, cdn.getColumnName());
				}
				checkForDuplicateColumns(ddlStmt, columnHT, cdn.getColumnName());
				cdn.checkUserType(td);
				cdn.bindAndValidateDefault(dd, td);

				cdn.validateAutoincrement(dd, td, tableType);

				if (tableElement instanceof ModifyColumnNode)
				{
					ModifyColumnNode mcdn = (ModifyColumnNode)cdn;
					mcdn.checkExistingConstraints(td);
					mcdn.useExistingCollation(td);

				} else if (cdn.isAutoincrementColumn())
                { numAutoCols ++; }
			}
			else if (tableElement.getElementType() == TableElementNode.AT_DROP_COLUMN)
			{
				String colName = tableElement.getName();
				if (td.getColumnDescriptor(colName) == null)
				{
					throw StandardException.newException(
												SQLState.LANG_COLUMN_NOT_FOUND_IN_TABLE,
												colName,
												td.getQualifiedName());
				}
				break;
			}

			/* The rest of this method deals with validating constraints */
			if (! (tableElement.hasConstraint()))
			{
				continue;
			}

			ConstraintDefinitionNode cdn = (ConstraintDefinitionNode) tableElement;

			cdn.bind(ddlStmt, dd);

			//if constraint is primary key or unique key, add it to the vector
			if (cdn.getConstraintType() == DataDictionary.PRIMARYKEY_CONSTRAINT ||
			cdn.getConstraintType() == DataDictionary.UNIQUE_CONSTRAINT)
			{
				/* In case of create table, the vector can have only ConstraintDefinitionNode
				* elements. In case of alter table, it can have both ConstraintDefinitionNode
				* (for new constraints) and ConstraintDescriptor(for pre-existing constraints).
				*/

				Object destConstraint;
				String destName = null;
				String[] destColumnNames = null;

				for (int i=0; i<constraintsVector.size();i++)
				{

					destConstraint = constraintsVector.elementAt(i);
					if (destConstraint instanceof ConstraintDefinitionNode)
					{
						ConstraintDefinitionNode destCDN = (ConstraintDefinitionNode)destConstraint;
						destName = destCDN.getConstraintMoniker();
						destColumnNames = destCDN.getColumnList().getColumnNames();
					}
					else if (destConstraint instanceof ConstraintDescriptor)
					{
						//will come here only for pre-existing constraints in case of alter table
						ConstraintDescriptor destCD = (ConstraintDescriptor)destConstraint;
						destName = destCD.getConstraintName();
						destColumnNames = destCD.getColumnDescriptors().getColumnNames();
					}
					//check if there are multiple constraints with same set of columns
					if (columnsMatch(cdn.getColumnList().getColumnNames(), destColumnNames))
						throw StandardException.newException(SQLState.LANG_MULTIPLE_CONSTRAINTS_WITH_SAME_COLUMNS,
						cdn.getConstraintMoniker(), destName);
				}
				constraintsVector.addElement(cdn);
			}

			/* Make sure that there are no duplicate constraint names in the list */
            checkForDuplicateConstraintNames(ddlStmt, constraintHT, cdn.getConstraintMoniker());

			/* Make sure that the constraint we are trying to drop exists */
			if (cdn.getConstraintType() == DataDictionary.DROP_CONSTRAINT)
			{
				/*
				** If no schema descriptor, then must be an invalid
				** schema name.
				*/

				String dropConstraintName = cdn.getConstraintMoniker();

				if (dropConstraintName != null) {

					String dropSchemaName = cdn.getDropSchemaName();

					SchemaDescriptor sd = dropSchemaName == null ? td.getSchemaDescriptor() :
											getSchemaDescriptor(dropSchemaName);

					ConstraintDescriptor cd =
								dd.getConstraintDescriptorByName(
										td, sd, dropConstraintName,
										false);
					if (cd == null)
					{
						throw StandardException.newException(SQLState.LANG_DROP_NON_EXISTENT_CONSTRAINT,
								(sd.getSchemaName() + "".""+ dropConstraintName),
								td.getQualifiedName());
					}
					/* Statement is dependendent on the ConstraintDescriptor */
					getCompilerContext().createDependency(cd);
				}
			}

            // validation of primary key nullability moved to validatePrimaryKeyNullability().
            if (cdn.hasPrimaryKeyConstraint())
            {
                // for PRIMARY KEY, check that columns are unique
                verifyUniqueColumnList(ddlStmt, cdn);
            }
            else if (cdn.hasUniqueKeyConstraint())
            {
                // for UNIQUE, check that columns are unique
                verifyUniqueColumnList(ddlStmt, cdn);

                // unique constraints on nullable columns added in 10.4, 
                // disallow until database hard upgraded at least to 10.4.
                if (!dd.checkVersion(
                        DataDictionary.DD_VERSION_DERBY_10_4, null))
                {
                    checkForNullColumns(cdn, td);
                }
            }
            else if (cdn.hasForeignKeyConstraint())
            {
                // for FOREIGN KEY, check that columns are unique
                verifyUniqueColumnList(ddlStmt, cdn);
            }
		}

		/* Can have only one autoincrement column in DB2 mode */
		if (numAutoCols > 1)
			throw StandardException.newException(SQLState.LANG_MULTIPLE_AUTOINCREMENT_COLUMNS);

	}"
https://github.com/apache/derby/tree/eea0d50c8d732cad9ba563ddfa786b7028eb092f//java/engine/org/apache/derby/impl/sql/compile/TableElementList.java,setCollationTypesOnCharacterStringColumns,close,"void setCollationTypesOnCharacterStringColumns(SchemaDescriptor sd)
        throws StandardException
    {
		int			size = size();
		int collationType = sd.getCollationType();
		for (int index = 0; index < size; index++)
		{
			TableElementNode tableElement = (TableElementNode) elementAt(index);

			if (tableElement instanceof ColumnDefinitionNode)
			{
				ColumnDefinitionNode cdn = (ColumnDefinitionNode) elementAt(index);

                setCollationTypeOnCharacterStringColumn( sd, cdn );
			}
		}
	}"
https://github.com/apache/derby/tree/eea0d50c8d732cad9ba563ddfa786b7028eb092f//java/engine/org/apache/derby/impl/sql/compile/TypeCompilerFactoryImpl.java,staticGetTypeCompiler,open,"static TypeCompiler staticGetTypeCompiler(TypeId typeId)
        {
                String sqlTypeName;

                switch (typeId.getJDBCTypeId())
                {
                  case Types.BINARY:
                        return bitTypeCompiler =
                                        getAnInstance(PACKAGE_NAME + ""BitTypeCompiler"",
                                                                        bitTypeCompiler,
                                                                        typeId);

                  case Types.BIT:
                  case Types.BOOLEAN:
                        return booleanTypeCompiler =
                                        getAnInstance(PACKAGE_NAME + ""BooleanTypeCompiler"",
                                                                booleanTypeCompiler,
                                                                typeId);

                  case Types.CHAR:
                          sqlTypeName = typeId.getSQLTypeName();
                          return charTypeCompiler =
                              getAnInstance(PACKAGE_NAME + ""CharTypeCompiler"",
                                                      charTypeCompiler,
                                                      typeId);

                  case Types.NUMERIC:
                  case Types.DECIMAL:
                        return decimalTypeCompiler =
                                getAnInstance(PACKAGE_NAME + ""NumericTypeCompiler"",
                                                                decimalTypeCompiler,
                                                                typeId);

                  case Types.DOUBLE:
                        return doubleTypeCompiler =
                                getAnInstance(PACKAGE_NAME + ""NumericTypeCompiler"",
                                                                doubleTypeCompiler,
                                                                typeId);

                  case Types.INTEGER:
                        return intTypeCompiler =
                                getAnInstance(PACKAGE_NAME + ""NumericTypeCompiler"",
                                                                intTypeCompiler,
                                                                typeId);

                  case Types.BIGINT:
                        return longintTypeCompiler =
                                getAnInstance(PACKAGE_NAME + ""NumericTypeCompiler"",
                                                                longintTypeCompiler,
                                                                typeId);

                  case Types.BLOB:
                        return blobTypeCompiler =
                                getAnInstance(PACKAGE_NAME + ""LOBTypeCompiler"",
                                                          blobTypeCompiler,
                                                          typeId);

                  case Types.LONGVARBINARY:
                        return longvarbitTypeCompiler =
                                getAnInstance(PACKAGE_NAME + ""BitTypeCompiler"",
                                                          longvarbitTypeCompiler,
                                                          typeId);

                  case Types.CLOB:
                      sqlTypeName = typeId.getSQLTypeName();
                      return clobTypeCompiler =
                          getAnInstance(PACKAGE_NAME + ""CLOBTypeCompiler"",
                                        clobTypeCompiler,
                                        typeId);
                  case Types.LONGVARCHAR:
                          sqlTypeName = typeId.getSQLTypeName();
                          return longvarcharTypeCompiler =
                              getAnInstance(PACKAGE_NAME + ""CharTypeCompiler"",
                                                      longvarcharTypeCompiler,
                                                      typeId);

                  case Types.REAL:
                        return realTypeCompiler =
                                getAnInstance(PACKAGE_NAME + ""NumericTypeCompiler"",
                                                                realTypeCompiler,
                                                                typeId);

                  case Types.SMALLINT:
                        return smallintTypeCompiler =
                                getAnInstance(PACKAGE_NAME + ""NumericTypeCompiler"",
                                                                smallintTypeCompiler,
                                                                typeId);

                  case Types.TINYINT:
                    return tinyintTypeCompiler =
                                getAnInstance(PACKAGE_NAME + ""NumericTypeCompiler"",
                                                                tinyintTypeCompiler,
                                                                typeId);

                  case Types.DATE:
                        return dateTypeCompiler =
                                        getAnInstance(PACKAGE_NAME + ""DateTypeCompiler"",
                                                                        dateTypeCompiler,
                                                                        typeId);

                  case Types.TIME:
                        return timeTypeCompiler =
                                        getAnInstance(PACKAGE_NAME + ""TimeTypeCompiler"",
                                                                        timeTypeCompiler,
                                                                        typeId);
                  case Types.TIMESTAMP:
                        return timestampTypeCompiler =
                                        getAnInstance(PACKAGE_NAME + ""TimestampTypeCompiler"",
                                                                        timestampTypeCompiler,
                                                                        typeId);
                  case Types.VARBINARY:
                        return varbitTypeCompiler =
                                getAnInstance(PACKAGE_NAME + ""BitTypeCompiler"",
                                                                varbitTypeCompiler,
                                                                typeId);

                  case Types.VARCHAR:
                          sqlTypeName = typeId.getSQLTypeName();
                          return varcharTypeCompiler =
                              getAnInstance(PACKAGE_NAME + ""CharTypeCompiler"",
                                                      varcharTypeCompiler,
                                                      typeId);

                  case Types.JAVA_OBJECT:
                  case Types.OTHER:
                        if (typeId.isRefTypeId())
                        {
                                return refTypeCompiler = getAnInstance(
                                                                                        PACKAGE_NAME + ""RefTypeCompiler"",
                                                                                        refTypeCompiler,
                                                                                        typeId);
                        }
                        else
                        {
                                // Cannot re-use instances of user-defined type compilers,
                                // because they contain the class name
                                BaseTypeCompiler btc = new UserDefinedTypeCompiler();
                                btc.setTypeId(typeId);
                                return btc;
                        }

                  case JDBC40Translation.SQLXML:
                        return xmlTypeCompiler =
                                getAnInstance(PACKAGE_NAME + ""XMLTypeCompiler"",
                                                                xmlTypeCompiler,
                                                                typeId);

                }

                if (SanityManager.DEBUG)
                {
                        SanityManager.THROWASSERT(""Unexpected JDBC type id "" +
                                                                                typeId.getJDBCTypeId() +
                                                                                "" for typeId of class "" +
                                                                                typeId.getClass().getName());
                }

                return null;
        }"
https://github.com/apache/derby/tree/eea0d50c8d732cad9ba563ddfa786b7028eb092f//java/engine/org/apache/derby/impl/sql/compile/ValueNodeList.java,comparable,close,"public void comparable(ValueNode leftOperand) throws StandardException
	{
		int			 size = size();
		TypeId	leftType;
		ValueNode		valueNode;

		leftType = leftOperand.getTypeId();

		for (int index = 0; index < size; index++)
		{
			valueNode = (ValueNode) elementAt(index);

			/*
			** Can the types be compared to each other?  If not, throw an
			** exception.
			*/
			if (! leftOperand.getTypeServices().comparable(valueNode.getTypeServices(),
									false,
									getClassFactory()))
			{
				throw StandardException.newException(SQLState.LANG_NOT_COMPARABLE, 
						leftOperand.getTypeServices().getSQLTypeNameWithCollation(),
						valueNode.getTypeServices().getSQLTypeNameWithCollation()
						);
			}
		}
	}"
https://github.com/apache/derby/tree/eea0d50c8d732cad9ba563ddfa786b7028eb092f//java/engine/org/apache/derby/impl/sql/compile/WindowResultSetNode.java,addNewColumns,close,"private void addNewColumns() throws StandardException {
        /*
         * Now process all of the window function calls.  Replace every
         * call with an RC.  We toss out the list of RCs, we need to get
         * each RC as we process its corresponding window function.
         */
        LanguageFactory lf =
            getLanguageConnectionContext().getLanguageFactory();

        ResultColumnList bottomRCL  = childResult.getResultColumns();
        ResultColumnList windowingRCL = resultColumns;

        ReplaceWindowFuncCallsWithCRVisitor replaceCallsVisitor =
            new ReplaceWindowFuncCallsWithCRVisitor(
                (ResultColumnList) getNodeFactory().getNode(
                    C_NodeTypes.RESULT_COLUMN_LIST,
                    getContextManager()),
                ((FromTable) childResult).getTableNumber(),
                ResultSetNode.class);
        parent.getResultColumns().accept(replaceCallsVisitor);

        for (int i=0; i < windowFuncCalls.size(); i++) {
            WindowFunctionNode winFunc =
                (WindowFunctionNode)windowFuncCalls.elementAt(i);

            if (SanityManager.DEBUG) {
                SanityManager.ASSERT(
                    !(winFunc.getWindow() instanceof WindowReferenceNode),
                    ""unresolved window-reference: "" +
                    winFunc.getWindow().getName());
            }

            WindowDefinitionNode funcWindow =
                (WindowDefinitionNode)winFunc.getWindow();

            if (funcWindow == wdn) {
                ResultColumn newRC = (ResultColumn) getNodeFactory().getNode(
                    C_NodeTypes.RESULT_COLUMN,
                    ""##winFuncResult"",
                    winFunc.getNewNullResultExpression(),
                    getContextManager());

                newRC.markGenerated();
                newRC.bindResultColumnToExpression();
                bottomRCL.addElement(newRC);
                newRC.setVirtualColumnId(bottomRCL.size());
                int winFuncResultVColId = newRC.getVirtualColumnId();

                /*
                ** Set the WindowResultSetNode result column to point to this.
                ** The Windowing Node result was created when we called
                ** ReplaceWindowFuncCallsWithCRVisitor.
                */
                ColumnReference newColumnRef =
                    (ColumnReference) getNodeFactory().getNode(
                        C_NodeTypes.COLUMN_REFERENCE,
                        newRC.getName(),
                        null,
                        getContextManager());

                newColumnRef.setSource(newRC);
                newColumnRef.setNestingLevel(this.getLevel());
                newColumnRef.setSourceLevel(this.getLevel());
                newColumnRef.markGeneratedToReplaceWindowFunctionCall();

                ResultColumn tmpRC = (ResultColumn) getNodeFactory().getNode(
                    C_NodeTypes.RESULT_COLUMN,
                    newRC.getColumnName(),
                    newColumnRef,
                    getContextManager());

                tmpRC.markGenerated();
                tmpRC.bindResultColumnToExpression();
                windowingRCL.addElement(tmpRC);
                tmpRC.setVirtualColumnId(windowingRCL.size());

                /*
                ** Set the column reference to point to
                ** this.
                */
                newColumnRef = winFunc.getGeneratedRef();

                if (newColumnRef != null) {
                    newColumnRef.setSource(tmpRC);
                } // Not generated, meaning it's no longer in use
            }
        }
    }"
https://github.com/apache/derby/tree/eea0d50c8d732cad9ba563ddfa786b7028eb092f//java/engine/org/apache/derby/impl/sql/compile/WindowResultSetNode.java,addNewPRNode,close,"private void addNewPRNode()
        throws StandardException
    {
        /*
        ** Get the new PR, put above the WindowResultSetNode.
        */
        ResultColumnList rclNew = (ResultColumnList)getNodeFactory().
            getNode(C_NodeTypes.RESULT_COLUMN_LIST,
                    getContextManager());

        int sz = resultColumns.size();
        for (int i = 0; i < sz; i++)
        {
            ResultColumn rc = (ResultColumn) resultColumns.elementAt(i);
            if (!rc.isGenerated()) {
                rclNew.addElement(rc);
            }
        }

        // if any columns in the source RCL were generated for an order by
        // remember it in the new RCL as well. After the sort is done it will
        // have to be projected out upstream.
        rclNew.copyOrderBySelect(resultColumns);

        parent = (FromTable) getNodeFactory().getNode(
                                        C_NodeTypes.PROJECT_RESTRICT_NODE,
                                        this, // child
                                        rclNew,
                                        null, // havingClause,
                                        null, // restriction list
                                        null, // project subqueries
                                        null, // havingSubquerys,
                                        null, // tableProperties,
                                        getContextManager());


        /*
         * Reset the bottom RCL to be empty.
         */
        childResult.setResultColumns((ResultColumnList)
                                            getNodeFactory().getNode(
                                                C_NodeTypes.RESULT_COLUMN_LIST,
                                                getContextManager()));

        /*
         * Set the Windowing RCL to be empty
         */
        resultColumns = (ResultColumnList) getNodeFactory().getNode(
                                            C_NodeTypes.RESULT_COLUMN_LIST,
                                            getContextManager());


        // Add all referenced columns in select list to windowing node's RCL
        // and substitute references in original node to point to the Windowing
        // result set. (modelled on GroupByNode's action for addUnAggColumns)
        CollectNodesVisitor getCRVisitor =
            new CollectNodesVisitor(ColumnReference.class);

        ResultColumnList prcl = parent.getResultColumns();

        parent.getResultColumns().accept(getCRVisitor);

        Vector colRefs = getCRVisitor.getList();

        // Find all unique columns referenced and add those to windowing result
        // set.
        Vector uniqueCols = new Vector();
        for (int i= 0; i< colRefs.size(); i++) {
            ColumnReference cr = (ColumnReference)colRefs.elementAt(i);
            if (!colRefAlreadySeen(uniqueCols, cr)) {
                uniqueCols.add(cr);
            }
        }

        // Add all virtual column select list to windowing node's RCL and
        // substitute references in original node to point to the Windowing
        // result set. Happens for example when we have a window over a group
        // by.
        CollectNodesVisitor getVCVisitor =
            new CollectNodesVisitor(VirtualColumnNode.class);

        parent.getResultColumns().accept(getVCVisitor);
        Vector vcs = getVCVisitor.getList();

        // Add any virtual columns to windowing result.
        for (int i= 0; i< vcs.size(); i++) {
            uniqueCols.add(vcs.elementAt(i));
        }

        ResultColumnList bottomRCL  = childResult.getResultColumns();
        ResultColumnList windowingRCL = resultColumns;

        for (int i= 0; i< uniqueCols.size(); i++) {
            ValueNode crOrVcn = (ValueNode)uniqueCols.elementAt(i);

            ResultColumn newRC = (ResultColumn) getNodeFactory().getNode(
                    C_NodeTypes.RESULT_COLUMN,
                    ""##UnWindowingColumn"",
                    crOrVcn,
                    getContextManager());

            // add this result column to the bottom rcl
            bottomRCL.addElement(newRC);
            newRC.markGenerated();
            newRC.bindResultColumnToExpression();
            newRC.setVirtualColumnId(bottomRCL.size());

            // now add this column to the windowing result column list
            ResultColumn wRC = (ResultColumn) getNodeFactory().getNode(
                    C_NodeTypes.RESULT_COLUMN,
                    ""##UnWindowingColumn"",
                    crOrVcn,
                    getContextManager());
            windowingRCL.addElement(wRC);
            wRC.markGenerated();
            wRC.bindResultColumnToExpression();
            wRC.setVirtualColumnId(windowingRCL.size());

            /*
             ** Reset the original node to point to the
             ** Windowing result set.
             */
            VirtualColumnNode vc = (VirtualColumnNode) getNodeFactory().getNode(
                    C_NodeTypes.VIRTUAL_COLUMN_NODE,
                    this, // source result set.
                    wRC,
                    new Integer(windowingRCL.size()),
                    getContextManager());

            SubstituteExpressionVisitor seVis =
                new SubstituteExpressionVisitor(crOrVcn, vc, null);
            parent.getResultColumns().accept(seVis);
        }
    }"
https://github.com/apache/derby/tree/eea0d50c8d732cad9ba563ddfa786b7028eb092f//java/engine/org/apache/derby/impl/sql/conn/CachedStatement.java,clearIdentity,open,"public void clearIdentity() {

		if (SanityManager.DEBUG)
			SanityManager.DEBUG(""StatementCacheInfo"",""CLEARING IDENTITY: ""+ps.getSource());
		ps.setCacheHolder(null);

		identity = null;
		ps = null;
	}"
https://github.com/apache/derby/tree/eea0d50c8d732cad9ba563ddfa786b7028eb092f//java/engine/org/apache/derby/impl/sql/conn/GenericLanguageConnectionContext.java,initDefaultSchemaDescriptor,close,"protected SchemaDescriptor initDefaultSchemaDescriptor()
        throws StandardException {
        /*
        ** - If the database supports schemas and a schema with the
        ** same name as the user's name exists (has been created using
        ** create schema already) the database will set the users
        ** default schema to the the schema with the same name as the
        ** user.
        ** - Else Set the default schema to APP.
        */
        if (cachedInitialDefaultSchemaDescr == null) {
            DataDictionary dd = getDataDictionary();
            String authorizationId = getSessionUserId();
            SchemaDescriptor sd =
                dd.getSchemaDescriptor(
                    getSessionUserId(), getTransactionCompile(), false);

            if (sd == null) {
                sd = new SchemaDescriptor(
                    dd,
                    getSessionUserId(),
                    getSessionUserId(),
                    (UUID) null,
                    false);
            }

            cachedInitialDefaultSchemaDescr = sd;
        }
        return cachedInitialDefaultSchemaDescr;
    }"
https://github.com/apache/derby/tree/eea0d50c8d732cad9ba563ddfa786b7028eb092f//java/engine/org/apache/derby/impl/sql/conn/GenericLanguageConnectionContext.java,verifyAllHeldResultSetsAreClosed,open,"public boolean verifyAllHeldResultSetsAreClosed()
            throws StandardException
    {
        boolean seenOpenResultSets = false;

        /* For every activation */
        for (int i = acts.size() - 1; i >= 0; i--) {

            Activation a = (Activation) acts.get(i);

            if (SanityManager.DEBUG)
            {
                SanityManager.ASSERT(a instanceof CursorActivation, ""a is not a CursorActivation"");
            }

            if (!a.isInUse())
            {
                continue;
            }

            if (!a.getResultSetHoldability())
            {
                continue;
            }

            ResultSet rs = ((CursorActivation) a).getResultSet();

            /* is there an open result set? */
            if ((rs != null) && !rs.isClosed() && rs.returnsRows())
            {
                seenOpenResultSets = true;
                break;
            }
        }

        if (!seenOpenResultSets)
            return(true);

        // There may be open ResultSet's that are yet to be garbage collected
        // let's try and force these out rather than throw an error
        System.gc();
        System.runFinalization();


        /* For every activation */
        for (int i = acts.size() - 1; i >= 0; i--) {
                
            Activation a = (Activation) acts.get(i);

            if (SanityManager.DEBUG)
            {
                SanityManager.ASSERT(a instanceof CursorActivation, ""a is not a CursorActivation"");
            }

            if (!a.isInUse())
            {
                continue;
            }

            if (!a.getResultSetHoldability())
            {
                continue;
            }

            ResultSet rs = ((CursorActivation) a).getResultSet();

            /* is there an open held result set? */
            if ((rs != null) && !rs.isClosed() && rs.returnsRows())
            {
                return(false);
            }
        }
        return(true);
    }"
https://github.com/apache/derby/tree/eea0d50c8d732cad9ba563ddfa786b7028eb092f//java/engine/org/apache/derby/impl/sql/conn/GenericLanguageConnectionContext.java,verifyNoOpenResultSets,open,"public boolean verifyNoOpenResultSets(PreparedStatement pStmt, Provider provider,
                                       int action)
            throws StandardException
    {
        /*
        ** It is not a problem to create an index when there is an open
        ** result set, since it doesn't invalidate the access path that was
        ** chosen for the result set.
        */
        boolean seenOpenResultSets = false;

        /* For every activation */

        // synchronize on acts as other threads may be closing activations
        // in this list, thus invalidating the Enumeration
        for (int i = acts.size() - 1; i >= 0; i--) {
                
            Activation a = (Activation) acts.get(i);

            if (!a.isInUse())
            {
                continue;
            }
            
            /* for this prepared statement */
            if (pStmt == a.getPreparedStatement()) {
                ResultSet rs = a.getResultSet();

                /* is there an open result set? */
                if (rs != null && ! rs.isClosed())
                {
                    if (!rs.returnsRows())
                        continue;
                    seenOpenResultSets = true;
                    break;
                }
                
            }
        }

        if (!seenOpenResultSets)
            return false;

        // There may be open ResultSet's that are yet to be garbage collected
        // let's try and force these out rather than throw an error
        System.gc();
        System.runFinalization();


        /* For every activation */
        // synchronize on acts as other threads may be closing activations
        // in this list, thus invalidating the Enumeration
        for (int i = acts.size() - 1; i >= 0; i--) {
                
            Activation a = (Activation) acts.get(i);

            if (!a.isInUse())
            {
                continue;
            }

            /* for this prepared statement */
            if (pStmt == a.getPreparedStatement()) {
                ResultSet rs = a.getResultSet();

                /* is there an open result set? */
                if (rs != null && ! rs.isClosed())
                {
                    if ((provider != null) && rs.returnsRows()) {
                    DependencyManager dmgr = getDataDictionary().getDependencyManager();

                    throw StandardException.newException(SQLState.LANG_CANT_INVALIDATE_OPEN_RESULT_SET, 
                                    dmgr.getActionString(action), 
                                    provider.getObjectName());

                    }
                    return true;
                }
            }
        }
        return false;
    }"
https://github.com/apache/derby/tree/eea0d50c8d732cad9ba563ddfa786b7028eb092f//java/engine/org/apache/derby/impl/sql/conn/GenericLanguageConnectionContext.java,autoincrementFlushCache,open,"public void autoincrementFlushCache(UUID tableUUID)
        throws StandardException
    {
        if (autoincrementCacheHashtable == null)
            return;

        if (autoincrementHT == null)
            autoincrementHT = new HashMap();

        DataDictionary dd = getDataDictionary();
        for (Iterator it = autoincrementCacheHashtable.keySet().iterator();
             it.hasNext(); )
        {
            Object key = it.next();
            AutoincrementCounter aic = 
                (AutoincrementCounter)autoincrementCacheHashtable.get(key);
            Long value = aic.getCurrentValue();
            aic.flushToDisk(getTransactionExecute(), dd, tableUUID);
            if (value != null)
            {
                autoincrementHT.put(key, value);
            }
        }
        autoincrementCacheHashtable.clear();
    }"
https://github.com/apache/derby/tree/eea0d50c8d732cad9ba563ddfa786b7028eb092f//java/engine/org/apache/derby/impl/sql/conn/GenericLanguageConnectionFactory.java,validate,open,"public boolean validate(String key,
						 Serializable value,
						 Dictionary p)
		throws StandardException {
		if (value == null)
			return true;
		else if (key.equals(Property.DEFAULT_CONNECTION_MODE_PROPERTY))
		{
			String value_s = (String)value;
			if (value_s != null &&
				!StringUtil.SQLEqualsIgnoreCase(value_s, Property.NO_ACCESS) &&
				!StringUtil.SQLEqualsIgnoreCase(value_s, Property.READ_ONLY_ACCESS) &&
				!StringUtil.SQLEqualsIgnoreCase(value_s, Property.FULL_ACCESS))
				throw StandardException.newException(SQLState.AUTH_INVALID_AUTHORIZATION_PROPERTY, key, value_s);

			return true;
		}
		else if (key.equals(Property.READ_ONLY_ACCESS_USERS_PROPERTY) ||
				 key.equals(Property.FULL_ACCESS_USERS_PROPERTY))
		{
			String value_s = (String)value;

			/** Parse the new userIdList to verify its syntax. */
			String[] newList_a;
			try {newList_a = IdUtil.parseIdList(value_s);}
			catch (StandardException se) {
                throw StandardException.newException(SQLState.AUTH_INVALID_AUTHORIZATION_PROPERTY, se, key,value_s);
			}

			/** Check the new list userIdList for duplicates. */
			String dups = IdUtil.dups(newList_a);
			if (dups != null) throw StandardException.newException(SQLState.AUTH_DUPLICATE_USERS, key,dups);

			/** Check for users with both read and full access permission. */
			String[] otherList_a;
			String otherList;
			if (key.equals(Property.READ_ONLY_ACCESS_USERS_PROPERTY))
				otherList = (String)p.get(Property.FULL_ACCESS_USERS_PROPERTY);
			else
				otherList = (String)p.get(Property.READ_ONLY_ACCESS_USERS_PROPERTY);
			otherList_a = IdUtil.parseIdList(otherList);
			String both = IdUtil.intersect(newList_a,otherList_a);
			if (both != null) throw StandardException.newException(SQLState.AUTH_USER_IN_READ_AND_WRITE_LISTS, both);
			
			return true;
		}

		return false;
	}"
https://github.com/apache/derby/tree/eea0d50c8d732cad9ba563ddfa786b7028eb092f//java/engine/org/apache/derby/impl/sql/conn/GenericLanguageConnectionFactory.java,validate,open,"public boolean validate(String key,
						 Serializable value,
						 Dictionary p)
		throws StandardException {
		if (value == null)
			return true;
		else if (key.equals(Property.DEFAULT_CONNECTION_MODE_PROPERTY))
		{
			String value_s = (String)value;
			if (value_s != null &&
				!StringUtil.SQLEqualsIgnoreCase(value_s, Property.NO_ACCESS) &&
				!StringUtil.SQLEqualsIgnoreCase(value_s, Property.READ_ONLY_ACCESS) &&
				!StringUtil.SQLEqualsIgnoreCase(value_s, Property.FULL_ACCESS))
				throw StandardException.newException(SQLState.AUTH_INVALID_AUTHORIZATION_PROPERTY, key, value_s);

			return true;
		}
		else if (key.equals(Property.READ_ONLY_ACCESS_USERS_PROPERTY) ||
				 key.equals(Property.FULL_ACCESS_USERS_PROPERTY))
		{
			String value_s = (String)value;

			/** Parse the new userIdList to verify its syntax. */
			String[] newList_a;
			try {newList_a = IdUtil.parseIdList(value_s);}
			catch (StandardException se) {
                throw StandardException.newException(SQLState.AUTH_INVALID_AUTHORIZATION_PROPERTY, se, key,value_s);
			}

			/** Check the new list userIdList for duplicates. */
			String dups = IdUtil.dups(newList_a);
			if (dups != null) throw StandardException.newException(SQLState.AUTH_DUPLICATE_USERS, key,dups);

			/** Check for users with both read and full access permission. */
			String[] otherList_a;
			String otherList;
			if (key.equals(Property.READ_ONLY_ACCESS_USERS_PROPERTY))
				otherList = (String)p.get(Property.FULL_ACCESS_USERS_PROPERTY);
			else
				otherList = (String)p.get(Property.READ_ONLY_ACCESS_USERS_PROPERTY);
			otherList_a = IdUtil.parseIdList(otherList);
			String both = IdUtil.intersect(newList_a,otherList_a);
			if (both != null) throw StandardException.newException(SQLState.AUTH_USER_IN_READ_AND_WRITE_LISTS, both);
			
			return true;
		}

		return false;
	}"
https://github.com/apache/derby/tree/eea0d50c8d732cad9ba563ddfa786b7028eb092f//java/engine/org/apache/derby/impl/sql/execute/AlterTableConstantAction.java,modifyColumnDefault,close,"private void modifyColumnDefault(int ix)
			throws StandardException						 
	{
		ColumnDescriptor columnDescriptor = 
			td.getColumnDescriptor(columnInfo[ix].name);
		DataDescriptorGenerator ddg = dd.getDataDescriptorGenerator();
		int columnPosition = columnDescriptor.getPosition();

		// Clean up after the old default, if non-null
		if (columnDescriptor.hasNonNullDefault())
		{
			// Invalidate off of the old default
			DefaultDescriptor defaultDescriptor = new DefaultDescriptor(dd, columnInfo[ix].oldDefaultUUID, 
										 td.getUUID(), columnPosition);

		
			dm.invalidateFor(defaultDescriptor, DependencyManager.MODIFY_COLUMN_DEFAULT, lcc);
		
			// Drop any dependencies
			dm.clearDependencies(lcc, defaultDescriptor);
		}

		UUID defaultUUID = columnInfo[ix].newDefaultUUID;

		/* Generate a UUID for the default, if one exists
		 * and there is no default id yet.
		 */
		if (columnInfo[ix].defaultInfo != null &&
			defaultUUID == null)
		{	
			defaultUUID = dd.getUUIDFactory().createUUID();
		}

		/* Get a ColumnDescriptor reflecting the new default */
		columnDescriptor = new ColumnDescriptor(
												   columnInfo[ix].name,
												   columnPosition,
												   columnInfo[ix].dataType,
												   columnInfo[ix].defaultValue,
												   columnInfo[ix].defaultInfo,
												   td,
												   defaultUUID,
												   columnInfo[ix].autoincStart,
												   columnInfo[ix].autoincInc,
												   columnInfo[ix].autoinc_create_or_modify_Start_Increment
												   );

		// Update the ColumnDescriptor with new default info
		dd.dropColumnDescriptor(td.getUUID(), columnInfo[ix].name, tc);
		dd.addDescriptor(columnDescriptor, td,
						 DataDictionary.SYSCOLUMNS_CATALOG_NUM, false, tc);
	
		if (columnInfo[ix].action == ColumnInfo.MODIFY_COLUMN_DEFAULT_INCREMENT)
		{
			// adding an autoincrement default-- calculate the maximum value 
			// of the autoincrement column.
            long maxValue = getColumnMax(td, columnInfo[ix].name,
                                         columnInfo[ix].autoincInc);
			dd.setAutoincrementValue(tc, td.getUUID(), columnInfo[ix].name,
									 maxValue, true);
		} else if (columnInfo[ix].action == ColumnInfo.MODIFY_COLUMN_DEFAULT_RESTART)
		{
			dd.setAutoincrementValue(tc, td.getUUID(), columnInfo[ix].name,
					 columnInfo[ix].autoincStart, false);
		} 
		// else we are simply changing the default value
	}"
https://github.com/apache/derby/tree/eea0d50c8d732cad9ba563ddfa786b7028eb092f//java/engine/org/apache/derby/impl/sql/execute/BaseActivation.java,getAutoGeneratedKeysColumnNames,close,"public String[] getAutoGeneratedKeysColumnNames()
	{
		return autoGeneratedKeysColumnNames;
	}"
https://github.com/apache/derby/tree/eea0d50c8d732cad9ba563ddfa786b7028eb092f//java/engine/org/apache/derby/impl/sql/execute/BaseActivation.java,getAutoGeneratedKeysColumnIndexes,close,"public int[] getAutoGeneratedKeysColumnIndexes()
	{
		return autoGeneratedKeysColumnIndexes;
	}"
https://github.com/apache/derby/tree/eea0d50c8d732cad9ba563ddfa786b7028eb092f//java/engine/org/apache/derby/impl/sql/execute/BaseActivation.java,setAutoGeneratedKeysResultsetInfo,close,"public void setAutoGeneratedKeysResultsetInfo(int[] columnIndexes, String[] columnNames)
	{
		autoGeneratedKeysResultSetMode = true;
		autoGeneratedKeysColumnIndexes = columnIndexes;
		autoGeneratedKeysColumnNames = columnNames;
	}"
https://github.com/apache/derby/tree/eea0d50c8d732cad9ba563ddfa786b7028eb092f//java/engine/org/apache/derby/impl/sql/execute/BaseActivation.java,setAutoGeneratedKeysResultsetInfo,close,"public void setAutoGeneratedKeysResultsetInfo(int[] columnIndexes, String[] columnNames)
	{
		autoGeneratedKeysResultSetMode = true;
		autoGeneratedKeysColumnIndexes = columnIndexes;
		autoGeneratedKeysColumnNames = columnNames;
	}"
https://github.com/apache/derby/tree/eea0d50c8d732cad9ba563ddfa786b7028eb092f//java/engine/org/apache/derby/impl/sql/execute/BaseActivation.java,getColumnFromRow,open,"protected final DataValueDescriptor getColumnFromRow(int rsNumber, int colId)
		throws StandardException {

        if (row[rsNumber] == null) {
            /* This actually happens. NoPutResultSetImpl.clearOrderableCache
             * attempts to prefetch invariant values into a cache. This fails
             * in some deeply nested joins. See Beetle 4736 and 4880.*/

            /*
             * Update: DERBY-4798 shows a query for which we get an NPE unless
             * this escape is in place (once removed by DERBY-3097, but
             * reintroduced by DERBY-4798 until we understand how we can get
             * rid of this anomaly). Thus, for now,
             * OuterJoinTest#testDerby_4798_NPE will provoke an NPE if this
             * code is removed.
             */
            return null;
        }

        return row[rsNumber].getColumn(colId);
	}"
https://github.com/apache/derby/tree/eea0d50c8d732cad9ba563ddfa786b7028eb092f//java/engine/org/apache/derby/impl/sql/execute/BaseActivation.java,getCurrentRow,open,"public Row getCurrentRow(int resultSetNumber)
	{
        return row[resultSetNumber];
	}"
https://github.com/apache/derby/tree/eea0d50c8d732cad9ba563ddfa786b7028eb092f//java/engine/org/apache/derby/impl/sql/execute/CardinalityCounter.java,getCardinality,open,public long[] getCardinality() { return cardinality; }
https://github.com/apache/derby/tree/eea0d50c8d732cad9ba563ddfa786b7028eb092f//java/engine/org/apache/derby/impl/sql/execute/ConstraintConstantAction.java,validateConstraint,close,"static boolean validateConstraint
	(
		String							constraintName,
		String							constraintText,
		TableDescriptor					td,
		LanguageConnectionContext		lcc,
		boolean							isCheckConstraint
	)
		throws StandardException
	{
		StringBuffer checkStmt = new StringBuffer();
		/* should not use select sum(not(<check-predicate>) ? 1: 0) because
		 * that would generate much more complicated code and may exceed Java
		 * limits if we have a large number of check constraints, beetle 4347
		 */
		checkStmt.append(""SELECT COUNT(*) FROM "");
		checkStmt.append(td.getQualifiedName());
		checkStmt.append("" WHERE NOT("");
		checkStmt.append(constraintText);
		checkStmt.append("")"");
	
		ResultSet rs = null;
		try
		{
			PreparedStatement ps = lcc.prepareInternalStatement(checkStmt.toString());

            // This is a substatement; for now, we do not set any timeout
            // for it. We might change this behaviour later, by linking
            // timeout to its parent statement's timeout settings.
			rs = ps.executeSubStatement(lcc, false, 0L);
			ExecRow row = rs.getNextRow();
			if (SanityManager.DEBUG)
			{
				if (row == null)
				{
					SanityManager.THROWASSERT(""did not get any rows back from query: ""+checkStmt.toString());
				}
			}

			DataValueDescriptor[] rowArray = row.getRowArray();
			Number value = ((Number)((NumberDataValue)row.getRowArray()[0]).getObject());
			/*
			** Value may be null if there are no rows in the
			** table.
			*/
			if ((value != null) && (value.longValue() != 0))
			{	
				//check constraint violated
				if (isCheckConstraint)
					throw StandardException.newException(SQLState.LANG_ADD_CHECK_CONSTRAINT_FAILED, 
						constraintName, td.getQualifiedName(), value.toString());
				/*
				 * for not null constraint violations exception will be thrown in caller
				 * check constraint will not get here since exception is thrown
				 * above
				 */
				return false;
			}
		}
		finally
		{
			if (rs != null)
			{
				rs.close();
			}
		}
		return true;
	}"
https://github.com/apache/derby/tree/eea0d50c8d732cad9ba563ddfa786b7028eb092f//java/engine/org/apache/derby/impl/sql/execute/ConstraintInfo.java,getReferencedColumnNames,close,"public String[] getReferencedColumnNames()
	{ return columnNames; }"
https://github.com/apache/derby/tree/eea0d50c8d732cad9ba563ddfa786b7028eb092f//java/engine/org/apache/derby/impl/sql/execute/CreateConstraintConstantAction.java,toString,open,"public String toString()
	{
		// Do not put this under SanityManager.DEBUG - it is needed for
		// error reporting.
		StringBuffer strbuf = new StringBuffer();
		strbuf.append( ""CREATE CONSTRAINT "" + constraintName );
		strbuf.append(""\n=========================\n"");

		if (columnNames == null)
		{
			strbuf.append(""columnNames == null\n"");
		}
		else
		{
			for (int ix=0; ix < columnNames.length; ix++)
			{
				strbuf.append(""\n\tcol[""+ix+""]""+columnNames[ix].toString());
			}
		}
		
		strbuf.append(""\n"");
		strbuf.append(constraintText);
		strbuf.append(""\n"");
		if (otherConstraintInfo != null)
		{
			strbuf.append(otherConstraintInfo.toString());
		}
		strbuf.append(""\n"");
		return strbuf.toString();
	}"
https://github.com/apache/derby/tree/eea0d50c8d732cad9ba563ddfa786b7028eb092f//java/engine/org/apache/derby/impl/sql/execute/CreateIndexConstantAction.java,executeConstantAction,open,"public void	executeConstantAction( Activation activation )
						throws StandardException
	{
		TableDescriptor 			td;
		UUID 						toid;
		ColumnDescriptor			columnDescriptor;
		int[]						baseColumnPositions;
		IndexRowGenerator			indexRowGenerator = null;
		ExecRow[]					baseRows;
		ExecIndexRow[]				indexRows;
		ExecRow[]					compactBaseRows;
		GroupFetchScanController    scan;
		RowLocationRetRowSource	    rowSource;
		long						sortId;
		int							maxBaseColumnPosition = -1;

		LanguageConnectionContext lcc = activation.getLanguageConnectionContext();
		DataDictionary dd = lcc.getDataDictionary();
		DependencyManager dm = dd.getDependencyManager();
		TransactionController tc = lcc.getTransactionExecute();

		/*
		** Inform the data dictionary that we are about to write to it.
		** There are several calls to data dictionary ""get"" methods here
		** that might be done in ""read"" mode in the data dictionary, but
		** it seemed safer to do this whole operation in ""write"" mode.
		**
		** We tell the data dictionary we're done writing at the end of
		** the transaction.
		*/
		dd.startWriting(lcc);

		/*
		** If the schema descriptor is null, then
		** we must have just read ourselves in.  
		** So we will get the corresponding schema
		** descriptor from the data dictionary.
		*/
		SchemaDescriptor sd = dd.getSchemaDescriptor(schemaName, tc, true) ;


		/* Get the table descriptor. */
		/* See if we can get the TableDescriptor 
		 * from the Activation.  (Will be there
		 * for backing indexes.)
		 */
		td = activation.getDDLTableDescriptor();

		if (td == null)
		{
			/* tableId will be non-null if adding an index to
			 * an existing table (as opposed to creating a
			 * table with a constraint with a backing index).
			 */
			if (tableId != null)
			{
				td = dd.getTableDescriptor(tableId);
			}
			else
			{
				td = dd.getTableDescriptor(tableName, sd, tc);
			}
		}

		if (td == null)
		{
			throw StandardException.newException(SQLState.LANG_CREATE_INDEX_NO_TABLE, 
						indexName, tableName);
		}

		if (td.getTableType() == TableDescriptor.SYSTEM_TABLE_TYPE)
		{
			throw StandardException.newException(SQLState.LANG_CREATE_SYSTEM_INDEX_ATTEMPTED, 
						indexName, tableName);
		}

		/* Get a shared table lock on the table. We need to lock table before
		 * invalidate dependents, otherwise, we may interfere with the
		 * compilation/re-compilation of DML/DDL.  See beetle 4325 and $WS/
		 * docs/language/SolutionsToConcurrencyIssues.txt (point f).
		 */
		lockTableForDDL(tc, td.getHeapConglomerateId(), false);

		// invalidate any prepared statements that
		// depended on this table (including this one)
		if (! forCreateTable)
		{
			dm.invalidateFor(td, DependencyManager.CREATE_INDEX, lcc);
		}

		// Translate the base column names to column positions
		baseColumnPositions = new int[columnNames.length];
		for (int i = 0; i < columnNames.length; i++)
		{
			// Look up the column in the data dictionary
			columnDescriptor = td.getColumnDescriptor(columnNames[i]);
			if (columnDescriptor == null)
			{
				throw StandardException.newException(SQLState.LANG_COLUMN_NOT_FOUND_IN_TABLE, 
															columnNames[i],
															tableName);
			}

			TypeId typeId = columnDescriptor.getType().getTypeId();

			// Don't allow a column to be created on a non-orderable type
			ClassFactory cf = lcc.getLanguageConnectionFactory().getClassFactory();
			boolean isIndexable = typeId.orderable(cf);

			if (isIndexable && typeId.userType()) {
				String userClass = typeId.getCorrespondingJavaTypeName();

				// Don't allow indexes to be created on classes that
				// are loaded from the database. This is because recovery
				// won't be able to see the class and it will need it to
				// run the compare method.
				try {
					if (cf.isApplicationClass(cf.loadApplicationClass(userClass)))
						isIndexable = false;
				} catch (ClassNotFoundException cnfe) {
					// shouldn't happen as we just check the class is orderable
					isIndexable = false;
				}
			}

			if (!isIndexable) {
				throw StandardException.newException(SQLState.LANG_COLUMN_NOT_ORDERABLE_DURING_EXECUTION, 
					typeId.getSQLTypeName());
			}

			// Remember the position in the base table of each column
			baseColumnPositions[i] = columnDescriptor.getPosition();

			if (maxBaseColumnPosition < baseColumnPositions[i])
				maxBaseColumnPosition = baseColumnPositions[i];
		}

		/* The code below tries to determine if the index that we're about
		 * to create can ""share"" a conglomerate with an existing index.
		 * If so, we will use a single physical conglomerate--namely, the
		 * one that already exists--to support both indexes. I.e. we will
		 * *not* create a new conglomerate as part of this constant action.
		 */ 

		// check if we have similar indices already for this table
		ConglomerateDescriptor[] congDescs = td.getConglomerateDescriptors();
		boolean shareExisting = false;
		for (int i = 0; i < congDescs.length; i++)
		{
			ConglomerateDescriptor cd = congDescs[i];
			if ( ! cd.isIndex())
				continue;

			if (droppedConglomNum == cd.getConglomerateNumber())
			{
				/* We can't share with any conglomerate descriptor
				 * whose conglomerate number matches the dropped
				 * conglomerate number, because that descriptor's
				 * backing conglomerate was dropped, as well.  If
				 * we're going to share, we have to share with a
				 * descriptor whose backing physical conglomerate
				 * is still around.
				 */
				continue;
			}

			IndexRowGenerator irg = cd.getIndexDescriptor();
			int[] bcps = irg.baseColumnPositions();
			boolean[] ia = irg.isAscending();
			int j = 0;

			/* The conditions which allow an index to share an existing
			 * conglomerate are as follows:
			 *
			 * 1. the set of columns (both key and include columns) and their 
			 *  order in the index is the same as that of an existing index AND 
			 *
			 * 2. the ordering attributes are the same AND 
			 *
			 * 3. one of the following is true:
			 *    a) the existing index is unique, OR
			 *    b) the existing index is non-unique with uniqueWhenNotNulls
			 *       set to TRUE and the index being created is non-unique, OR
			 *    c) both the existing index and the one being created are
			 *       non-unique and have uniqueWithDuplicateNulls set to FALSE.
			 */ 
			boolean possibleShare = (irg.isUnique() || !unique) &&
			    (bcps.length == baseColumnPositions.length);

			//check if existing index is non unique and uniqueWithDuplicateNulls
			//is set to true (backing index for unique constraint)
			if (possibleShare && !irg.isUnique ())
			{
				/* If the existing index has uniqueWithDuplicateNulls set to
				 * TRUE it can be shared by other non-unique indexes; otherwise
				 * the existing non-unique index has uniqueWithDuplicateNulls
				 * set to FALSE, which means the new non-unique conglomerate
				 * can only share if it has uniqueWithDuplicateNulls set to
				 * FALSE, as well.
				 */
				possibleShare = (irg.isUniqueWithDuplicateNulls() ||
								! uniqueWithDuplicateNulls);
			}

			if (possibleShare && indexType.equals(irg.indexType()))
			{
				for (; j < bcps.length; j++)
				{
					if ((bcps[j] != baseColumnPositions[j]) || (ia[j] != isAscending[j]))
						break;
				}
			}

			if (j == baseColumnPositions.length)	// share
			{
				/*
				 * Don't allow users to create a duplicate index. Allow if being done internally
				 * for a constraint
				 */
				if (!isConstraint)
				{
					activation.addWarning(
							StandardException.newWarning(
								SQLState.LANG_INDEX_DUPLICATE,
								cd.getConglomerateName()));

					return;
				}

				/* Sharing indexes share the physical conglomerate
				 * underneath, so pull the conglomerate number from
				 * the existing conglomerate descriptor.
				 */
				conglomId = cd.getConglomerateNumber();

				/* We create a new IndexRowGenerator because certain
				 * attributes--esp. uniqueness--may be different between
				 * the index we're creating and the conglomerate that
				 * already exists.  I.e. even though we're sharing a
				 * conglomerate, the new index is not necessarily
				 * identical to the existing conglomerate. We have to
				 * keep track of that info so that if we later drop
				 * the shared physical conglomerate, we can figure out
				 * what this index (the one we're creating now) is
				 * really supposed to look like.
				 */
				indexRowGenerator =
					new IndexRowGenerator(
						indexType, unique, uniqueWithDuplicateNulls,
						baseColumnPositions,
						isAscending,
						baseColumnPositions.length);

				//DERBY-655 and DERBY-1343  
				// Sharing indexes will have unique logical conglomerate UUIDs.
				conglomerateUUID = dd.getUUIDFactory().createUUID();
				shareExisting = true;
				break;
			}
		}

		/* If we have a droppedConglomNum then the index we're about to
		 * ""create"" already exists--i.e. it has an index descriptor and
		 * the corresponding information is already in the system catalogs.
		 * The only thing we're missing, then, is the physical conglomerate
		 * to back the index (because the old conglomerate was dropped).
		 */
		boolean alreadyHaveConglomDescriptor = (droppedConglomNum > -1L);

		/* If this index already has an essentially same one, we share the
		 * conglomerate with the old one, and just simply add a descriptor
		 * entry into SYSCONGLOMERATES--unless we already have a descriptor,
		 * in which case we don't even need to do that.
		 */
		DataDescriptorGenerator ddg = dd.getDataDescriptorGenerator();
		if (shareExisting && !alreadyHaveConglomDescriptor)
		{
			ConglomerateDescriptor cgd =
				ddg.newConglomerateDescriptor(conglomId, indexName, true,
										  indexRowGenerator, isConstraint,
										  conglomerateUUID, td.getUUID(), sd.getUUID() );
			dd.addDescriptor(cgd, sd, DataDictionary.SYSCONGLOMERATES_CATALOG_NUM, false, tc);
			// add newly added conglomerate to the list of conglomerate 
			// descriptors in the td.
			ConglomerateDescriptorList cdl = 
				td.getConglomerateDescriptorList();
			cdl.add(cgd);

			// can't just return yet, need to get member ""indexTemplateRow""
			// because create constraint may use it
		}

		// Describe the properties of the index to the store using Properties
		// RESOLVE: The following properties assume a BTREE index.
		Properties	indexProperties;
		
		if (properties != null)
		{
			indexProperties = properties;
		}
		else
		{
			indexProperties = new Properties();
		}

		// Tell it the conglomerate id of the base table
		indexProperties.put(""baseConglomerateId"",
							Long.toString(td.getHeapConglomerateId()));
        
		if (uniqueWithDuplicateNulls) 
        {
            if (dd.checkVersion(DataDictionary.DD_VERSION_DERBY_10_4, null))
            {
				indexProperties.put(
                    ""uniqueWithDuplicateNulls"", Boolean.toString(true));
			}
			else 
            {
				// for lower version of DD there is no unique with nulls 
                // index creating a unique index instead.
				if (uniqueWithDuplicateNulls) 
                {
					unique = true;
				}
			}
		}

		// All indexes are unique because they contain the RowLocation.
		// The number of uniqueness columns must include the RowLocation
		// if the user did not specify a unique index.
		indexProperties.put(""nUniqueColumns"",
					Integer.toString(unique ? baseColumnPositions.length :
												baseColumnPositions.length + 1)
							);
		// By convention, the row location column is the last column
		indexProperties.put(""rowLocationColumn"",
							Integer.toString(baseColumnPositions.length));

		// For now, all columns are key fields, including the RowLocation
		indexProperties.put(""nKeyFields"",
							Integer.toString(baseColumnPositions.length + 1));

		// For now, assume that all index columns are ordered columns
		if (! shareExisting)
		{
            if (dd.checkVersion(DataDictionary.DD_VERSION_DERBY_10_4, null))
            {
                indexRowGenerator = new IndexRowGenerator(
                                            indexType, 
                                            unique, 
                                            uniqueWithDuplicateNulls,
                                            baseColumnPositions,
                                            isAscending,
                                            baseColumnPositions.length);
			}
			else 
            {
				indexRowGenerator = new IndexRowGenerator(
                                            indexType, 
                                            unique,
                                            baseColumnPositions,
                                            isAscending,
                                            baseColumnPositions.length);
			}
		}

		/* Now add the rows from the base table to the conglomerate.
		 * We do this by scanning the base table and inserting the
		 * rows into a sorter before inserting from the sorter
		 * into the index.  This gives us better performance
		 * and a more compact index.
		 */

		rowSource = null;
		sortId = 0;
		boolean needToDropSort = false;	// set to true once the sorter is created

		/* bulkFetchSIze will be 16 (for now) unless
		 * we are creating the table in which case it
		 * will be 1.  Too hard to remove scan when
		 * creating index on new table, so minimize
		 * work where we can.
		 */
		int bulkFetchSize = (forCreateTable) ? 1 : 16;	
		int numColumns = td.getNumberOfColumns();
		int approximateRowSize = 0;

		// Create the FormatableBitSet for mapping the partial to full base row
		FormatableBitSet bitSet = new FormatableBitSet(numColumns+1);
		for (int index = 0; index < baseColumnPositions.length; index++)
		{
			bitSet.set(baseColumnPositions[index]);
		}
		FormatableBitSet zeroBasedBitSet = RowUtil.shift(bitSet, 1);

		// Start by opening a full scan on the base table.
		scan = tc.openGroupFetchScan(
                            td.getHeapConglomerateId(),
							false,	// hold
							0,	// open base table read only
                            TransactionController.MODE_TABLE,
                            TransactionController.ISOLATION_SERIALIZABLE,
							zeroBasedBitSet,    // all fields as objects
							(DataValueDescriptor[]) null,	// startKeyValue
							0,		// not used when giving null start posn.
							null,	// qualifier
							(DataValueDescriptor[]) null,	// stopKeyValue
							0);		// not used when giving null stop posn.

		// Create an array to put base row template
		baseRows = new ExecRow[bulkFetchSize];
		indexRows = new ExecIndexRow[bulkFetchSize];
		compactBaseRows = new ExecRow[bulkFetchSize];

		try
		{
			// Create the array of base row template
			for (int i = 0; i < bulkFetchSize; i++)
			{
				// create a base row template
				baseRows[i] = activation.getExecutionFactory().getValueRow(maxBaseColumnPosition);

				// create an index row template
				indexRows[i] = indexRowGenerator.getIndexRowTemplate();

				// create a compact base row template
				compactBaseRows[i] = activation.getExecutionFactory().getValueRow(
													baseColumnPositions.length);
			}

			indexTemplateRow = indexRows[0];

			// Fill the partial row with nulls of the correct type
			ColumnDescriptorList cdl = td.getColumnDescriptorList();
			int					 cdlSize = cdl.size();
			for (int index = 0, numSet = 0; index < cdlSize; index++)
			{
				if (! zeroBasedBitSet.get(index))
				{
					continue;
				}
				numSet++;
				ColumnDescriptor cd = (ColumnDescriptor) cdl.elementAt(index);
				DataTypeDescriptor dts = cd.getType();


				for (int i = 0; i < bulkFetchSize; i++)
				{
					// Put the column in both the compact and sparse base rows
					baseRows[i].setColumn(index + 1,
								  dts.getNull());
					compactBaseRows[i].setColumn(numSet,
								  baseRows[i].getColumn(index + 1));
				}

				// Calculate the approximate row size for the index row
				approximateRowSize += dts.getTypeId().getApproximateLengthInBytes(dts);
			}

			// Get an array of RowLocation template
			RowLocation rl[] = new RowLocation[bulkFetchSize];
			for (int i = 0; i < bulkFetchSize; i++)
			{
				rl[i] = scan.newRowLocationTemplate();

				// Get an index row based on the base row
				indexRowGenerator.getIndexRow(compactBaseRows[i], rl[i], indexRows[i], bitSet);
			}

			/* now that we got indexTemplateRow, done for sharing index
			 */
			if (shareExisting)
				return;

			/* For non-unique indexes, we order by all columns + the RID.
			 * For unique indexes, we just order by the columns.
			 * We create a unique index observer for unique indexes
			 * so that we can catch duplicate key.
			 * We create a basic sort observer for non-unique indexes
			 * so that we can reuse the wrappers during an external
			 * sort.
			 */
			int             numColumnOrderings;
			SortObserver    sortObserver   = null;
            Properties      sortProperties = null;
			if (unique || uniqueWithDuplicateNulls)
			{
				// if the index is a constraint, use constraintname in 
                // possible error message
				String indexOrConstraintName = indexName;
				if  (conglomerateUUID != null)
				{
					ConglomerateDescriptor cd = 
                        dd.getConglomerateDescriptor(conglomerateUUID);
					if ((isConstraint) && 
                        (cd != null && cd.getUUID() != null && td != null))
					{
						ConstraintDescriptor conDesc = 
                            dd.getConstraintDescriptor(td, cd.getUUID());
						indexOrConstraintName = conDesc.getConstraintName();
					}
				}

				if (unique) 
				{
                    numColumnOrderings = baseColumnPositions.length;

					sortObserver = 
                        new UniqueIndexSortObserver(
                                true, 
                                isConstraint, 
                                indexOrConstraintName,
                                indexTemplateRow,
                                true,
                                td.getName());
				}
				else 
                {
                    // unique with duplicate nulls allowed.

					numColumnOrderings = baseColumnPositions.length + 1;

                    // tell transaction controller to use the unique with 
                    // duplicate nulls sorter, when making createSort() call.
					sortProperties = new Properties();
					sortProperties.put(
                        AccessFactoryGlobals.IMPL_TYPE, 
                        AccessFactoryGlobals.SORT_UNIQUEWITHDUPLICATENULLS_EXTERNAL);
					//use sort operator which treats nulls unequal
					sortObserver = 
                        new UniqueWithDuplicateNullsIndexSortObserver(
                                true, 
                                isConstraint, 
                                indexOrConstraintName,
                                indexTemplateRow,
                                true,
                                td.getName());
				}
			}
			else
			{
				numColumnOrderings = baseColumnPositions.length + 1;
				sortObserver = new BasicSortObserver(true, false, 
													 indexTemplateRow,
													 true);
			}

			ColumnOrdering[]	order = new ColumnOrdering[numColumnOrderings];
			for (int i=0; i < numColumnOrderings; i++) 
			{
				order[i] = 
                    new IndexColumnOrder(
                        i, 
                        unique || i < numColumnOrderings - 1 ? 
                            isAscending[i] : true);
			}

			// create the sorter
			sortId = tc.createSort((Properties)sortProperties, 
					indexTemplateRow.getRowArrayClone(),
					order,
					sortObserver,
					false,			// not in order
					scan.getEstimatedRowCount(),
					approximateRowSize	// est row size, -1 means no idea	
					);

			needToDropSort = true;

			// Populate sorter and get the output of the sorter into a row
			// source.  The sorter has the indexed columns only and the columns
			// are in the correct order. 
			rowSource = loadSorter(baseRows, indexRows, tc,
								   scan, sortId, rl);

			conglomId = 
                tc.createAndLoadConglomerate(
					indexType,
					indexTemplateRow.getRowArray(),	// index row template
					order, //colums sort order
                    indexRowGenerator.getColumnCollationIds(
                        td.getColumnDescriptorList()),
					indexProperties,
					TransactionController.IS_DEFAULT, // not temporary
					rowSource,
					(long[]) null);
			
		}
		finally
		{

			/* close the table scan */
			if (scan != null)
				scan.close();

			/* close the sorter row source before throwing exception */
			if (rowSource != null)
				rowSource.closeRowSource();

			/*
			** drop the sort so that intermediate external sort run can be
			** removed from disk
			*/
			if (needToDropSort)
			 	tc.dropSort(sortId);
		}

		ConglomerateController indexController =
			tc.openConglomerate(
                conglomId, false, 0, TransactionController.MODE_TABLE,
                TransactionController.ISOLATION_SERIALIZABLE);

		// Check to make sure that the conglomerate can be used as an index
		if ( ! indexController.isKeyed())
		{
			indexController.close();
			throw StandardException.newException(SQLState.LANG_NON_KEYED_INDEX, indexName,
														   indexType);
		}
		indexController.close();

		//
		// Create a conglomerate descriptor with the conglomId filled
		// in and add it--if we don't have one already.
		//
		if (!alreadyHaveConglomDescriptor)
		{
			ConglomerateDescriptor cgd =
				ddg.newConglomerateDescriptor(
					conglomId, indexName, true,
					indexRowGenerator, isConstraint,
					conglomerateUUID, td.getUUID(), sd.getUUID() );

			dd.addDescriptor(cgd, sd,
				DataDictionary.SYSCONGLOMERATES_CATALOG_NUM, false, tc);

			// add newly added conglomerate to the list of conglomerate
			// descriptors in the td.
			ConglomerateDescriptorList cdl = td.getConglomerateDescriptorList();
			cdl.add(cgd);

			/* Since we created a new conglomerate descriptor, load
			 * its UUID into the corresponding field, to ensure that
			 * it is properly set in the StatisticsDescriptor created
			 * below.
			 */
			conglomerateUUID = cgd.getUUID();
		}

		CardinalityCounter cCount = (CardinalityCounter)rowSource;

        long numRows = cCount.getRowCount();
        if (addStatistics(dd, indexRowGenerator, numRows))
		{
			long[] c = cCount.getCardinality();
			for (int i = 0; i < c.length; i++)
			{
				StatisticsDescriptor statDesc = 
					new StatisticsDescriptor(dd,
						dd.getUUIDFactory().createUUID(),
						conglomerateUUID, td.getUUID(), ""I"",
						new StatisticsImpl(numRows, c[i]), i + 1);

				dd.addDescriptor(statDesc, null, 
								 DataDictionary.SYSSTATISTICS_CATALOG_NUM,
								 true, tc);
			}
		}
	}"
https://github.com/apache/derby/tree/eea0d50c8d732cad9ba563ddfa786b7028eb092f//java/engine/org/apache/derby/impl/sql/execute/CreateIndexConstantAction.java,executeConstantAction,open,"public void	executeConstantAction( Activation activation )
						throws StandardException
	{
		TableDescriptor 			td;
		UUID 						toid;
		ColumnDescriptor			columnDescriptor;
		int[]						baseColumnPositions;
		IndexRowGenerator			indexRowGenerator = null;
		ExecRow[]					baseRows;
		ExecIndexRow[]				indexRows;
		ExecRow[]					compactBaseRows;
		GroupFetchScanController    scan;
		RowLocationRetRowSource	    rowSource;
		long						sortId;
		int							maxBaseColumnPosition = -1;

		LanguageConnectionContext lcc = activation.getLanguageConnectionContext();
		DataDictionary dd = lcc.getDataDictionary();
		DependencyManager dm = dd.getDependencyManager();
		TransactionController tc = lcc.getTransactionExecute();

		/*
		** Inform the data dictionary that we are about to write to it.
		** There are several calls to data dictionary ""get"" methods here
		** that might be done in ""read"" mode in the data dictionary, but
		** it seemed safer to do this whole operation in ""write"" mode.
		**
		** We tell the data dictionary we're done writing at the end of
		** the transaction.
		*/
		dd.startWriting(lcc);

		/*
		** If the schema descriptor is null, then
		** we must have just read ourselves in.  
		** So we will get the corresponding schema
		** descriptor from the data dictionary.
		*/
		SchemaDescriptor sd = dd.getSchemaDescriptor(schemaName, tc, true) ;


		/* Get the table descriptor. */
		/* See if we can get the TableDescriptor 
		 * from the Activation.  (Will be there
		 * for backing indexes.)
		 */
		td = activation.getDDLTableDescriptor();

		if (td == null)
		{
			/* tableId will be non-null if adding an index to
			 * an existing table (as opposed to creating a
			 * table with a constraint with a backing index).
			 */
			if (tableId != null)
			{
				td = dd.getTableDescriptor(tableId);
			}
			else
			{
				td = dd.getTableDescriptor(tableName, sd, tc);
			}
		}

		if (td == null)
		{
			throw StandardException.newException(SQLState.LANG_CREATE_INDEX_NO_TABLE, 
						indexName, tableName);
		}

		if (td.getTableType() == TableDescriptor.SYSTEM_TABLE_TYPE)
		{
			throw StandardException.newException(SQLState.LANG_CREATE_SYSTEM_INDEX_ATTEMPTED, 
						indexName, tableName);
		}

		/* Get a shared table lock on the table. We need to lock table before
		 * invalidate dependents, otherwise, we may interfere with the
		 * compilation/re-compilation of DML/DDL.  See beetle 4325 and $WS/
		 * docs/language/SolutionsToConcurrencyIssues.txt (point f).
		 */
		lockTableForDDL(tc, td.getHeapConglomerateId(), false);

		// invalidate any prepared statements that
		// depended on this table (including this one)
		if (! forCreateTable)
		{
			dm.invalidateFor(td, DependencyManager.CREATE_INDEX, lcc);
		}

		// Translate the base column names to column positions
		baseColumnPositions = new int[columnNames.length];
		for (int i = 0; i < columnNames.length; i++)
		{
			// Look up the column in the data dictionary
			columnDescriptor = td.getColumnDescriptor(columnNames[i]);
			if (columnDescriptor == null)
			{
				throw StandardException.newException(SQLState.LANG_COLUMN_NOT_FOUND_IN_TABLE, 
															columnNames[i],
															tableName);
			}

			TypeId typeId = columnDescriptor.getType().getTypeId();

			// Don't allow a column to be created on a non-orderable type
			ClassFactory cf = lcc.getLanguageConnectionFactory().getClassFactory();
			boolean isIndexable = typeId.orderable(cf);

			if (isIndexable && typeId.userType()) {
				String userClass = typeId.getCorrespondingJavaTypeName();

				// Don't allow indexes to be created on classes that
				// are loaded from the database. This is because recovery
				// won't be able to see the class and it will need it to
				// run the compare method.
				try {
					if (cf.isApplicationClass(cf.loadApplicationClass(userClass)))
						isIndexable = false;
				} catch (ClassNotFoundException cnfe) {
					// shouldn't happen as we just check the class is orderable
					isIndexable = false;
				}
			}

			if (!isIndexable) {
				throw StandardException.newException(SQLState.LANG_COLUMN_NOT_ORDERABLE_DURING_EXECUTION, 
					typeId.getSQLTypeName());
			}

			// Remember the position in the base table of each column
			baseColumnPositions[i] = columnDescriptor.getPosition();

			if (maxBaseColumnPosition < baseColumnPositions[i])
				maxBaseColumnPosition = baseColumnPositions[i];
		}

		/* The code below tries to determine if the index that we're about
		 * to create can ""share"" a conglomerate with an existing index.
		 * If so, we will use a single physical conglomerate--namely, the
		 * one that already exists--to support both indexes. I.e. we will
		 * *not* create a new conglomerate as part of this constant action.
		 */ 

		// check if we have similar indices already for this table
		ConglomerateDescriptor[] congDescs = td.getConglomerateDescriptors();
		boolean shareExisting = false;
		for (int i = 0; i < congDescs.length; i++)
		{
			ConglomerateDescriptor cd = congDescs[i];
			if ( ! cd.isIndex())
				continue;

			if (droppedConglomNum == cd.getConglomerateNumber())
			{
				/* We can't share with any conglomerate descriptor
				 * whose conglomerate number matches the dropped
				 * conglomerate number, because that descriptor's
				 * backing conglomerate was dropped, as well.  If
				 * we're going to share, we have to share with a
				 * descriptor whose backing physical conglomerate
				 * is still around.
				 */
				continue;
			}

			IndexRowGenerator irg = cd.getIndexDescriptor();
			int[] bcps = irg.baseColumnPositions();
			boolean[] ia = irg.isAscending();
			int j = 0;

			/* The conditions which allow an index to share an existing
			 * conglomerate are as follows:
			 *
			 * 1. the set of columns (both key and include columns) and their 
			 *  order in the index is the same as that of an existing index AND 
			 *
			 * 2. the ordering attributes are the same AND 
			 *
			 * 3. one of the following is true:
			 *    a) the existing index is unique, OR
			 *    b) the existing index is non-unique with uniqueWhenNotNulls
			 *       set to TRUE and the index being created is non-unique, OR
			 *    c) both the existing index and the one being created are
			 *       non-unique and have uniqueWithDuplicateNulls set to FALSE.
			 */ 
			boolean possibleShare = (irg.isUnique() || !unique) &&
			    (bcps.length == baseColumnPositions.length);

			//check if existing index is non unique and uniqueWithDuplicateNulls
			//is set to true (backing index for unique constraint)
			if (possibleShare && !irg.isUnique ())
			{
				/* If the existing index has uniqueWithDuplicateNulls set to
				 * TRUE it can be shared by other non-unique indexes; otherwise
				 * the existing non-unique index has uniqueWithDuplicateNulls
				 * set to FALSE, which means the new non-unique conglomerate
				 * can only share if it has uniqueWithDuplicateNulls set to
				 * FALSE, as well.
				 */
				possibleShare = (irg.isUniqueWithDuplicateNulls() ||
								! uniqueWithDuplicateNulls);
			}

			if (possibleShare && indexType.equals(irg.indexType()))
			{
				for (; j < bcps.length; j++)
				{
					if ((bcps[j] != baseColumnPositions[j]) || (ia[j] != isAscending[j]))
						break;
				}
			}

			if (j == baseColumnPositions.length)	// share
			{
				/*
				 * Don't allow users to create a duplicate index. Allow if being done internally
				 * for a constraint
				 */
				if (!isConstraint)
				{
					activation.addWarning(
							StandardException.newWarning(
								SQLState.LANG_INDEX_DUPLICATE,
								cd.getConglomerateName()));

					return;
				}

				/* Sharing indexes share the physical conglomerate
				 * underneath, so pull the conglomerate number from
				 * the existing conglomerate descriptor.
				 */
				conglomId = cd.getConglomerateNumber();

				/* We create a new IndexRowGenerator because certain
				 * attributes--esp. uniqueness--may be different between
				 * the index we're creating and the conglomerate that
				 * already exists.  I.e. even though we're sharing a
				 * conglomerate, the new index is not necessarily
				 * identical to the existing conglomerate. We have to
				 * keep track of that info so that if we later drop
				 * the shared physical conglomerate, we can figure out
				 * what this index (the one we're creating now) is
				 * really supposed to look like.
				 */
				indexRowGenerator =
					new IndexRowGenerator(
						indexType, unique, uniqueWithDuplicateNulls,
						baseColumnPositions,
						isAscending,
						baseColumnPositions.length);

				//DERBY-655 and DERBY-1343  
				// Sharing indexes will have unique logical conglomerate UUIDs.
				conglomerateUUID = dd.getUUIDFactory().createUUID();
				shareExisting = true;
				break;
			}
		}

		/* If we have a droppedConglomNum then the index we're about to
		 * ""create"" already exists--i.e. it has an index descriptor and
		 * the corresponding information is already in the system catalogs.
		 * The only thing we're missing, then, is the physical conglomerate
		 * to back the index (because the old conglomerate was dropped).
		 */
		boolean alreadyHaveConglomDescriptor = (droppedConglomNum > -1L);

		/* If this index already has an essentially same one, we share the
		 * conglomerate with the old one, and just simply add a descriptor
		 * entry into SYSCONGLOMERATES--unless we already have a descriptor,
		 * in which case we don't even need to do that.
		 */
		DataDescriptorGenerator ddg = dd.getDataDescriptorGenerator();
		if (shareExisting && !alreadyHaveConglomDescriptor)
		{
			ConglomerateDescriptor cgd =
				ddg.newConglomerateDescriptor(conglomId, indexName, true,
										  indexRowGenerator, isConstraint,
										  conglomerateUUID, td.getUUID(), sd.getUUID() );
			dd.addDescriptor(cgd, sd, DataDictionary.SYSCONGLOMERATES_CATALOG_NUM, false, tc);
			// add newly added conglomerate to the list of conglomerate 
			// descriptors in the td.
			ConglomerateDescriptorList cdl = 
				td.getConglomerateDescriptorList();
			cdl.add(cgd);

			// can't just return yet, need to get member ""indexTemplateRow""
			// because create constraint may use it
		}

		// Describe the properties of the index to the store using Properties
		// RESOLVE: The following properties assume a BTREE index.
		Properties	indexProperties;
		
		if (properties != null)
		{
			indexProperties = properties;
		}
		else
		{
			indexProperties = new Properties();
		}

		// Tell it the conglomerate id of the base table
		indexProperties.put(""baseConglomerateId"",
							Long.toString(td.getHeapConglomerateId()));
        
		if (uniqueWithDuplicateNulls) 
        {
            if (dd.checkVersion(DataDictionary.DD_VERSION_DERBY_10_4, null))
            {
				indexProperties.put(
                    ""uniqueWithDuplicateNulls"", Boolean.toString(true));
			}
			else 
            {
				// for lower version of DD there is no unique with nulls 
                // index creating a unique index instead.
				if (uniqueWithDuplicateNulls) 
                {
					unique = true;
				}
			}
		}

		// All indexes are unique because they contain the RowLocation.
		// The number of uniqueness columns must include the RowLocation
		// if the user did not specify a unique index.
		indexProperties.put(""nUniqueColumns"",
					Integer.toString(unique ? baseColumnPositions.length :
												baseColumnPositions.length + 1)
							);
		// By convention, the row location column is the last column
		indexProperties.put(""rowLocationColumn"",
							Integer.toString(baseColumnPositions.length));

		// For now, all columns are key fields, including the RowLocation
		indexProperties.put(""nKeyFields"",
							Integer.toString(baseColumnPositions.length + 1));

		// For now, assume that all index columns are ordered columns
		if (! shareExisting)
		{
            if (dd.checkVersion(DataDictionary.DD_VERSION_DERBY_10_4, null))
            {
                indexRowGenerator = new IndexRowGenerator(
                                            indexType, 
                                            unique, 
                                            uniqueWithDuplicateNulls,
                                            baseColumnPositions,
                                            isAscending,
                                            baseColumnPositions.length);
			}
			else 
            {
				indexRowGenerator = new IndexRowGenerator(
                                            indexType, 
                                            unique,
                                            baseColumnPositions,
                                            isAscending,
                                            baseColumnPositions.length);
			}
		}

		/* Now add the rows from the base table to the conglomerate.
		 * We do this by scanning the base table and inserting the
		 * rows into a sorter before inserting from the sorter
		 * into the index.  This gives us better performance
		 * and a more compact index.
		 */

		rowSource = null;
		sortId = 0;
		boolean needToDropSort = false;	// set to true once the sorter is created

		/* bulkFetchSIze will be 16 (for now) unless
		 * we are creating the table in which case it
		 * will be 1.  Too hard to remove scan when
		 * creating index on new table, so minimize
		 * work where we can.
		 */
		int bulkFetchSize = (forCreateTable) ? 1 : 16;	
		int numColumns = td.getNumberOfColumns();
		int approximateRowSize = 0;

		// Create the FormatableBitSet for mapping the partial to full base row
		FormatableBitSet bitSet = new FormatableBitSet(numColumns+1);
		for (int index = 0; index < baseColumnPositions.length; index++)
		{
			bitSet.set(baseColumnPositions[index]);
		}
		FormatableBitSet zeroBasedBitSet = RowUtil.shift(bitSet, 1);

		// Start by opening a full scan on the base table.
		scan = tc.openGroupFetchScan(
                            td.getHeapConglomerateId(),
							false,	// hold
							0,	// open base table read only
                            TransactionController.MODE_TABLE,
                            TransactionController.ISOLATION_SERIALIZABLE,
							zeroBasedBitSet,    // all fields as objects
							(DataValueDescriptor[]) null,	// startKeyValue
							0,		// not used when giving null start posn.
							null,	// qualifier
							(DataValueDescriptor[]) null,	// stopKeyValue
							0);		// not used when giving null stop posn.

		// Create an array to put base row template
		baseRows = new ExecRow[bulkFetchSize];
		indexRows = new ExecIndexRow[bulkFetchSize];
		compactBaseRows = new ExecRow[bulkFetchSize];

		try
		{
			// Create the array of base row template
			for (int i = 0; i < bulkFetchSize; i++)
			{
				// create a base row template
				baseRows[i] = activation.getExecutionFactory().getValueRow(maxBaseColumnPosition);

				// create an index row template
				indexRows[i] = indexRowGenerator.getIndexRowTemplate();

				// create a compact base row template
				compactBaseRows[i] = activation.getExecutionFactory().getValueRow(
													baseColumnPositions.length);
			}

			indexTemplateRow = indexRows[0];

			// Fill the partial row with nulls of the correct type
			ColumnDescriptorList cdl = td.getColumnDescriptorList();
			int					 cdlSize = cdl.size();
			for (int index = 0, numSet = 0; index < cdlSize; index++)
			{
				if (! zeroBasedBitSet.get(index))
				{
					continue;
				}
				numSet++;
				ColumnDescriptor cd = (ColumnDescriptor) cdl.elementAt(index);
				DataTypeDescriptor dts = cd.getType();


				for (int i = 0; i < bulkFetchSize; i++)
				{
					// Put the column in both the compact and sparse base rows
					baseRows[i].setColumn(index + 1,
								  dts.getNull());
					compactBaseRows[i].setColumn(numSet,
								  baseRows[i].getColumn(index + 1));
				}

				// Calculate the approximate row size for the index row
				approximateRowSize += dts.getTypeId().getApproximateLengthInBytes(dts);
			}

			// Get an array of RowLocation template
			RowLocation rl[] = new RowLocation[bulkFetchSize];
			for (int i = 0; i < bulkFetchSize; i++)
			{
				rl[i] = scan.newRowLocationTemplate();

				// Get an index row based on the base row
				indexRowGenerator.getIndexRow(compactBaseRows[i], rl[i], indexRows[i], bitSet);
			}

			/* now that we got indexTemplateRow, done for sharing index
			 */
			if (shareExisting)
				return;

			/* For non-unique indexes, we order by all columns + the RID.
			 * For unique indexes, we just order by the columns.
			 * We create a unique index observer for unique indexes
			 * so that we can catch duplicate key.
			 * We create a basic sort observer for non-unique indexes
			 * so that we can reuse the wrappers during an external
			 * sort.
			 */
			int             numColumnOrderings;
			SortObserver    sortObserver   = null;
            Properties      sortProperties = null;
			if (unique || uniqueWithDuplicateNulls)
			{
				// if the index is a constraint, use constraintname in 
                // possible error message
				String indexOrConstraintName = indexName;
				if  (conglomerateUUID != null)
				{
					ConglomerateDescriptor cd = 
                        dd.getConglomerateDescriptor(conglomerateUUID);
					if ((isConstraint) && 
                        (cd != null && cd.getUUID() != null && td != null))
					{
						ConstraintDescriptor conDesc = 
                            dd.getConstraintDescriptor(td, cd.getUUID());
						indexOrConstraintName = conDesc.getConstraintName();
					}
				}

				if (unique) 
				{
                    numColumnOrderings = baseColumnPositions.length;

					sortObserver = 
                        new UniqueIndexSortObserver(
                                true, 
                                isConstraint, 
                                indexOrConstraintName,
                                indexTemplateRow,
                                true,
                                td.getName());
				}
				else 
                {
                    // unique with duplicate nulls allowed.

					numColumnOrderings = baseColumnPositions.length + 1;

                    // tell transaction controller to use the unique with 
                    // duplicate nulls sorter, when making createSort() call.
					sortProperties = new Properties();
					sortProperties.put(
                        AccessFactoryGlobals.IMPL_TYPE, 
                        AccessFactoryGlobals.SORT_UNIQUEWITHDUPLICATENULLS_EXTERNAL);
					//use sort operator which treats nulls unequal
					sortObserver = 
                        new UniqueWithDuplicateNullsIndexSortObserver(
                                true, 
                                isConstraint, 
                                indexOrConstraintName,
                                indexTemplateRow,
                                true,
                                td.getName());
				}
			}
			else
			{
				numColumnOrderings = baseColumnPositions.length + 1;
				sortObserver = new BasicSortObserver(true, false, 
													 indexTemplateRow,
													 true);
			}

			ColumnOrdering[]	order = new ColumnOrdering[numColumnOrderings];
			for (int i=0; i < numColumnOrderings; i++) 
			{
				order[i] = 
                    new IndexColumnOrder(
                        i, 
                        unique || i < numColumnOrderings - 1 ? 
                            isAscending[i] : true);
			}

			// create the sorter
			sortId = tc.createSort((Properties)sortProperties, 
					indexTemplateRow.getRowArrayClone(),
					order,
					sortObserver,
					false,			// not in order
					scan.getEstimatedRowCount(),
					approximateRowSize	// est row size, -1 means no idea	
					);

			needToDropSort = true;

			// Populate sorter and get the output of the sorter into a row
			// source.  The sorter has the indexed columns only and the columns
			// are in the correct order. 
			rowSource = loadSorter(baseRows, indexRows, tc,
								   scan, sortId, rl);

			conglomId = 
                tc.createAndLoadConglomerate(
					indexType,
					indexTemplateRow.getRowArray(),	// index row template
					order, //colums sort order
                    indexRowGenerator.getColumnCollationIds(
                        td.getColumnDescriptorList()),
					indexProperties,
					TransactionController.IS_DEFAULT, // not temporary
					rowSource,
					(long[]) null);
			
		}
		finally
		{

			/* close the table scan */
			if (scan != null)
				scan.close();

			/* close the sorter row source before throwing exception */
			if (rowSource != null)
				rowSource.closeRowSource();

			/*
			** drop the sort so that intermediate external sort run can be
			** removed from disk
			*/
			if (needToDropSort)
			 	tc.dropSort(sortId);
		}

		ConglomerateController indexController =
			tc.openConglomerate(
                conglomId, false, 0, TransactionController.MODE_TABLE,
                TransactionController.ISOLATION_SERIALIZABLE);

		// Check to make sure that the conglomerate can be used as an index
		if ( ! indexController.isKeyed())
		{
			indexController.close();
			throw StandardException.newException(SQLState.LANG_NON_KEYED_INDEX, indexName,
														   indexType);
		}
		indexController.close();

		//
		// Create a conglomerate descriptor with the conglomId filled
		// in and add it--if we don't have one already.
		//
		if (!alreadyHaveConglomDescriptor)
		{
			ConglomerateDescriptor cgd =
				ddg.newConglomerateDescriptor(
					conglomId, indexName, true,
					indexRowGenerator, isConstraint,
					conglomerateUUID, td.getUUID(), sd.getUUID() );

			dd.addDescriptor(cgd, sd,
				DataDictionary.SYSCONGLOMERATES_CATALOG_NUM, false, tc);

			// add newly added conglomerate to the list of conglomerate
			// descriptors in the td.
			ConglomerateDescriptorList cdl = td.getConglomerateDescriptorList();
			cdl.add(cgd);

			/* Since we created a new conglomerate descriptor, load
			 * its UUID into the corresponding field, to ensure that
			 * it is properly set in the StatisticsDescriptor created
			 * below.
			 */
			conglomerateUUID = cgd.getUUID();
		}

		CardinalityCounter cCount = (CardinalityCounter)rowSource;

        long numRows = cCount.getRowCount();
        if (addStatistics(dd, indexRowGenerator, numRows))
		{
			long[] c = cCount.getCardinality();
			for (int i = 0; i < c.length; i++)
			{
				StatisticsDescriptor statDesc = 
					new StatisticsDescriptor(dd,
						dd.getUUIDFactory().createUUID(),
						conglomerateUUID, td.getUUID(), ""I"",
						new StatisticsImpl(numRows, c[i]), i + 1);

				dd.addDescriptor(statDesc, null, 
								 DataDictionary.SYSSTATISTICS_CATALOG_NUM,
								 true, tc);
			}
		}
	}"
https://github.com/apache/derby/tree/eea0d50c8d732cad9ba563ddfa786b7028eb092f//java/engine/org/apache/derby/impl/sql/execute/CreateTableConstantAction.java,executeConstantAction,open,"public void	executeConstantAction( Activation activation )
		throws StandardException
	{
		TableDescriptor 			td;
		UUID 						toid;
		SchemaDescriptor			schemaDescriptor;
		ColumnDescriptor			columnDescriptor;
		ExecRow						template;

		LanguageConnectionContext lcc = activation.getLanguageConnectionContext();
		DataDictionary dd = lcc.getDataDictionary();
		DependencyManager dm = dd.getDependencyManager();
		TransactionController tc = lcc.getTransactionExecute();

		/* Mark the activation as being for create table */
		activation.setForCreateTable();

        // setup for create conglomerate call:
        //   o create row template to tell the store what type of rows this
        //     table holds.
        //   o create array of collation id's to tell collation id of each
        //     column in table.
		template            = RowUtil.getEmptyValueRow(columnInfo.length, lcc);
        int[] collation_ids = new int[columnInfo.length];

		for (int ix = 0; ix < columnInfo.length; ix++)
		{
            ColumnInfo  col_info = columnInfo[ix];

            // Get a template value for each column

			if (col_info.defaultValue != null)
            {
                /* If there is a default value, use it, otherwise use null */
				template.setColumn(ix + 1, col_info.defaultValue);
            }
			else
            {
				template.setColumn(ix + 1, col_info.dataType.getNull());
            }

            // get collation info for each column.

            collation_ids[ix] = col_info.dataType.getCollationType();
		}


		/* create the conglomerate to hold the table's rows
		 * RESOLVE - If we ever have a conglomerate creator
		 * that lets us specify the conglomerate number then
		 * we will need to handle it here.
		 */
		long conglomId = tc.createConglomerate(
				""heap"", // we're requesting a heap conglomerate
				template.getRowArray(), // row template
				null, //column sort order - not required for heap
                collation_ids,
				properties, // properties
				tableType == TableDescriptor.GLOBAL_TEMPORARY_TABLE_TYPE ?
                    (TransactionController.IS_TEMPORARY | 
                     TransactionController.IS_KEPT) : 
                        TransactionController.IS_DEFAULT);

		/*
		** Inform the data dictionary that we are about to write to it.
		** There are several calls to data dictionary ""get"" methods here
		** that might be done in ""read"" mode in the data dictionary, but
		** it seemed safer to do this whole operation in ""write"" mode.
		**
		** We tell the data dictionary we're done writing at the end of
		** the transaction.
		*/
		if ( tableType != TableDescriptor.GLOBAL_TEMPORARY_TABLE_TYPE )
			dd.startWriting(lcc);

		SchemaDescriptor sd;
		if (tableType == TableDescriptor.GLOBAL_TEMPORARY_TABLE_TYPE)
			sd = dd.getSchemaDescriptor(schemaName, tc, true);
		else
			sd = DDLConstantAction.getSchemaDescriptorForCreate(dd, activation, schemaName);

		//
		// Create a new table descriptor.
		// 
		DataDescriptorGenerator ddg = dd.getDataDescriptorGenerator();

		if ( tableType != TableDescriptor.GLOBAL_TEMPORARY_TABLE_TYPE )
		{
			td = ddg.newTableDescriptor(tableName, sd, tableType, lockGranularity);
			dd.addDescriptor(td, sd, DataDictionary.SYSTABLES_CATALOG_NUM, false, tc);
		} else
		{
			td = ddg.newTableDescriptor(tableName, sd, tableType, onCommitDeleteRows, onRollbackDeleteRows);
			td.setUUID(dd.getUUIDFactory().createUUID());
		}
		toid = td.getUUID();

		// Save the TableDescriptor off in the Activation
		activation.setDDLTableDescriptor(td);

		/* NOTE: We must write the columns out to the system
		 * tables before any of the conglomerates, including
		 * the heap, since we read the columns before the
		 * conglomerates when building a TableDescriptor.
		 * This will hopefully reduce the probability of
		 * a deadlock involving those system tables.
		 */
		
		// for each column, stuff system.column
		int index = 1;

		ColumnDescriptor[] cdlArray = new ColumnDescriptor[columnInfo.length];
		for (int ix = 0; ix < columnInfo.length; ix++)
		{
			UUID defaultUUID = columnInfo[ix].newDefaultUUID;

			/* Generate a UUID for the default, if one exists
			 * and there is no default id yet.
			 */
			if (columnInfo[ix].defaultInfo != null &&
				defaultUUID == null)
			{
				defaultUUID = dd.getUUIDFactory().createUUID();
			}

			if (columnInfo[ix].autoincInc != 0)//dealing with autoinc column
			columnDescriptor = new ColumnDescriptor(
				                   columnInfo[ix].name,
								   index++,
								   columnInfo[ix].dataType,
								   columnInfo[ix].defaultValue,
								   columnInfo[ix].defaultInfo,
								   td,
								   defaultUUID,
								   columnInfo[ix].autoincStart,
								   columnInfo[ix].autoincInc,
								   columnInfo[ix].autoinc_create_or_modify_Start_Increment
							   );
			else
				columnDescriptor = new ColumnDescriptor(
		                   columnInfo[ix].name,
						   index++,
						   columnInfo[ix].dataType,
						   columnInfo[ix].defaultValue,
						   columnInfo[ix].defaultInfo,
						   td,
						   defaultUUID,
						   columnInfo[ix].autoincStart,
						   columnInfo[ix].autoincInc
					   );

			cdlArray[ix] = columnDescriptor;
		}

		if ( tableType != TableDescriptor.GLOBAL_TEMPORARY_TABLE_TYPE )
		{
			dd.addDescriptorArray(cdlArray, td,
							  DataDictionary.SYSCOLUMNS_CATALOG_NUM,
							  false, tc);
		}

		// now add the column descriptors to the table.
		ColumnDescriptorList cdl = td.getColumnDescriptorList();
		for (int i = 0; i < cdlArray.length; i++)
			cdl.add(cdlArray[i]);
				 
		//
		// Create a conglomerate desciptor with the conglomId filled in and
		// add it.
		//
		// RESOLVE: Get information from the conglomerate descriptor which
		//          was provided. 
		//
		ConglomerateDescriptor cgd =
			ddg.newConglomerateDescriptor(conglomId, null, false, null, false, null, toid,
										  sd.getUUID());
		if ( tableType != TableDescriptor.GLOBAL_TEMPORARY_TABLE_TYPE )
		{
			dd.addDescriptor(cgd, sd, DataDictionary.SYSCONGLOMERATES_CATALOG_NUM,
						 false, tc);
		}

		// add the newly added conglomerate to the table descriptor
		ConglomerateDescriptorList conglomList = td.getConglomerateDescriptorList();
		conglomList.add(cgd);

		/* Create any constraints */
		if (constraintActions != null)
		{
			/*
			** Do everything but FK constraints first,
			** then FK constraints on 2nd pass.
			*/
			for (int conIndex = 0; conIndex < constraintActions.length; conIndex++)
			{
				// skip fks
				if (!constraintActions[conIndex].isForeignKeyConstraint())
				{
					constraintActions[conIndex].executeConstantAction(activation);
				}
			}

			for (int conIndex = 0; conIndex < constraintActions.length; conIndex++)
			{
				// only foreign keys
				if (constraintActions[conIndex].isForeignKeyConstraint())
				{
					constraintActions[conIndex].executeConstantAction(activation);
				}
			}
		}

        //
        // Add dependencies. These can arise if a generated column depends
        // on a user created function.
        //
		for (int ix = 0; ix < columnInfo.length; ix++)
		{
            addColumnDependencies( lcc, dd, td, columnInfo[ ix ] );
        }

        //
        // The table itself can depend on the user defined types of its columns.
        //
        adjustUDTDependencies( lcc, dd, td, columnInfo, false );
        
		if ( tableType == TableDescriptor.GLOBAL_TEMPORARY_TABLE_TYPE )
		{
			lcc.addDeclaredGlobalTempTable(td);
		}

		// Indicate that the CREATE TABLE statement itself depends on the
		// table it is creating. Normally such statement dependencies are
		// added during compilation, but here we have a bootstrapping issue
		// because the table doesn't exist until the CREATE TABLE statement
		// has been executed, so we had to defer the creation of this
		// dependency until now. (DERBY-4479)
		dd.getDependencyManager().addDependency(
			activation.getPreparedStatement(), td, lcc.getContextManager());

	}"
https://github.com/apache/derby/tree/eea0d50c8d732cad9ba563ddfa786b7028eb092f//java/engine/org/apache/derby/impl/sql/execute/CreateTriggerConstantAction.java,executeConstantAction,close,"public void	executeConstantAction(Activation activation)
						throws StandardException
	{
		SPSDescriptor				whenspsd = null;
		SPSDescriptor				actionspsd;

		LanguageConnectionContext lcc = activation.getLanguageConnectionContext();
		DataDictionary dd = lcc.getDataDictionary();
		DependencyManager dm = dd.getDependencyManager();
		TransactionController tc = lcc.getTransactionExecute();

		/*
		** Indicate that we are about to modify the data dictionary.
		** 
		** We tell the data dictionary we're done writing at the end of
		** the transaction.
		*/
		dd.startWriting(lcc);

		SchemaDescriptor triggerSd = getSchemaDescriptorForCreate(dd, activation, triggerSchemaName);

		if (spsCompSchemaId == null) {
			SchemaDescriptor def = lcc.getDefaultSchema();
			if (def.getUUID() == null) {
				// Descriptor for default schema is stale,
				// look it up in the dictionary
				def = dd.getSchemaDescriptor(def.getDescriptorName(), tc, 
											 false);
			}
			
			/* 
			** It is possible for spsCompSchemaId to be null.  For instance, 
			** the current schema may not have been physically created yet but 
			** it exists ""virtually"".  In this case, its UUID will have the 
			** value of null meaning that it is not persistent.  e.g.:   
			**
			** CONNECT 'db;create=true' user 'ernie';
			** CREATE TABLE bert.t1 (i INT);
			** CREATE TRIGGER bert.tr1 AFTER INSERT ON bert.t1 
			**    FOR EACH STATEMENT MODE DB2SQL 
			**    SELECT * FROM SYS.SYSTABLES;
			**
			** Note that in the above case, the trigger action statement have a 
			** null compilation schema.  A compilation schema with null value 
			** indicates that the trigger action statement text does not have 
			** any dependencies with the CURRENT SCHEMA.  This means:
			**
			** o  It is safe to compile this statement in any schema since 
			**    there is no dependency with the CURRENT SCHEMA. i.e.: All 
			**    relevent identifiers are qualified with a specific schema.
			**
			** o  The statement cache mechanism can utilize this piece of 
			**    information to enable better statement plan sharing across 
			**    connections in different schemas; thus, avoiding unnecessary 
			**    statement compilation.
			*/ 
			if (def != null)
				spsCompSchemaId = def.getUUID();
		}

		String tabName;
		if (triggerTable != null)
		{
			triggerTableId = triggerTable.getUUID();
			tabName = triggerTable.getName();
		}
		else
			tabName = ""with UUID "" + triggerTableId;

		/* We need to get table descriptor again.  We simply can't trust the
		 * one we got at compile time, the lock on system table was released
		 * when compile was done, and the table might well have been dropped.
		 */
		triggerTable = dd.getTableDescriptor(triggerTableId);
		if (triggerTable == null)
		{
			throw StandardException.newException(
								SQLState.LANG_TABLE_NOT_FOUND_DURING_EXECUTION,
								tabName);
		}
		/* Lock the table for DDL.  Otherwise during our execution, the table
		 * might be changed, even dropped.  Beetle 4269
		 */
		lockTableForDDL(tc, triggerTable.getHeapConglomerateId(), true);
		/* get triggerTable again for correctness, in case it's changed before
		 * the lock is aquired
		 */
		triggerTable = dd.getTableDescriptor(triggerTableId);
		if (triggerTable == null)
		{
			throw StandardException.newException(
								SQLState.LANG_TABLE_NOT_FOUND_DURING_EXECUTION,
								tabName);
		}

		/*
		** Send an invalidate on the table from which
		** the triggering event emanates.  This it
		** to make sure that DML statements on this table
		** will be recompiled.  Do this before we create
		** our trigger spses lest we invalidate them just
		** after creating them.
		*/
		dm.invalidateFor(triggerTable, DependencyManager.CREATE_TRIGGER, lcc);

		/*
		** Lets get our trigger id up front, we'll use it when
	 	** we create our spses.
		*/
		UUID tmpTriggerId = dd.getUUIDFactory().createUUID();

		actionSPSId = (actionSPSId == null) ? 
			dd.getUUIDFactory().createUUID() : actionSPSId;
 
		DataDescriptorGenerator ddg = dd.getDataDescriptorGenerator();

		/*
		** Create the trigger descriptor first so the trigger action
		** compilation can pick up the relevant trigger especially in 
		** the case of self triggering.
		*/
		TriggerDescriptor triggerd =
				ddg.newTriggerDescriptor(
									triggerSd,
									tmpTriggerId,
									triggerName,
									eventMask,
									isBefore,
									isRow,
									isEnabled,
									triggerTable,
									whenspsd == null ? null : whenspsd.getUUID(),
									actionSPSId,
									creationTimestamp == null ? new Timestamp(System.currentTimeMillis()) : creationTimestamp,
									referencedCols,
									referencedColsInTriggerAction,
									originalActionText,
									referencingOld,
									referencingNew,
									oldReferencingName,
									newReferencingName);


		dd.addDescriptor(triggerd, triggerSd,
								DataDictionary.SYSTRIGGERS_CATALOG_NUM, false,
								tc);


		/*	
		** If we have a WHEN action we create it now.
		*/
		if (whenText != null)
		{
			whenspsd = createSPS(lcc, ddg, dd, tc, tmpTriggerId, triggerSd,
						whenSPSId, spsCompSchemaId, whenText, true, triggerTable);
		}

		/*
		** Create the trigger action
		*/
		actionspsd = createSPS(lcc, ddg, dd, tc, tmpTriggerId, triggerSd,
						actionSPSId, spsCompSchemaId, actionText, false, triggerTable);
		
		/*
		** Make underlying spses dependent on the trigger.
		*/
		if (whenspsd != null)
		{
			dm.addDependency(triggerd, whenspsd, lcc.getContextManager());
		}
		dm.addDependency(triggerd, actionspsd, lcc.getContextManager());
		dm.addDependency(triggerd, triggerTable, lcc.getContextManager());
		//store trigger's dependency on various privileges in the dependeny system
		storeViewTriggerDependenciesOnPrivileges(activation, triggerd);		
	}"
https://github.com/apache/derby/tree/eea0d50c8d732cad9ba563ddfa786b7028eb092f//java/engine/org/apache/derby/impl/sql/execute/CurrentDatetime.java,getCurrentDate,open,"public Date getCurrentDate() {
		if (currentDate == null) {
			setCurrentDatetime();
			currentDate = new Date(currentDatetime.getTime());
		}
		return currentDate;
	}"
https://github.com/apache/derby/tree/eea0d50c8d732cad9ba563ddfa786b7028eb092f//java/engine/org/apache/derby/impl/sql/execute/CurrentDatetime.java,getCurrentTimestamp,open,"public Timestamp getCurrentTimestamp() {
		if (currentTimestamp == null) {
			setCurrentDatetime();
			currentTimestamp = new Timestamp(currentDatetime.getTime());
		}
		return currentTimestamp;
	}"
https://github.com/apache/derby/tree/eea0d50c8d732cad9ba563ddfa786b7028eb092f//java/engine/org/apache/derby/impl/sql/execute/CurrentOfResultSet.java,getNextRowCore,open,"public ExecRow	getNextRowCore() throws StandardException {

		if ( isOpen ) {
	        if ( ! next ) {
	            next = true;
				if (SanityManager.DEBUG)
					SanityManager.ASSERT(! cursor.isClosed(), ""cursor closed"");

				ExecRow cursorRow = cursor.getCurrentRow();

				// requalify the current row
				if (cursorRow == null) {
					throw StandardException.newException(SQLState.NO_CURRENT_ROW);
				}
				// we know it will be requested, may as well get it now.
				rowLocation = cursor.getRowLocation();

				// get the row from the base table, which is the real result
				// row for the CurrentOfResultSet
				currentRow = target.getCurrentRow();

				// if the source result set is a ScrollInsensitiveResultSet, and
				// the current row has been deleted (while the cursor was 
				// opened), the cursor result set (scroll insensitive) will 
				// return the cached row, while the target result set will 
				// return null (row has been deleted under owr feet).
				if (rowLocation == null  || 
						(cursorRow != null && currentRow == null)) {
					activation.addWarning(StandardException.
							newWarning(SQLState.CURSOR_OPERATION_CONFLICT));
					return null;
				}

				/* beetle 3865: updateable cursor using index.  If underlying is a covering
				 * index, target is a TableScanRS (instead of a IndexRow2BaseRowRS) for the
				 * index scan.  But the problem is it returns a compact row in index key order.
				 * However the ProjectRestrictRS above us that sets up the old and new column
				 * values expects us to return a sparse row in heap order.  We have to do the
				 * wiring here, since we don't have IndexRow2BaseRowRS to do this work.  This
				 * problem was not exposed before, because we never used index scan for updateable
				 * cursors.
				 */
				if (target instanceof TableScanResultSet)
				{
					TableScanResultSet scan = (TableScanResultSet) target;
					if (scan.indexCols != null && currentRow != null)
						currentRow = getSparseRow(currentRow, scan.indexCols);
				}

				// REMIND: verify the row is still there
				// at present we get an ugly exception from the store,
				// Hopefully someday we can just do this:
				//
				// if (!rowLocation.rowExists())
				//     throw StandardException.newException(SQLState.LANG_NO_CURRENT_ROW, cursorName);
			}
			else {
				currentRow = null;
				rowLocation = null;
			}
	    }
		else {
			currentRow = null;
			rowLocation = null;
		}
		setCurrentRow(currentRow);
	    return currentRow;
	}"
https://github.com/apache/derby/tree/eea0d50c8d732cad9ba563ddfa786b7028eb092f//java/engine/org/apache/derby/impl/sql/execute/DDLConstantAction.java,findRoleUsage,close,"private static PermissionsDescriptor findRoleUsage
		(Activation activation,
		 StatementPermission statPerm) throws StandardException {

		LanguageConnectionContext lcc =
			activation.getLanguageConnectionContext();
		DataDictionary dd = lcc.getDataDictionary();
		RoleGrantDescriptor rootGrant = null;
		String role = lcc.getCurrentRoleId(activation);
		String dbo = dd.getAuthorizationDatabaseOwner();
        String currentUser = lcc.getCurrentUserId(activation);
		PermissionsDescriptor permDesc = null;

		if (SanityManager.DEBUG) {
			SanityManager.ASSERT(
				role != null,
				""Unexpected: current role is not set"");
		}

		// determine how we got to be able use this role
		rootGrant =
            dd.getRoleGrantDescriptor(role, currentUser, dbo);

		if (rootGrant == null) {
			rootGrant = dd.getRoleGrantDescriptor(
				role,
				Authorizer.PUBLIC_AUTHORIZATION_ID,
				dbo);
		}

		// If not found in current role, get transitive
		// closure of roles granted to current role and
		// iterate over it to see if permission has
		// been granted to any of the roles the current
		// role inherits.
		RoleClosureIterator rci =
			dd.createRoleClosureIterator
			(activation.getTransactionController(),
			 role, true /* inverse relation*/);

		String graphGrant;
		while (permDesc == null &&
			   (graphGrant = rci.next()) != null) {
			permDesc =
				statPerm.getPermissionDescriptor
				(graphGrant, dd);
		}

		if (SanityManager.DEBUG) {
			SanityManager.ASSERT(
				permDesc != null,
				""Unexpected: Permission needs to be found via role"");
		}

		return permDesc;
	}"
https://github.com/apache/derby/tree/eea0d50c8d732cad9ba563ddfa786b7028eb092f//java/engine/org/apache/derby/impl/sql/execute/DDLConstantAction.java,storeConstraintDependenciesOnPrivileges,close,"protected void storeConstraintDependenciesOnPrivileges(
		Activation activation,
		Dependent dependent,
		UUID refTableUUID,
		ProviderInfo[] providers)
			throws StandardException
	{
		LanguageConnectionContext lcc = activation.getLanguageConnectionContext();
		DataDictionary dd = lcc.getDataDictionary();
		DependencyManager dm = dd.getDependencyManager();
		String dbo = dd.getAuthorizationDatabaseOwner();
        String currentUser = lcc.getCurrentUserId(activation);
		SettableBoolean roleDepAdded = new SettableBoolean();

		//If the Database Owner is creating this constraint, then no need to 
		//collect any privilege dependencies because the Database Owner can   
		//access any objects without any restrictions
        if (! currentUser.equals( dd.getAuthorizationDatabaseOwner()) )
		{
			PermissionsDescriptor permDesc;
			// Now, it is time to add into dependency system the FOREIGN
			// constraint's dependency on REFERENCES privilege, or, if it is a
			// CHECK constraint, any EXECUTE or USAGE privileges. If the REFERENCES is
			// revoked from the constraint owner, the constraint will get
			// dropped automatically.
			List requiredPermissionsList = activation.getPreparedStatement().getRequiredPermissionsList();

			if (requiredPermissionsList != null && ! requiredPermissionsList.isEmpty())
			{
				for(Iterator iter = requiredPermissionsList.iterator();iter.hasNext();)
				{
					StatementPermission statPerm = (StatementPermission) iter.next();
					//First check if we are dealing with a Table or 
					//Column level privilege. All the other privileges
					//are not required for a foreign key constraint.
					if (statPerm instanceof StatementTablePermission)
					{//It is a table/column level privilege
						StatementTablePermission statementTablePermission = 
							(StatementTablePermission) statPerm;
						//Check if we are dealing with REFERENCES privilege.
						//If not, move on to the next privilege in the
						//required privileges list
						if (statementTablePermission.getPrivType() != Authorizer.REFERENCES_PRIV)
							continue;
						//Next check is this REFERENCES privilege is 
						//on the same table as referenced by the foreign
						//key constraint? If not, move on to the next
						//privilege in the required privileges list
						if (!statementTablePermission.getTableUUID().equals(refTableUUID))
							continue;
					} else if (statPerm instanceof StatementSchemaPermission
						    || statPerm instanceof StatementRolePermission
                               || statPerm instanceof StatementGenericPermission ) {
						continue;
					} else {
						if (SanityManager.DEBUG) {
							SanityManager.ASSERT(
								statPerm instanceof StatementRoutinePermission,
								""only StatementRoutinePermission expected"");
						}

						// skip if this permission concerns a function not
						// referenced by this constraint
						StatementRoutinePermission rp =
							(StatementRoutinePermission)statPerm;
						if (!inProviderSet(providers, rp.getRoutineUUID())) {
							continue;
						}
					}


					// We know that we are working with a REFERENCES, EXECUTE, or USAGE
					// privilege. Find all the PermissionDescriptors for this
					// privilege and make constraint depend on it through
					// dependency manager.  The REFERENCES privilege could be
					// defined at the table level or it could be defined at
					// individual column levels. In addition, individual column
					// REFERENCES privilege could be available at the user
					// level, PUBLIC or role level.  EXECUTE and USAGE privileges could be
					// available at the user level, PUBLIC or role level.
                    permDesc = statPerm.getPermissionDescriptor(
                        currentUser, dd);

					if (permDesc == null) 
					{
						// No privilege exists for given user. The privilege
						// has to exist at at PUBLIC level....

						permDesc = statPerm.getPermissionDescriptor(Authorizer.PUBLIC_AUTHORIZATION_ID, dd);
						// .... or at the role level. Additionally, for column
						// level privileges, even if *some* were available at
						// the PUBLIC level others may be still be missing,
						// hence the call in the test below to
						// allColumnsCoveredByUserOrPUBLIC.
						boolean roleUsed = false;

						if (permDesc == null ||
							((permDesc instanceof ColPermsDescriptor) &&
                                 ! ((StatementColumnPermission)statPerm).
                                   allColumnsCoveredByUserOrPUBLIC(
                                       currentUser, dd))) {
							roleUsed = true;
							permDesc = findRoleUsage(activation, statPerm);
						}

						// If the user accessing the object is the owner of
						// that object, then no privilege tracking is needed
						// for the owner.
                        if (! permDesc.checkOwner(currentUser) ) {

                            dm.addDependency(dependent, permDesc,
											 lcc.getContextManager());

							if (roleUsed) {
								// We had to rely on role, so track that
								// dependency, too.
								trackRoleDependency
									(activation, dependent, roleDepAdded);
							}
						}
					} else
						//if the object on which permission is required is owned by the
						//same user as the current user, then no need to keep that
						//object's privilege dependency in the dependency system
                    if (! permDesc.checkOwner(currentUser))
					{
						dm.addDependency(dependent, permDesc, lcc.getContextManager());
						if (permDesc instanceof ColPermsDescriptor)
						{
							// The if statement above means we found a
							// REFERENCES privilege at column level for the
							// given authorizer. If this privilege doesn't
							// cover all the column , then there has to exisit
							// REFERENCES for the remaining columns at PUBLIC
							// level or at role level.  Get that permission
							// descriptor and save it in dependency system
							StatementColumnPermission
								statementColumnPermission = (
									StatementColumnPermission)statPerm;
							permDesc = statementColumnPermission.
                                getPUBLIClevelColPermsDescriptor(
                                    currentUser, dd);
							//Following if checks if some column level privileges
							//exist only at public level. If so, then the public
							//level column privilege dependency is added
							//into the dependency system
							if (permDesc != null &&
									permDesc.getObjectID() != null) {
								// User did not have all required column
								// permissions and at least one column is
								// covered by PUBLIC.
								dm.addDependency(dependent, permDesc,
												 lcc.getContextManager());
							}
							// Possibly, the current role has also been relied
							// upon.
							if (!statementColumnPermission.
                                    allColumnsCoveredByUserOrPUBLIC(
                                        currentUser, dd)) {
								// Role has been relied upon, so register a
								// dependency.
								trackRoleDependency
									(activation, dependent, roleDepAdded);
							}
						}
					}

					if (!(statPerm instanceof StatementRoutinePermission)) {
						//We have found the REFERENCES privilege for all the
						//columns in foreign key constraint and we don't
						//need to go through the rest of the privileges
						//for this sql statement.
						break;
					} else {
						// For EXECUTE privilege there may be several functions
						// referenced in the constraint, so continue looking.
					}
				}
			}
		}
		
	}"
https://github.com/apache/derby/tree/eea0d50c8d732cad9ba563ddfa786b7028eb092f//java/engine/org/apache/derby/impl/sql/execute/DependentResultSet.java,printPosition,open,"private String printPosition(int searchOperator, ExecIndexRow positioner)
	{
		String idt = """";
		String output = """";

		String searchOp = null;
		switch (searchOperator)
		{
			case ScanController.GE:
				searchOp = "">="";
				break;

			case ScanController.GT:
				searchOp = "">"";
				break;

			default:
				if (SanityManager.DEBUG)
				{
					SanityManager.THROWASSERT(""Unknown search operator "" +
												searchOperator);
				}

				// NOTE: This does not have to be internationalized because
				// this code should never be reached.
				searchOp = ""unknown value ("" + searchOperator + "")"";
				break;
		}

		if(positioner !=null)
		{
			output = output + ""\t"" +
				MessageService.getTextMessage(
										  SQLState.LANG_POSITIONER,
										  searchOp,
										  String.valueOf(positioner.nColumns())) +
				""\n"";

			output = output + ""\t"" +
				MessageService.getTextMessage(
											  SQLState.LANG_ORDERED_NULL_SEMANTICS) +
				""\n"";
			boolean colSeen = false;
			for (int position = 0; position < positioner.nColumns(); position++)
			{
				if (positioner.areNullsOrdered(position))
				{
					output = output + position + "" "";
					colSeen = true;
				}

				if (colSeen && position == positioner.nColumns() - 1) {
					output = output +  ""\n"";
				}
			}
		}
	
		return output;
	}"
https://github.com/apache/derby/tree/eea0d50c8d732cad9ba563ddfa786b7028eb092f//java/engine/org/apache/derby/impl/sql/execute/GenericAggregator.java,getAggregatorInstance,open,"ExecAggregator getAggregatorInstance()
		throws StandardException
	{
		ExecAggregator aggregatorInstance;
		if (cachedAggregator == null)
		{
			try
			{
				Class aggregatorClass = cf.loadApplicationClass(aggInfo.getAggregatorClassName());
				Object agg = aggregatorClass.newInstance();
				aggregatorInstance = (ExecAggregator)agg;
				cachedAggregator = aggregatorInstance;

				aggregatorInstance.setup
                    (
                     cf,
                     aggInfo.getAggregateName(),
                     aggInfo.getResultDescription().getColumnInfo()[ 0 ].getType()
                     );

			} catch (Exception e)
			{
				throw StandardException.unexpectedUserException(e);
			}
		}
		else
		{
			aggregatorInstance = cachedAggregator.newAggregator();
		}


		return aggregatorInstance;
	}"
https://github.com/apache/derby/tree/eea0d50c8d732cad9ba563ddfa786b7028eb092f//java/engine/org/apache/derby/impl/sql/execute/GrantRoleConstantAction.java,executeConstantAction,open,"public void executeConstantAction(Activation activation)
            throws StandardException {

        LanguageConnectionContext lcc =
            activation.getLanguageConnectionContext();
        DataDictionary dd = lcc.getDataDictionary();
        TransactionController tc = lcc.getTransactionExecute();
        DataDescriptorGenerator ddg = dd.getDataDescriptorGenerator();

        final String grantor = lcc.getCurrentUserId(activation);

        dd.startWriting(lcc);

        for (Iterator rIter = roleNames.iterator(); rIter.hasNext();) {
            String role = (String)rIter.next();

            if (role.equals(Authorizer.PUBLIC_AUTHORIZATION_ID)) {
                throw StandardException.
                    newException(SQLState.AUTH_PUBLIC_ILLEGAL_AUTHORIZATION_ID);
            }

            for (Iterator gIter = grantees.iterator(); gIter.hasNext();) {
                String grantee = (String)gIter.next();

                // check that role exists
                RoleGrantDescriptor rdDef =
                    dd.getRoleDefinitionDescriptor(role);

                if (rdDef == null) {
                    throw StandardException.
                        newException(SQLState.ROLE_INVALID_SPECIFICATION, role);
                }

                // Check that role is granted to us (or PUBLIC) with
                // WITH ADMIN option so we can grant it. For database
                // owner, a role definition always fulfills this
                // requirement.  If we implement granting with WITH ADMIN
                // option later, we need to look for a grant to us (or
                // PUBLIC) which has WITH ADMIN. The role definition
                // descriptor will not suffice in that case, so we
                // need something like:
                //
                // rdDef = dd.findRoleGrantWithAdminToRoleOrPublic(grantor)
                // if (rdDef != null) {
                //   :
                if (grantor.equals(lcc.getDataDictionary().
                                       getAuthorizationDatabaseOwner())) {
                    // All ok, we are database owner
                    if (SanityManager.DEBUG) {
                        SanityManager.ASSERT(
                            rdDef.getGrantee().equals(grantor),
                            ""expected database owner in role grant descriptor"");
                        SanityManager.ASSERT(
                            rdDef.isWithAdminOption(),
                            ""expected role definition to have ADMIN OPTION"");
                    }
                } else {
                    throw StandardException.newException
                        (SQLState.AUTH_ROLE_DBO_ONLY, ""GRANT role"");
                }

                // Has it already been granted?
                RoleGrantDescriptor rgd =
                    dd.getRoleGrantDescriptor(role, grantee, grantor);

                if (rgd != null &&
                        withAdminOption && !rgd.isWithAdminOption()) {

                    // NOTE: Never called yet, withAdminOption not yet
                    // implemented.

                    // Remove old descriptor and add a new one with admin
                    // option: cf. SQL 2003, section 12.5, general rule 3
                    rgd.drop(lcc);
                    rgd.setWithAdminOption(true);
                    dd.addDescriptor(rgd,
                                     null,  // parent
                                     DataDictionary.SYSROLES_CATALOG_NUM,
                                     false, // no duplicatesAllowed
                                     tc);
                } else if (rgd == null) {
                    // Check if the grantee is a role (if not, it is a user)
                    RoleGrantDescriptor granteeDef =
                        dd.getRoleDefinitionDescriptor(grantee);

                    if (granteeDef != null) {
                        checkCircularity(role, grantee, grantor, tc, dd);
                    }

                    rgd = ddg.newRoleGrantDescriptor(
                        dd.getUUIDFactory().createUUID(),
                        role,
                        grantee,
                        grantor, // dbo for now
                        withAdminOption,
                        false);  // not definition
                    dd.addDescriptor(
                        rgd,
                        null,  // parent
                        DataDictionary.SYSROLES_CATALOG_NUM,
                        false, // no duplicatesAllowed
                        tc);
                } // else exists already, no need to add
            }
        }
    }"
https://github.com/apache/derby/tree/eea0d50c8d732cad9ba563ddfa786b7028eb092f//java/engine/org/apache/derby/impl/sql/execute/HashScanResultSet.java,openCore,open,"public void	openCore() throws StandardException
	{
	    TransactionController tc;

		beginTime = getCurrentTimeMillis();
		if (SanityManager.DEBUG)
		    SanityManager.ASSERT( ! isOpen, ""HashScanResultSet already open"");

        // Get the current transaction controller
        tc = activation.getTransactionController();

		initIsolationLevel();

		if (startKeyGetter != null)
		{
			startPosition = (ExecIndexRow) startKeyGetter.invoke(activation);
			if (sameStartStopPosition)
			{
				stopPosition = startPosition;
			}
		}
		if (stopKeyGetter != null)
		{
			stopPosition = (ExecIndexRow) stopKeyGetter.invoke(activation);
		}

		// Check whether there are any comparisons with unordered nulls
		// on either the start or stop position.  If there are, we can
		// (and must) skip the scan, because no rows can qualify
		if (skipScan(startPosition, stopPosition))
		{
			// Do nothing
			;
		}
		else if (! hashtableBuilt)
		{
			DataValueDescriptor[] startPositionRow = 
                startPosition == null ? null : startPosition.getRowArray();
			DataValueDescriptor[] stopPositionRow = 
                stopPosition == null ? null : stopPosition.getRowArray();

            hashtable = 
                tc.createBackingStoreHashtableFromScan(
                    conglomId,          // conglomerate to open
                    (forUpdate ? TransactionController.OPENMODE_FORUPDATE : 0),
                    lockMode,
                    isolationLevel,
                    accessedCols, 
                    startPositionRow,   
                    startSearchOperator,
                    scanQualifiers,
                    stopPositionRow,   
                    stopSearchOperator,
                    -1,                 // no limit on total rows.
                    keyColumns,      
                    eliminateDuplicates,// remove duplicates?
                    -1,                 // RESOLVE - is there a row estimate?
                    maxCapacity,
                    initialCapacity,    // in memory Hashtable initial capacity
                    loadFactor,         // in memory Hashtable load factor
                    runTimeStatisticsOn,
					skipNullKeyColumns,
					keepAfterCommit);


			if (runTimeStatisticsOn)
			{
				hashtableSize = hashtable.size();

				if (scanProperties == null)
				{
					scanProperties = new Properties();
				}

				try
				{
					if (hashtable != null)
					{
                        hashtable.getAllRuntimeStats(scanProperties);
					}
				}
				catch(StandardException se)
				{
					// ignore
				}
			}


			/* Remember that we created the hash table */
			hashtableBuilt = true;

			/*
			** Tell the activation about the number of qualifying rows.
			** Do this only here, not in reopen, because we don't want
			** to do this costly operation too often.
			*/
			activation.informOfRowCount(this, (long) hashtableSize);
		}

	    isOpen = true;

		resetProbeVariables();

		numOpens++;
		openTime += getElapsedMillis(beginTime);
	}"
https://github.com/apache/derby/tree/eea0d50c8d732cad9ba563ddfa786b7028eb092f//java/engine/org/apache/derby/impl/sql/execute/HashScanResultSet.java,printPosition,open,"private String printPosition(int searchOperator,
								 GeneratedMethod positionGetter,
								 ExecIndexRow eiRow)
	{
		String idt = """";

		String output = """";
		if (positionGetter == null)
		{
			return ""\t"" +
					MessageService.getTextMessage(SQLState.LANG_NONE) +
					""\n"";
		}

		ExecIndexRow	positioner = null;

		try
		{
			positioner = (ExecIndexRow) positionGetter.invoke(activation);
		}
		catch (StandardException e)
		{

			if (eiRow == null)
			{
				return ""\t"" + MessageService.getTextMessage(
											SQLState.LANG_POSITION_NOT_AVAIL);
			}
			return ""\t"" + MessageService.getTextMessage(
							SQLState.LANG_UNEXPECTED_EXC_GETTING_POSITIONER) +
							""\n"";
		}

		if (positioner == null)
		{
			return ""\t"" +
					MessageService.getTextMessage(SQLState.LANG_NONE) +
					""\n"";
		}

		String searchOp = null;

		switch (searchOperator)
		{
			case ScanController.GE:
				searchOp = "">="";
				break;

			case ScanController.GT:
				searchOp = "">"";
				break;

			default:
				if (SanityManager.DEBUG)
				{
					SanityManager.THROWASSERT(""Unknown search operator "" +
												searchOperator);
				}

				// This is not internationalized because we should never
				// reach here.
				searchOp = ""unknown value ("" + searchOperator + "")"";
				break;
		}

		output += ""\t"" + MessageService.getTextMessage(
										SQLState.LANG_POSITIONER,
										searchOp,
										String.valueOf(positioner.nColumns()))
										+ ""\n"";
			
		output += ""\t"" + MessageService.getTextMessage(
										SQLState.LANG_ORDERED_NULL_SEMANTICS) +
										""\n"";
		boolean colSeen = false;
		for (int position = 0; position < positioner.nColumns(); position++)
		{
			if (positioner.areNullsOrdered(position))
			{
				output = output + position + "" "";
				colSeen = true;
			}

			if (colSeen && position == positioner.nColumns() - 1) {
				output = output +  ""\n"";
			}
		}
		
		return output;
	}"
https://github.com/apache/derby/tree/eea0d50c8d732cad9ba563ddfa786b7028eb092f//java/engine/org/apache/derby/impl/sql/execute/HashTableResultSet.java,getNextRowCore,open,"public ExecRow	getNextRowCore() throws StandardException {
	    ExecRow result = null;
		DataValueDescriptor[] columns = null;

		beginTime = getCurrentTimeMillis();
	    if ( isOpen )
	    {
			/* We use a do/while loop to ensure that we continue down
			 * the duplicate chain, if one exists, until we find a
			 * row that matches on all probe predicates (or the
			 * duplicate chain is exhausted.)
			 */
			do 
			{
				if (firstNext)
				{			  
					firstNext = false;

					/* Hash key could be either a single column or multiple 
                     * columns.  If a single column, then it is the datavalue 
                     * wrapper, otherwise it is a KeyHasher.
					 */
					Object hashEntry;
					if (keyColumns.length == 1)
					{
						hashEntry = ht.get(nextQualifiers[0][0].getOrderable());
					}
					else
					{
						KeyHasher mh = 
                            new KeyHasher(keyColumns.length);

						for (int index = 0; index < keyColumns.length; index++)
						{
                            // RESOLVE (mikem) - will need to change when we
                            // support OR's in qualifiers.
							mh.setObject(
                                index, nextQualifiers[0][index].getOrderable());
						}
						hashEntry = ht.get(mh);
					}

					if (hashEntry instanceof List)
					{
						entryVector = (List) hashEntry;
						entryVectorSize = entryVector.size();
						columns = 
                            (DataValueDescriptor[]) entryVector.get(0);
					}
					else
					{
						entryVector = null;
						entryVectorSize = 0;
						columns = (DataValueDescriptor[]) hashEntry;
					}
				}
				else if (numFetchedOnNext < entryVectorSize)
				{
					// We are walking a list and there are more rows left.
					columns = (DataValueDescriptor[]) 
                        entryVector.get(numFetchedOnNext);
				}

				if (columns != null)
				{
					if (SanityManager.DEBUG)
					{
						// Columns is really a Storable[]
						for (int i = 0; i < columns.length; i++)
						{
							if (! (columns[0] instanceof Storable))
							{
								SanityManager.THROWASSERT(
								""columns["" + i + ""] expected to be Storable, not "" +
								columns[i].getClass().getName());
							}
						}
					}

					// See if the entry satisfies all of the other qualifiers
					boolean qualifies = true;

					/* We've already ""evaluated"" the 1st keyColumns qualifiers 
                     * when we probed into the hash table, but we need to 
                     * evaluate them again here because of the behavior of 
                     * NULLs.  NULLs are treated as equal when building and 
                     * probing the hash table so that we only get a single 
                     * entry.  However, NULL does not equal NULL, so the 
                     * compare() method below will eliminate any row that
					 * has a key column containing a NULL.
					 */

                    // RESOLVE (mikem) will have to change when qualifiers 
                    // support OR's.

                    if (SanityManager.DEBUG)
                    {
                        // we don't support 2 d qualifiers yet.
                        SanityManager.ASSERT(nextQualifiers.length == 1);
                    }
					for (int index = 0; index < nextQualifiers[0].length; index++)
					{
                        Qualifier q = nextQualifiers[0][index];

						qualifies = 
                            columns[q.getColumnId()].compare(
                                q.getOperator(),
                                q.getOrderable(),
                                q.getOrderedNulls(),
                                q.getUnknownRV());

						if (q.negateCompareResult()) 
						{ 
							qualifies = !(qualifies);
						} 

						// Stop if any predicate fails
						if (! qualifies)
						{
							break;
						}
					}

					if (qualifies)
					{

						for (int index = 0; index < columns.length; index++)
						{
							nextCandidate.setColumn(index + 1, columns[index]);
						}

						result = doProjection(nextCandidate);
					}
					else
					{
						result = null;
					}

					numFetchedOnNext++;
				}
				else
				{
					result = null;
				}
			}
			while (result == null && numFetchedOnNext < entryVectorSize);
		}

		setCurrentRow(result);

		nextTime += getElapsedMillis(beginTime);

		if (runTimeStatsOn)
		{
			if (! isTopResultSet)
			{
				/* This is simply for RunTimeStats */
				/* We first need to get the subquery tracking array via the StatementContext */
				StatementContext sc = activation.getLanguageConnectionContext().getStatementContext();
				subqueryTrackingArray = sc.getSubqueryTrackingArray();
			}
			nextTime += getElapsedMillis(beginTime);
		}
    	return result;
	}"
https://github.com/apache/derby/tree/eea0d50c8d732cad9ba563ddfa786b7028eb092f//java/engine/org/apache/derby/impl/sql/execute/IndexSetChanger.java,open,open,"public void open(boolean[] fixOnUpdate)
		 throws StandardException
	{
		if (SanityManager.DEBUG)
		    SanityManager.ASSERT( ! isOpen, ""IndexSetChanger already open"");

		this.fixOnUpdate = fixOnUpdate;
		isOpen = true;
	}"
https://github.com/apache/derby/tree/eea0d50c8d732cad9ba563ddfa786b7028eb092f//java/engine/org/apache/derby/impl/sql/execute/InsertConstantAction.java,getAutoincRowLocation,open,"public RowLocation[] getAutoincRowLocation()
	{
		return autoincRowLocation;
	}"
https://github.com/apache/derby/tree/eea0d50c8d732cad9ba563ddfa786b7028eb092f//java/engine/org/apache/derby/impl/sql/execute/ValueRow.java,getRowArray,open,"public DataValueDescriptor[] getRowArray() {
		return column;
	}"
https://github.com/apache/derby/tree/eea0d50c8d732cad9ba563ddfa786b7028eb092f//java/engine/org/apache/derby/impl/sql/execute/ValueRow.java,setRowArray,open,"public void setRowArray(DataValueDescriptor[] value)
	{
		column = value;
	}"
https://github.com/apache/derby/tree/eea0d50c8d732cad9ba563ddfa786b7028eb092f//java/engine/org/apache/derby/impl/sql/execute/rts/RunTimeStatisticsImpl.java,getEndCompilationTimestamp,close,"public Timestamp getEndCompilationTimestamp()
	{
		return endCompilationTimestamp;
	}"
https://github.com/apache/derby/tree/eea0d50c8d732cad9ba563ddfa786b7028eb092f//java/engine/org/apache/derby/impl/sql/execute/rts/RunTimeStatisticsImpl.java,getEndExecutionTimestamp,close,"public Timestamp getEndExecutionTimestamp()
	{
		return endExecutionTimestamp;
	}"
https://github.com/apache/derby/tree/eea0d50c8d732cad9ba563ddfa786b7028eb092f//java/engine/org/apache/derby/impl/sql/execute/rts/RunTimeStatisticsImpl.java,getBeginCompilationTimestamp,close,"public Timestamp getBeginCompilationTimestamp()
	{
		return beginCompilationTimestamp;
	}"
https://github.com/apache/derby/tree/eea0d50c8d732cad9ba563ddfa786b7028eb092f//java/engine/org/apache/derby/impl/sql/execute/rts/RunTimeStatisticsImpl.java,getBeginExecutionTimestamp,close,"public Timestamp getBeginExecutionTimestamp()
	{
		return beginExecutionTimestamp;
	}"
https://github.com/apache/derby/tree/eea0d50c8d732cad9ba563ddfa786b7028eb092f//java/engine/org/apache/derby/impl/sql/execute/xplain/XPLAINFactory.java,getXPLAINVisitor,open,"public XPLAINVisitor getXPLAINVisitor()
        throws StandardException
    {
        try
        {
            LanguageConnectionContext lcc = ConnectionUtil.getCurrentLCC();
            String schema = lcc.getXplainSchema();
            if (schema != currentSchema)
            {
                currentSchema = schema;
                if (currentSchema == null)
                    currentVisitor = new XPLAINDefaultVisitor();
                else
                    currentVisitor = new XPLAINSystemTableVisitor();
            }
        }
        catch (SQLException e)
        {
            throw StandardException.plainWrapException(e);
        }
        return currentVisitor;
    }"
https://github.com/apache/derby/tree/eea0d50c8d732cad9ba563ddfa786b7028eb092f//java/engine/org/apache/derby/impl/sql/execute/xplain/XPLAINSystemTableVisitor.java,addArraysToSystemCatalogs,open,"private void addArraysToSystemCatalogs()
        throws StandardException, SQLException
    {
        Iterator iter;
        boolean statsSave = lcc.getRunTimeStatisticsMode();
        lcc.setRunTimeStatisticsMode(false);
        Connection conn = getDefaultConn();

        PreparedStatement ps = conn.prepareStatement(
            (String)lcc.getXplainStatement(""SYSXPLAIN_RESULTSETS""));
        iter = rsets.iterator();
        while (iter.hasNext())
        {
            XPLAINResultSetDescriptor rset =
                (XPLAINResultSetDescriptor)iter.next();
            rset.setStatementParameters(ps);
            ps.executeUpdate();
        }
        ps.close();

        // add the resultset timings descriptors, if timing is on
        if(considerTimingInformation)
        {
            ps = conn.prepareStatement(
                (String)lcc.getXplainStatement(""SYSXPLAIN_RESULTSET_TIMINGS""));
            iter = rsetsTimings.iterator();
            while (iter.hasNext())
            {
                XPLAINResultSetTimingsDescriptor rsetT =
                    (XPLAINResultSetTimingsDescriptor)iter.next();
                rsetT.setStatementParameters(ps);
                ps.executeUpdate();
            }
            ps.close();
        }
        ps = conn.prepareStatement(
            (String)lcc.getXplainStatement(""SYSXPLAIN_SCAN_PROPS""));
        iter = scanrsets.iterator();
        while (iter.hasNext())
        {
            XPLAINScanPropsDescriptor scanProps =
                (XPLAINScanPropsDescriptor)iter.next();
            scanProps.setStatementParameters(ps);
            ps.executeUpdate();
        }
        ps.close();

        ps = conn.prepareStatement(
            (String)lcc.getXplainStatement(""SYSXPLAIN_SORT_PROPS""));
        iter = sortrsets.iterator();
        while (iter.hasNext())
        {
            XPLAINSortPropsDescriptor sortProps =
                (XPLAINSortPropsDescriptor)iter.next();
            sortProps.setStatementParameters(ps);
            ps.executeUpdate();
        }
        ps.close();

        conn.close();
        lcc.setRunTimeStatisticsMode(statsSave);
    }"
https://github.com/apache/derby/tree/eea0d50c8d732cad9ba563ddfa786b7028eb092f//java/engine/org/apache/derby/impl/sql/execute/xplain/XPLAINSystemTableVisitor.java,addStmtDescriptorsToSystemCatalog,open,"private void addStmtDescriptorsToSystemCatalog()
        throws StandardException, SQLException
    {
        boolean statsSave = lcc.getRunTimeStatisticsMode();
        lcc.setRunTimeStatisticsMode(false);
        Connection conn = getDefaultConn();
        PreparedStatement ps = conn.prepareStatement(
            (String)lcc.getXplainStatement(""SYSXPLAIN_STATEMENTS""));
        stmt.setStatementParameters(ps);
        ps.executeUpdate();
        ps.close();
            
        if(considerTimingInformation)
        {
            ps = conn.prepareStatement(
                (String)lcc.getXplainStatement(""SYSXPLAIN_STATEMENT_TIMINGS""));
            stmtTimings.setStatementParameters(ps);
            ps.executeUpdate();
            ps.close();
        }
        conn.close();
        lcc.setRunTimeStatisticsMode(statsSave);
    }"
https://github.com/apache/derby/tree/eea0d50c8d732cad9ba563ddfa786b7028eb092f//java/engine/org/apache/derby/impl/sql/execute/xplain/XPLAINSystemTableVisitor.java,addArraysToSystemCatalogs,open,"private void addArraysToSystemCatalogs()
        throws StandardException, SQLException
    {
        Iterator iter;
        boolean statsSave = lcc.getRunTimeStatisticsMode();
        lcc.setRunTimeStatisticsMode(false);
        Connection conn = getDefaultConn();

        PreparedStatement ps = conn.prepareStatement(
            (String)lcc.getXplainStatement(""SYSXPLAIN_RESULTSETS""));
        iter = rsets.iterator();
        while (iter.hasNext())
        {
            XPLAINResultSetDescriptor rset =
                (XPLAINResultSetDescriptor)iter.next();
            rset.setStatementParameters(ps);
            ps.executeUpdate();
        }
        ps.close();

        // add the resultset timings descriptors, if timing is on
        if(considerTimingInformation)
        {
            ps = conn.prepareStatement(
                (String)lcc.getXplainStatement(""SYSXPLAIN_RESULTSET_TIMINGS""));
            iter = rsetsTimings.iterator();
            while (iter.hasNext())
            {
                XPLAINResultSetTimingsDescriptor rsetT =
                    (XPLAINResultSetTimingsDescriptor)iter.next();
                rsetT.setStatementParameters(ps);
                ps.executeUpdate();
            }
            ps.close();
        }
        ps = conn.prepareStatement(
            (String)lcc.getXplainStatement(""SYSXPLAIN_SCAN_PROPS""));
        iter = scanrsets.iterator();
        while (iter.hasNext())
        {
            XPLAINScanPropsDescriptor scanProps =
                (XPLAINScanPropsDescriptor)iter.next();
            scanProps.setStatementParameters(ps);
            ps.executeUpdate();
        }
        ps.close();

        ps = conn.prepareStatement(
            (String)lcc.getXplainStatement(""SYSXPLAIN_SORT_PROPS""));
        iter = sortrsets.iterator();
        while (iter.hasNext())
        {
            XPLAINSortPropsDescriptor sortProps =
                (XPLAINSortPropsDescriptor)iter.next();
            sortProps.setStatementParameters(ps);
            ps.executeUpdate();
        }
        ps.close();

        conn.close();
        lcc.setRunTimeStatisticsMode(statsSave);
    }"
https://github.com/apache/derby/tree/eea0d50c8d732cad9ba563ddfa786b7028eb092f//java/engine/org/apache/derby/impl/sql/execute/xplain/XPLAINSystemTableVisitor.java,addStmtDescriptorsToSystemCatalog,open,"private void addStmtDescriptorsToSystemCatalog()
        throws StandardException, SQLException
    {
        boolean statsSave = lcc.getRunTimeStatisticsMode();
        lcc.setRunTimeStatisticsMode(false);
        Connection conn = getDefaultConn();
        PreparedStatement ps = conn.prepareStatement(
            (String)lcc.getXplainStatement(""SYSXPLAIN_STATEMENTS""));
        stmt.setStatementParameters(ps);
        ps.executeUpdate();
        ps.close();
            
        if(considerTimingInformation)
        {
            ps = conn.prepareStatement(
                (String)lcc.getXplainStatement(""SYSXPLAIN_STATEMENT_TIMINGS""));
            stmtTimings.setStatementParameters(ps);
            ps.executeUpdate();
            ps.close();
        }
        conn.close();
        lcc.setRunTimeStatisticsMode(statsSave);
    }"
https://github.com/apache/derby/tree/eea0d50c8d732cad9ba563ddfa786b7028eb092f//java/engine/org/apache/derby/impl/sql/execute/xplain/XPLAINUtil.java,getLockGranularityCode,open,"public static String getLockGranularityCode(String lockString){
         lockString = lockString.toUpperCase();
         if(lockString.endsWith(""TABLE"")){
             return LOCK_GRANULARITY_TABLE;
         } else {
             return LOCK_GRANULARITY_ROW;
         }
     }"
https://github.com/apache/derby/tree/eea0d50c8d732cad9ba563ddfa786b7028eb092f//java/engine/org/apache/derby/impl/sql/execute/xplain/XPLAINUtil.java,getLockModeCode,open,"public static String getLockModeCode(String lockString){
         lockString = lockString.toUpperCase();
         if(lockString.startsWith(""EXCLUSIVE"")){
             return LOCK_MODE_EXCLUSIVE;
         } else
         if(lockString.startsWith(""SHARE"")){
             return LOCK_MODE_SHARE;
         } else
         if(lockString.startsWith(""INSTANTANEOUS"")){
             int start = ""INSTANTANEOUS"".length();
             int length = lockString.length();
             String sub = lockString.substring(start+1, length);
             if (sub.startsWith(""EXCLUSIVE"")){
                 return LOCK_MODE_INSTANTENOUS_EXCLUSIVE;
             } else 
             if (sub.startsWith(""SHARE"")){
                 return LOCK_MODE_INSTANTENOUS_SHARE;
             } else 
             return null;
         } else
         return null;
     }"
https://github.com/apache/derby/tree/eea0d50c8d732cad9ba563ddfa786b7028eb092f//java/engine/org/apache/derby/impl/sql/execute/xplain/XPLAINUtil.java,getStatementType,open,"public static String getStatementType(String SQLText){
         String type = """";
         String text = SQLText.toUpperCase().trim();
         if (text.startsWith(""CALL"")){
             type = CALL_STMT_TYPE;
         } else 
         if (text.startsWith(""SELECT"")){
             if (text.indexOf(""~"")>-1){
                 type = SELECT_APPROXIMATE_STMT_TYPE;
             } else {
                 type = SELECT_STMT_TYPE;
             }
         } else
         if (text.startsWith(""DELETE"")){
             type = DELETE_STMT_TYPE;
         } else
         if (text.startsWith(""INSERT"")){
             type = INSERT_STMT_TYPE;
         } else
         if (text.startsWith(""UPDATE"")){
             type = UPDATE_STMT_TYPE;
         } else
         if (text.startsWith(""CREATE"") ||
             text.startsWith(""ALTER"")  ||
             text.startsWith(""DROP"")     ){
             type = DDL_STMT_TYPE;
         }
         return type;
     }"
https://github.com/apache/derby/tree/eea0d50c8d732cad9ba563ddfa786b7028eb092f//java/engine/org/apache/derby/impl/sql/execute/xplain/XPLAINUtil.java,getHashKeyColumnNumberString,open,"public static String getHashKeyColumnNumberString(int[] hashKeyColumns){
        // original derby encoding
        String hashKeyColumnString;
        if (hashKeyColumns.length == 1)
        {
            hashKeyColumnString = MessageService.getTextMessage(
                                                        SQLState.RTS_HASH_KEY) +
                                    "" "" + hashKeyColumns[0];
        }
        else
        {
            hashKeyColumnString = MessageService.getTextMessage(
                                                    SQLState.RTS_HASH_KEYS) +
                                    "" ("" + hashKeyColumns[0];
            for (int index = 1; index < hashKeyColumns.length; index++)
            {
                hashKeyColumnString = hashKeyColumnString + "","" + hashKeyColumns[index];
            }
            hashKeyColumnString = hashKeyColumnString + "")"";
        }
         return hashKeyColumnString;
     }"
https://github.com/apache/derby/tree/eea0d50c8d732cad9ba563ddfa786b7028eb092f//java/engine/org/apache/derby/impl/store/access/btree/OpenBTree.java,checkConsistency,open,"public void checkConsistency()
		throws StandardException
    {
		ControlRow root = null;

        try
        {
            if (this.container == null)
            {
                throw(StandardException.newException(
                        SQLState.BTREE_IS_CLOSED, new Long(err_containerid)));
            }

            if (SanityManager.DEBUG)
                SanityManager.ASSERT(this.init_conglomerate.format_ids != null);

            root = ControlRow.get(this, BTree.ROOTPAGEID);

            int actualpages = root.checkConsistency(this, null, true);

            // RESOLVE (mikem) - anything useful to assert about number of pages
            // in the tree?
        }
        finally
        {
            if (root != null)
                root.release();
        }
    }"
https://github.com/apache/derby/tree/eea0d50c8d732cad9ba563ddfa786b7028eb092f//java/engine/org/apache/derby/impl/store/access/btree/index/B2IRowLocking3.java,_lockScanRow,close,"protected boolean _lockScanRow(
    OpenBTree               open_btree,
    BTree                   btree,
    BTreeRowPosition        pos,
    boolean                 request_row_lock,
    FetchDescriptor         lock_fetch_desc,
    DataValueDescriptor[]   lock_template,
    RowLocation             lock_row_loc,
    boolean                 previous_key_lock,
    boolean                 forUpdate,
    int                     lock_operation)
		throws StandardException
    {
        boolean latch_released = false;
        B2I     b2i            = (B2I) btree;

        if (request_row_lock)
        {
            // In order to implement a serialized scan based on previous
            // key locking, this method acquires a row lock on
            // the base table's row from the index row at [startpage/startslot].
            // This will be the 'previous key'.

            if (pos.current_slot == 0)
            {
                // this call will take care of searching left in the btree
                // to find the previous row to lock, 0 is the control row and
                // not a valid thing to lock as a previous key.

                // it is ok to call the non-scan as this is just a special
                // case of a previous key lock call.  The only scan code that
                // will call this routine with slot == 0 will retry if this
                // routine returns that a latch was released.

                latch_released = 
                    !lockNonScanPreviousRow(
                        btree,
                        pos.current_leaf,
                        1 /* lock row previous to row at slot 1 */, 
                        lock_fetch_desc,
                        lock_template,
                        lock_row_loc,
                        open_btree, 
                        lock_operation,
                        TransactionManager.LOCK_COMMIT_DURATION);

                // special test to see if latch release code works
                if (SanityManager.DEBUG)
                {
                    latch_released = 
                        OpenBTree.test_errors(
                            open_btree,
                            ""B2iRowLocking3_1_lockScanRow"",
                            null, // Don't save position since the operation
                                  // will be retried if the latch was released.
                                  // See also comment above call to
                                  // lockNonScanPreviousRow().
                            this, pos.current_leaf, latch_released);
                }
            }
            else
            {
                // Just lock the row at ""slot""

                latch_released = 
                    !lockRowOnPage(
                        btree,
                        pos.current_leaf, 
                        (LeafControlRow) null /* no other latch currently */,
                        pos.current_slot, 
                        pos,
                        lock_fetch_desc,
                        lock_template,
                        lock_row_loc,
                        lock_operation,
                        TransactionManager.LOCK_COMMIT_DURATION);

                // special test to see if latch release code works
                if (SanityManager.DEBUG)
                {
                    latch_released = 
                        OpenBTree.test_errors(
                            open_btree,
                            ""B2iRowLocking3_2_lockScanRow"", pos,
                            this, pos.current_leaf, latch_released);
                }
            }
        }

        return(!latch_released);
    }"
https://github.com/apache/derby/tree/eea0d50c8d732cad9ba563ddfa786b7028eb092f//java/engine/org/apache/derby/impl/store/raw/data/RawField.java,getData,open,"public byte[] getData() {
		return data;
	}"
https://github.com/apache/derby/tree/eea0d50c8d732cad9ba563ddfa786b7028eb092f//java/engine/org/apache/derby/impl/store/raw/xact/GlobalXactId.java,getBranchQualifier,open,"public byte[] getBranchQualifier()
    {
        return(branch_id);
    }"
https://github.com/apache/derby/tree/eea0d50c8d732cad9ba563ddfa786b7028eb092f//java/engine/org/apache/derby/impl/store/raw/xact/GlobalXactId.java,getGlobalTransactionId,open,"public byte[] getGlobalTransactionId()
    {
        return(global_id);
    }"
https://github.com/apache/derby/tree/eea0d50c8d732cad9ba563ddfa786b7028eb092f//java/tools/org/apache/derby/impl/tools/ij/URLCheck.java,main,open,"public static void main(String[] args) {
    if (args.length > 0) {
      //Get the first argument passed in.
      URLCheck aCheck = new URLCheck(args[0]);
    }
  }"
https://github.com/apache/derby/tree/eea0d50c8d732cad9ba563ddfa786b7028eb092f//java/tools/org/apache/derby/impl/tools/ij/ijMultipleResultSetResult.java,getColumnWidthList,close,public int[] getColumnWidthList() { return columnWidths; }
https://github.com/apache/derby/tree/eea0d50c8d732cad9ba563ddfa786b7028eb092f//java/tools/org/apache/derby/impl/tools/ij/ijMultipleResultSetResult.java,getColumnDisplayList,close,public int[] getColumnDisplayList() { return displayColumns; }
https://github.com/apache/derby/tree/eea0d50c8d732cad9ba563ddfa786b7028eb092f//java/tools/org/apache/derby/impl/tools/ij/ijResultSetResult.java,getColumnWidthList,close,public int[] getColumnWidthList() { return columnWidths; }
https://github.com/apache/derby/tree/eea0d50c8d732cad9ba563ddfa786b7028eb092f//java/tools/org/apache/derby/impl/tools/ij/ijResultSetResult.java,getColumnDisplayList,close,public int[] getColumnDisplayList() { return displayColumns; }
https://github.com/apache/derby/tree/eea0d50c8d732cad9ba563ddfa786b7028eb092f//java/tools/org/apache/derby/impl/tools/ij/utilMain.java,runScriptGuts,open,"private int runScriptGuts() {

        int scriptErrorCount = 0;
		
		boolean done = false;
		String command = null;
		while (!ijParser.exit && !done) {
			try{
				ijParser.setConnection(connEnv[currCE], (numConnections > 1));
			} catch(Throwable t){
				//do nothing
				}

			connEnv[currCE].doPrompt(true, out);
   			try {
   				command = null;
				out.flush();
				command = commandGrabber[currCE].nextStatement();

				// if there is no next statement,
				// pop back to the top saved grabber.
				while (command == null && ! oldGrabbers.empty()) {
					// close the old input file if not System.in
					if (fileInput) commandGrabber[currCE].close();
					commandGrabber[currCE] = (StatementFinder)oldGrabbers.pop();
					if (oldGrabbers.empty())
						fileInput = initialFileInput;
					command = commandGrabber[currCE].nextStatement();
				}

				// if there are no grabbers left,
				// we are done.
				if (command == null && oldGrabbers.empty()) {
					done = true;
				}
				else {
					boolean	elapsedTimeOn = ijParser.getElapsedTimeState();
					long	beginTime = 0;
					long	endTime;

					if (fileInput) {
						out.println(command+"";"");
						out.flush();
					}

					charStream.ReInit(new StringReader(command), 1, 1);
					ijTokMgr.ReInit(charStream);
					ijParser.ReInit(ijTokMgr);

					if (elapsedTimeOn) {
						beginTime = System.currentTimeMillis();
					}

					ijResult result = ijParser.ijStatement();
					displayResult(out,result,connEnv[currCE].getConnection());

					// if something went wrong, an SQLException or ijException was thrown.
					// we can keep going to the next statement on those (see catches below).
					// ijParseException means we try the SQL parser.

					/* Print the elapsed time if appropriate */
					if (elapsedTimeOn) {
						endTime = System.currentTimeMillis();
						out.println(langUtil.getTextMessage(""IJ_ElapTime0Mil"", 
						langUtil.getNumberAsString(endTime - beginTime)));
					}

					// would like when it completes a statement
					// to see if there is stuff after the ;
					// and before the <EOL> that we will IGNORE
					// (with a warning to that effect)
				}

    			} catch (ParseException e) {
 					if (command != null)
                        scriptErrorCount += doCatch(command) ? 0 : 1;
				} catch (TokenMgrError e) {
 					if (command != null)
                        scriptErrorCount += doCatch(command) ? 0 : 1;
    			} catch (SQLException e) {
                    scriptErrorCount++;
					// SQL exception occurred in ij's actions; print and continue
					// unless it is considered fatal.
					handleSQLException(out,e);
    			} catch (ijException e) {
                    scriptErrorCount++;
					// exception occurred in ij's actions; print and continue
    			  	out.println(langUtil.getTextMessage(""IJ_IjErro0"",e.getMessage()));
					doTrace(e);
    			} catch (Throwable e) {
                    scriptErrorCount++;
    			  	out.println(langUtil.getTextMessage(""IJ_JavaErro0"",e.toString()));
					doTrace(e);
				}

			/* Go to the next connection/user, if there is one */
			currCE = ++currCE % connEnv.length;
		}
        
        return scriptErrorCount;
	}"
https://github.com/apache/derby/tree/eea0d50c8d732cad9ba563ddfa786b7028eb092f//java/tools/org/apache/derby/impl/tools/planexporter/AccessDatabase.java,getData,close,"public TreeNode[] getData() {
        return data;
    }"
https://github.com/apache/derby/tree/eea0d50c8d732cad9ba563ddfa786b7028eb092f//java/tools/org/apache/derby/impl/tools/planexporter/AccessDatabase.java,createXMLData,open,"private void createXMLData(String qry, int x) throws SQLException{

        PreparedStatement ps = conn.prepareStatement(qry);
        ps.setString(1, getQuery());

        ResultSet results = ps.executeQuery();

        int i=0;
        while(results.next())
        {
            String text= results.getString(1);

            if(text != null){

                /*Removing possible occurrences of special XML characters
                 * from XML node attributes in XML representation.*/
                text = escapeInAttribute(text);

                switch(x){
                case ID:
                    data[i].setId(text+"" "");
                    break;
                case P_ID:
                    data[i].setParent(text);
                    break;
                case NODE_TYPE:
                    data[i].setNodeType(text+"" "");
                    break;
                case NO_OF_OPENS:
                    data[i].setNoOfOpens(text+"" "");
                    break;
                case INPUT_ROWS:
                    data[i].setInputRows(text+"" "");
                    break;
                case RETURNED_ROWS:
                    data[i].setReturnedRows(text+"" "");
                    break;
                case VISITED_PAGES:
                    data[i].setVisitedPages(text+"" "");
                    break;
                case SCAN_QUALIFIERS:
                    data[i].setScanQualifiers(text+"" "");
                    break;
                case NEXT_QUALIFIERS:
                    data[i].setNextQualifiers(text+"" "");
                    break;
                case SCANNED_OBJECT:
                    data[i].setScannedObject(text+"" "");
                    break;
                case SCAN_TYPE:
                    data[i].setScanType(text+"" "");
                    break;
                case SORT_TYPE:
                    data[i].setSortType(text+"" "");
                    break;
                case NO_OF_OUTPUT_ROWS_BY_SORTER:
                    data[i].setSorterOutput(text+"" "");
                    break;
                }
            }
            else{
                /*Other attributes are omitted from the xml document
                 * if they're null.
                 * P_ID can be null at the root.
                 * */
                switch(x){
                case P_ID:
                    data[i].setParent(text+"""");
                    break;
                }
            }
            i++;
        }
        results.close();
        ps.close();
    }"
https://github.com/apache/derby/tree/eea0d50c8d732cad9ba563ddfa786b7028eb092f//java/engine/org/apache/derby/vti/StringColumnVTI.java,getBytes,open,"public byte[] getBytes(int columnIndex) throws SQLException
    {
        String  columnValue = getString( columnIndex );

        if ( columnValue == null ) { return null; }
        else
        {
            try {
                return columnValue.getBytes( ""UTF-8"" );
            } catch (Throwable t) { throw new SQLException( t.getMessage() ); }
        }
    }"
https://github.com/apache/derby/tree/eea0d50c8d732cad9ba563ddfa786b7028eb092f//java/build/org/apache/derbyBuild/ClassSizeCrawler.java,main,open,"public static void main( String[] arg)
    {
        String[] classAndInterfaceList = {""org.apache.derby.iapi.types.DataValueDescriptor""};
        if(arg.length > 0)
            classAndInterfaceList = arg;
        Class[] interfaceList = new Class[classAndInterfaceList.length];
        int interfaceCount = 0;
        Class[] classList = new Class[classAndInterfaceList.length];
        int classCount = 0;

        Class classSizeClass = ClassSize.class; // Make sure that the garbage collector does not unload it
        ClassSize.setDummyCatalog();
        /* Most of the classes we will catalog invoke ClassSize.estimateBaseFromCatalog in
         * their static initializer. This dummy the catalog out so that this will not generate
         * errors. We will not actually use the classes, just examine their fields.
         */

        for( int i = 0; i < classAndInterfaceList.length; i++)
        {
            Class cls = null;
            try
            {
                cls = Class.forName( classAndInterfaceList[i]);
            }
            catch( ClassNotFoundException cnfe)
            {
                System.err.println( ""*** Could not find class "" + classAndInterfaceList[i]);
                System.exit(1);
            }
            if( cls.isInterface())
                interfaceList[ interfaceCount++] = cls;
            else
                classList[ classCount++] = cls;
        }

        String WS = System.getProperty( ""WS"");
        if( WS == null)
        {
            System.err.println( ""*** WS is not set."");
            System.exit(1);
        }

        StringBuffer baseDir = new StringBuffer( System.getProperty( ""classDir"", """"));
        if( baseDir.length() == 0)
        {
            baseDir.append( WS);
            baseDir.append( '/');
            baseDir.append( ""classes"");
        }
        int baseDirLength = baseDir.length();

        StringBuffer packagePrefix = new StringBuffer( );

        Hashtable<String, int[]> classSizes = new Hashtable<String, int[]>();

        ClassSizeCrawler crawler = new ClassSizeCrawler(interfaceList, interfaceCount, classSizes);

        if( interfaceCount > 0)
        {
            boolean gotPrefix = false;
            // Crawl through the class hierarchies for classes implementing the interfaces
            for( Enumeration e = System.getProperties().propertyNames();
                 e.hasMoreElements();)
            {
                String propertyName = (String) e.nextElement();
                if( propertyName.equals( ""prefix"") || propertyName.startsWith( ""prefix.""))
                {
                    gotPrefix = true;
                    packagePrefix.setLength( 0);
                    packagePrefix.append( System.getProperty( propertyName));
                    baseDir.setLength( baseDirLength);
                    if( packagePrefix.length() > 0)
                    {
                        baseDir.append( '/');
                        for( int offset = 0; offset < packagePrefix.length(); offset++)
                        {
                            char c = packagePrefix.charAt( offset);
                            if( c == '.')
                                baseDir.append( '/');
                            else
                                baseDir.append( c);
                        }
                    }
                    crawler.crawl( new File( baseDir.toString()), packagePrefix);
                }
            }
            if( ! gotPrefix)
            {
                System.err.println( ""*** Could not search the class hierarchy because no starting"");
                System.err.println( ""    prefixes where specified."");
                System.exit(1);
            }
        }
        for( int i = 0; i < classCount; i++)
            crawler.addClass( classList[i]);

        baseDir.setLength( baseDirLength);
        String outputFileName =
          System.getProperty( ""out"", WS + ""/java/org.apache.derby.iapi.services.cache.ClassSizeCatalog.java"");
        try
        {
            PrintWriter out = new PrintWriter( new FileWriter( outputFileName));
            out.print( ""/*\n\n"" +

                       ""   Licensed to the Apache Software Foundation (ASF) under one or more\n"" +
                       ""   contributor license agreements.  See the NOTICE file distributed with\n"" +
                       ""   this work for additional information regarding copyright ownership.\n"" +
                       ""   The ASF licenses this file to You under the Apache License, Version 2.0\n"" +
                       ""   (the \""License\""); you may not use this file except in compliance with\n"" +
                       ""   the License.  You may obtain a copy of the License at\n"" +
                       ""\n"" +
                       ""      http://www.apache.org/licenses/LICENSE-2.0\n"" +
                       ""\n"" +
                       ""   Unless required by applicable law or agreed to in writing, software\n"" +
                       ""   distributed under the License is distributed on an \""AS IS\"" BASIS,\n"" +
                       ""   WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n"" +
                       ""   See the License for the specific language governing permissions and\n"" +
                       ""   limitations under the License.\n"" +
                       "" */\n"");
            out.print( ""package org.apache.derby.iapi.services.cache;\n"" +
                       ""import java.util.Hashtable;\n"" +
                       ""class ClassSizeCatalog extends java.util.Hashtable\n"" +
                       ""{\n"" +
                       ""    ClassSizeCatalog()\n"" +
                       ""    {\n"");
            for( Enumeration e = classSizes.keys();
                 e.hasMoreElements();)
            {
                String className = (String) e.nextElement();
                int[] coeff = (int[]) classSizes.get( className);
                out.print( ""        put( \"""" + className + ""\"", new int[]{"" + coeff[0] + "","" + coeff[1] + ""});\n"");
            }
            out.print(""    }\n"" +
                      ""}\n"");
            out.flush();
            out.close();
        }
        catch( IOException ioe)
        {
            System.err.println( ""*** Cannot write to "" + outputFileName);
            System.err.println( ""   "" + ioe.getMessage());
            System.exit(1);
        }
    }"
https://github.com/apache/jmeter/tree/adca9fe1d982342e0cec8d1e410dabd0967bb852//src/components/org/apache/jmeter/assertions/XMLAssertion.java,getResult,close,"@Override
    public AssertionResult getResult(SampleResult response) {
        // no error as default
        AssertionResult result = new AssertionResult(getName());
        byte[] responseData = response.getResponseData();
        if (responseData.length == 0) {
            return result.setResultForNull();
        }
        result.setFailure(false);

        // the result data
        String resultData = new String(getResultBody(responseData)); // TODO - charset?

        SAXBuilder builder = myBuilder.get();

        try {
            builder.build(new StringReader(resultData));
        } catch (JDOMException e) {
            log.debug(""Cannot parse result content"", e); // may well happen
            result.setFailure(true);
            result.setFailureMessage(e.getMessage());
        } catch (IOException e) {
            log.error(""Cannot read result content"", e); // should never happen
            result.setError(true);
            result.setFailureMessage(e.getMessage());
        }

        return result;
    }"
https://github.com/apache/jmeter/tree/adca9fe1d982342e0cec8d1e410dabd0967bb852//src/protocol/http/org/apache/jmeter/protocol/http/sampler/HTTPSampleResult.java,getDataEncodingWithDefault,close,"@Override
    public String getDataEncodingWithDefault() {
        if (getDataEncodingNoDefault() == null && getContentType().startsWith(""text/html"")){ // $NON-NLS-1$
            byte[] bytes=getResponseData();
            // get the start of the file
            // TODO - charset?
            String prefix = new String(bytes,0,Math.min(bytes.length, 2000)).toLowerCase(java.util.Locale.ENGLISH);
            // Extract the content-type if present
            final String METATAG = ""<meta http-equiv=\""content-type\"" content=\""""; // $NON-NLS-1$
            int tagstart=prefix.indexOf(METATAG);
            if (tagstart!=-1){
                tagstart += METATAG.length();
                int tagend = prefix.indexOf('\""', tagstart); // $NON-NLS-1$
                if (tagend!=-1){
                    // TODO use fixed charset:
                    final String ct = new String(bytes,tagstart,tagend-tagstart); // TODO - charset?
                    setEncodingAndType(ct);// Update the dataEncoding
                }
            }
        }
        return super.getDataEncodingWithDefault(DEFAULT_HTTP_ENCODING);
    }"
https://github.com/apache/jmeter/tree/adca9fe1d982342e0cec8d1e410dabd0967bb852//src/protocol/http/org/apache/jmeter/protocol/http/sampler/HTTPSamplerBase.java,resultProcessing,open,"protected HTTPSampleResult resultProcessing(boolean areFollowingRedirect, int frameDepth, HTTPSampleResult res) {
        boolean wasRedirected = false;
        if (!areFollowingRedirect) {
            if (res.isRedirect()) {
                log.debug(""Location set to - "" + res.getRedirectLocation());

                if (getFollowRedirects()) {
                    res = followRedirects(res, frameDepth);
                    areFollowingRedirect = true;
                    wasRedirected = true;
                }
            }
        }
        if (isImageParser() && (SampleResult.TEXT).equals(res.getDataType()) && res.isSuccessful()) {
            if (frameDepth > MAX_FRAME_DEPTH) {
                res.addSubResult(errorResult(new Exception(""Maximum frame/iframe nesting depth exceeded.""), new HTTPSampleResult(res)));
            } else {
                // Only download page resources if we were not redirected.
                // If we were redirected, the page resources have already been
                // downloaded for the sample made for the redirected url
                // otherwise, use null so the container is created if necessary unless
                // the flag is false, in which case revert to broken 2.1 behaviour 
                // Bug 51939 -  https://issues.apache.org/bugzilla/show_bug.cgi?id=51939
                if(!wasRedirected) {
                    HTTPSampleResult container = (HTTPSampleResult) (
                            areFollowingRedirect ? res.getParent() : SEPARATE_CONTAINER ? null : res);
                    res = downloadPageResources(res, container, frameDepth);
                }
            }
        }
        return res;
    }"
https://github.com/apache/jmeter/tree/adca9fe1d982342e0cec8d1e410dabd0967bb852//src/protocol/http/org/apache/jmeter/protocol/http/sampler/HTTPSamplerBase.java,errorResult,open,"protected HTTPSampleResult errorResult(Throwable e, HTTPSampleResult res) {
        res.setSampleLabel(""Error: "" + res.getSampleLabel());
        res.setDataType(SampleResult.TEXT);
        ByteArrayOutputStream text = new ByteArrayOutputStream(200);
        e.printStackTrace(new PrintStream(text));
        res.setResponseData(text.toByteArray());
        res.setResponseCode(NON_HTTP_RESPONSE_CODE+"": ""+e.getClass().getName());
        res.setResponseMessage(NON_HTTP_RESPONSE_MESSAGE+"": ""+e.getMessage());
        res.setSuccessful(false);
        res.setMonitor(this.isMonitor());
        return res;
    }"
https://github.com/apache/lucene-solr/tree/9e82c2409d62e7be04dc4fae7c45c3712be639a2//lucene/core/src/java/org/apache/lucene/index/LogMergePolicy.java,compareTo,close,"@Override
    public int compareTo(SegmentInfoAndLevel other) {
      if (level < other.level) {
        return 1;
      } else if (level > other.level) {
        return -1;
      } else {
        return 0;
      }
    }"
https://github.com/apache/lucene-solr/tree/9e82c2409d62e7be04dc4fae7c45c3712be639a2//lucene/core/src/java/org/apache/lucene/index/LogMergePolicy.java,compareTo,open,"@Override
    public int compareTo(SegmentInfoAndLevel other) {
      if (level < other.level) {
        return 1;
      } else if (level > other.level) {
        return -1;
      } else {
        return 0;
      }
    }"
https://github.com/apache/lucene-solr/tree/9e82c2409d62e7be04dc4fae7c45c3712be639a2//solr/core/src/java/org/apache/solr/core/SolrResourceLoader.java,findClass,open,"public <T> Class<? extends T> findClass(String cname, Class<T> expectedType, String... subpackages) {
    if (subpackages == null || subpackages.length == 0 || subpackages == packages) {
      subpackages = packages;
      String  c = classNameCache.get(cname);
      if(c != null) {
        try {
          return Class.forName(c, true, classLoader).asSubclass(expectedType);
        } catch (ClassNotFoundException e) {
          //this is unlikely
          log.error(""Unable to load cached class-name :  ""+ c +"" for shortname : ""+cname + e);
        }

      }
    }
    Class<? extends T> clazz = null;
    
    // first try legacy analysis patterns, now replaced by Lucene's Analysis package:
    final Matcher m = legacyAnalysisPattern.matcher(cname);
    if (m.matches()) {
      final String name = m.group(4);
      log.trace(""Trying to load class from analysis SPI using name='{}'"", name);
      try {
        if (CharFilterFactory.class.isAssignableFrom(expectedType)) {
          return clazz = CharFilterFactory.lookupClass(name).asSubclass(expectedType);
        } else if (TokenizerFactory.class.isAssignableFrom(expectedType)) {
          return clazz = TokenizerFactory.lookupClass(name).asSubclass(expectedType);
        } else if (TokenFilterFactory.class.isAssignableFrom(expectedType)) {
          return clazz = TokenFilterFactory.lookupClass(name).asSubclass(expectedType);
        } else {
          log.warn(""'{}' looks like an analysis factory, but caller requested different class type: {}"", cname, expectedType.getName());
        }
      } catch (IllegalArgumentException ex) { 
        // ok, we fall back to legacy loading
      }
    }
    
    // first try cname == full name
    try {
      return Class.forName(cname, true, classLoader).asSubclass(expectedType);
    } catch (ClassNotFoundException e) {
      String newName=cname;
      if (newName.startsWith(project)) {
        newName = cname.substring(project.length()+1);
      }
      for (String subpackage : subpackages) {
        try {
          String name = base + '.' + subpackage + newName;
          log.trace(""Trying class name "" + name);
          return clazz = Class.forName(name,true,classLoader).asSubclass(expectedType);
        } catch (ClassNotFoundException e1) {
          // ignore... assume first exception is best.
        }
      }
  
      throw new SolrException( SolrException.ErrorCode.SERVER_ERROR, ""Error loading class '"" + cname + ""'"", e);
    }finally{
      //cache the shortname vs FQN if it is loaded by the webapp classloader  and it is loaded
      // using a shortname
      if ( clazz != null &&
              clazz.getClassLoader() == SolrResourceLoader.class.getClassLoader() &&
              !cname.equals(clazz.getName()) &&
              (subpackages.length == 0 || subpackages == packages)) {
        //store in the cache
        classNameCache.put(cname, clazz.getName());
      }
    }
  }"
https://github.com/apache/lucene-solr/tree/9e82c2409d62e7be04dc4fae7c45c3712be639a2//solr/core/src/java/org/apache/solr/schema/CurrencyField.java,init,close,"@Override
  protected void init(IndexSchema schema, Map<String, String> args) {
    super.init(schema, args);
    if (this.isMultiValued()) { 
      throw new SolrException(SolrException.ErrorCode.SERVER_ERROR, 
                              ""CurrencyField types can not be multiValued: "" + 
                              this.typeName);
    }
    this.schema = schema;
    this.exchangeRateProviderClass = args.get(PARAM_RATE_PROVIDER_CLASS);
    this.defaultCurrency = args.get(PARAM_DEFAULT_CURRENCY);

    if (this.defaultCurrency == null) {
      this.defaultCurrency = DEFAULT_DEFAULT_CURRENCY;
    }
    
    if (this.exchangeRateProviderClass == null) {
      this.exchangeRateProviderClass = DEFAULT_RATE_PROVIDER_CLASS;
    }

    if (java.util.Currency.getInstance(this.defaultCurrency) == null) {
      throw new SolrException(SolrException.ErrorCode.BAD_REQUEST, ""Invalid currency code "" + this.defaultCurrency);
    }

    String precisionStepString = args.get(PARAM_PRECISION_STEP);
    if (precisionStepString == null) {
      precisionStepString = DEFAULT_PRECISION_STEP;
    }

    // Initialize field type for amount
    fieldTypeAmountRaw = new TrieLongField();
    fieldTypeAmountRaw.setTypeName(""amount_raw_type_tlong"");
    Map<String,String> map = new HashMap<String,String>(1);
    map.put(""precisionStep"", precisionStepString);
    fieldTypeAmountRaw.init(schema, map);
    
    // Initialize field type for currency string
    fieldTypeCurrency = new StrField();
    fieldTypeCurrency.setTypeName(""currency_type_string"");
    fieldTypeCurrency.init(schema, new HashMap<String,String>());
    
    args.remove(PARAM_RATE_PROVIDER_CLASS);
    args.remove(PARAM_DEFAULT_CURRENCY);
    args.remove(PARAM_PRECISION_STEP);

    try {
      Class<? extends ExchangeRateProvider> c = schema.getResourceLoader().findClass(exchangeRateProviderClass, ExchangeRateProvider.class);
      provider = c.newInstance();
      provider.init(args);
    } catch (Exception e) {
      throw new SolrException(ErrorCode.BAD_REQUEST, ""Error instansiating exhange rate provider ""+exchangeRateProviderClass+"". Please check your FieldType configuration"", e);
    }
  }"
https://github.com/apache/lucene-solr/tree/9e82c2409d62e7be04dc4fae7c45c3712be639a2//solr/core/src/java/org/apache/solr/schema/CurrencyField.java,init,open,"@Override
  protected void init(IndexSchema schema, Map<String, String> args) {
    super.init(schema, args);
    if (this.isMultiValued()) { 
      throw new SolrException(SolrException.ErrorCode.SERVER_ERROR, 
                              ""CurrencyField types can not be multiValued: "" + 
                              this.typeName);
    }
    this.schema = schema;
    this.exchangeRateProviderClass = args.get(PARAM_RATE_PROVIDER_CLASS);
    this.defaultCurrency = args.get(PARAM_DEFAULT_CURRENCY);

    if (this.defaultCurrency == null) {
      this.defaultCurrency = DEFAULT_DEFAULT_CURRENCY;
    }
    
    if (this.exchangeRateProviderClass == null) {
      this.exchangeRateProviderClass = DEFAULT_RATE_PROVIDER_CLASS;
    }

    if (java.util.Currency.getInstance(this.defaultCurrency) == null) {
      throw new SolrException(SolrException.ErrorCode.BAD_REQUEST, ""Invalid currency code "" + this.defaultCurrency);
    }

    String precisionStepString = args.get(PARAM_PRECISION_STEP);
    if (precisionStepString == null) {
      precisionStepString = DEFAULT_PRECISION_STEP;
    }

    // Initialize field type for amount
    fieldTypeAmountRaw = new TrieLongField();
    fieldTypeAmountRaw.setTypeName(""amount_raw_type_tlong"");
    Map<String,String> map = new HashMap<String,String>(1);
    map.put(""precisionStep"", precisionStepString);
    fieldTypeAmountRaw.init(schema, map);
    
    // Initialize field type for currency string
    fieldTypeCurrency = new StrField();
    fieldTypeCurrency.setTypeName(""currency_type_string"");
    fieldTypeCurrency.init(schema, new HashMap<String,String>());
    
    args.remove(PARAM_RATE_PROVIDER_CLASS);
    args.remove(PARAM_DEFAULT_CURRENCY);
    args.remove(PARAM_PRECISION_STEP);

    try {
      Class<? extends ExchangeRateProvider> c = schema.getResourceLoader().findClass(exchangeRateProviderClass, ExchangeRateProvider.class);
      provider = c.newInstance();
      provider.init(args);
    } catch (Exception e) {
      throw new SolrException(ErrorCode.BAD_REQUEST, ""Error instansiating exhange rate provider ""+exchangeRateProviderClass+"". Please check your FieldType configuration"", e);
    }
  }"
https://github.com/apache/lucene-solr/tree/9e82c2409d62e7be04dc4fae7c45c3712be639a2//solr/core/src/java/org/apache/solr/schema/OpenExchangeRatesOrgProvider.java,getExchangeRate,close,"@Override
  public double getExchangeRate(String sourceCurrencyCode, String targetCurrencyCode) {
    if (rates == null) {
      throw new SolrException(SolrException.ErrorCode.SERVICE_UNAVAILABLE, ""Rates not initialized."");
    }
      
    if (sourceCurrencyCode == null || targetCurrencyCode == null) {
      throw new SolrException(SolrException.ErrorCode.BAD_REQUEST, ""Cannot get exchange rate; currency was null."");
    }
    
    if (rates.getTimestamp() + refreshInterval*60*1000 > System.currentTimeMillis()) {
      log.debug(""Refresh interval has expired. Refreshing exchange rates."");
      reload();
    }
    
    Double source = (Double) rates.getRates().get(sourceCurrencyCode);
    Double target = (Double) rates.getRates().get(targetCurrencyCode);

    if (source == null || target == null) {
      throw new SolrException(SolrException.ErrorCode.BAD_REQUEST, 
          ""No available conversion rate from "" + sourceCurrencyCode + "" to "" + targetCurrencyCode + "". ""
          + ""Available rates are ""+listAvailableCurrencies());
    }
    
    return target / source;  
  }"
https://github.com/apache/lucene-solr/tree/9e82c2409d62e7be04dc4fae7c45c3712be639a2//solr/core/src/java/org/apache/solr/schema/OpenExchangeRatesOrgProvider.java,reload,open,"@Override
  public boolean reload() throws SolrException {
    InputStream ratesJsonStream = null;
    try {
      log.info(""Reloading exchange rates from ""+ratesFileLocation);
      try {
        ratesJsonStream = (new URL(ratesFileLocation)).openStream();
      } catch (Exception e) {
        ratesJsonStream = resourceLoader.openResource(ratesFileLocation);
      }
        
      rates = new OpenExchangeRates(ratesJsonStream);
      return true;
    } catch (Exception e) {
      throw new SolrException(ErrorCode.SERVER_ERROR, ""Error reloading exchange rates"", e);
    } finally {
      if (ratesJsonStream != null) try {
        ratesJsonStream.close();
      } catch (IOException e) {
        throw new SolrException(ErrorCode.SERVER_ERROR, ""Error closing stream"", e);
      }
    }
  }"
https://github.com/apache/lucene-solr/tree/9e82c2409d62e7be04dc4fae7c45c3712be639a2//solr/core/src/java/org/apache/solr/update/UpdateLog.java,getLogList,close,"public static String[] getLogList(File directory) {
    final String prefix = TLOG_NAME+'.';
    String[] names = directory.list(new FilenameFilter() {
      @Override
      public boolean accept(File dir, String name) {
        return name.startsWith(prefix);
      }
    });
    Arrays.sort(names);
    return names;
  }"
https://github.com/apache/lucene-solr/tree/9e82c2409d62e7be04dc4fae7c45c3712be639a2//solr/core/src/java/org/apache/solr/update/UpdateLog.java,init,open,"@Override
  public void init(PluginInfo info) {
    dataDir = (String)info.initArgs.get(""dir"");
    defaultSyncLevel = SyncLevel.getSyncLevel((String)info.initArgs.get(""syncLevel""));
  }"
https://github.com/apache/lucene-solr/tree/9e82c2409d62e7be04dc4fae7c45c3712be639a2//solr/core/src/java/org/apache/solr/update/processor/CloneFieldUpdateProcessorFactory.java,inform,close,"@Override
  public void inform(final SolrCore core) {
    
    final IndexSchema schema = core.getSchema();

    srcSelector = 
      FieldMutatingUpdateProcessor.createFieldNameSelector
      (core.getResourceLoader(),
       core.getSchema(),
       srcInclusions.fieldName,
       srcInclusions.typeName,
       srcInclusions.typeClass,
       srcInclusions.fieldRegex,
       FieldMutatingUpdateProcessor.SELECT_NO_FIELDS);

    for (SelectorParams exc : srcExclusions) {
      srcSelector = FieldMutatingUpdateProcessor.wrap
        (srcSelector,
         FieldMutatingUpdateProcessor.createFieldNameSelector
         (core.getResourceLoader(),
          core.getSchema(),
          exc.fieldName,
          exc.typeName,
          exc.typeClass,
          exc.fieldRegex,
          FieldMutatingUpdateProcessor.SELECT_NO_FIELDS));
    }
  }"
https://github.com/apache/tomcat/tree/ad9a49cb08bf004af97cad465bba45d21d112325//webapps/examples/WEB-INF/classes/compressionFilters/CompressionServletResponseWrapper.java,setCompressionMimeTypes,open,"public void setCompressionMimeTypes(String[] mimeTypes) {
        if (debug > 1) {
            System.out.println(""setCompressionMimeTypes to "" +
                    Arrays.toString(mimeTypes));
        }
        this.compressionMimeTypes = mimeTypes;
    }"
https://github.com/apache/tomcat/tree/ad9a49cb08bf004af97cad465bba45d21d112325//java/org/apache/jasper/JspC.java,initServletContext,open,"protected void initServletContext() {
        try {
            context =new JspCServletContext
                (new PrintWriter(System.out),
                 new URL(""file:"" + uriRoot.replace('\\','/') + '/'));
            tldLocationsCache = TldLocationsCache.getInstance(context);
        } catch (MalformedURLException me) {
            System.out.println(""**"" + me);
        }
        rctxt = new JspRuntimeContext(context, this);
        jspConfig = new JspConfig(context);
        tagPluginManager = new TagPluginManager(context);
    }"
https://github.com/apache/tomcat/tree/ad9a49cb08bf004af97cad465bba45d21d112325//java/org/apache/jasper/JspC.java,setValidateXml,close,"public void setValidateXml( boolean b ) {
        org.apache.jasper.xmlparser.ParserUtils.validating=b;
    }"
https://github.com/apache/tomcat/tree/ad9a49cb08bf004af97cad465bba45d21d112325//java/org/apache/jasper/JspCompilationContext.java,getJspLoader,open,"public ClassLoader getJspLoader() {
        if( jspLoader == null ) {
            jspLoader = new JasperLoader
            (new URL[] {baseUrl},
                    getClassLoader(),
                    rctxt.getPermissionCollection());
        }
        return jspLoader;
    }"
https://github.com/apache/tomcat/tree/ad9a49cb08bf004af97cad465bba45d21d112325//java/org/apache/tomcat/buildutil/Txt2Html.java,convert,close,"private void convert( File from, File to )
        throws IOException
    {
        // Open files:
        BufferedReader in = new BufferedReader( new FileReader( from ) );
        PrintWriter out = new PrintWriter( new FileWriter( to ) );

        // Output header:
        out.println( ""<html><body><pre>"" );

        // Convert, line-by-line:
        String line;
        while( (line = in.readLine()) != null ) {
            StringBuilder result = new StringBuilder();
            int len = line.length();
            for( int i = 0; i < len; i++ ) {
                char c = line.charAt( i );
                switch( c ) {
                    case '&':
                        result.append( ""&amp;"" );
                        break;
                    case '<':
                        result.append( ""&lt;"" );
                        break;
                    default:
                        result.append( c );
                }
            }
            out.println( result.toString() );
        }

        // Output footer:
        out.println( ""</pre></body></html>"" );

        // Close streams:
        out.close();
        in.close();
    }"
https://github.com/apache/tomcat/tree/ad9a49cb08bf004af97cad465bba45d21d112325//java/org/apache/tomcat/buildutil/Txt2Html.java,execute,open,"@Override
    public void execute()
        throws BuildException
    {
        int count = 0;

        // Step through each file and convert.
        Iterator<FileSet> iter = filesets.iterator();
        while( iter.hasNext() ) {
            FileSet fs = iter.next();
            DirectoryScanner ds = fs.getDirectoryScanner(getProject());
            File basedir = ds.getBasedir();
            String[] files = ds.getIncludedFiles();
            for( int i = 0; i < files.length; i++ ) {
                File from = new File( basedir, files[i] );
                File to = new File( todir, files[i] + "".html"" );
                if( !to.exists() ||
                    (from.lastModified() > to.lastModified()) )
                {
                    log( ""Converting file '"" + from.getAbsolutePath() +
                        ""' to '"" + to.getAbsolutePath(), Project.MSG_VERBOSE );
                    try {
                        convert( from, to );
                    }
                    catch( IOException e ) {
                        throw new BuildException( ""Could not convert '"" +
                            from.getAbsolutePath() + ""' to '"" +
                            to.getAbsolutePath() + ""'"", e );
                    }
                    count++;
                }
            }
            if( count > 0 ) {
                log( ""Converted "" + count + "" file"" + (count > 1 ? ""s"" : """") +
                    "" to "" + todir.getAbsolutePath() );
            }
        }
    }"
https://github.com/apache/tomcat/tree/ad9a49cb08bf004af97cad465bba45d21d112325//modules/jdbc-pool/src/main/java/org/apache/tomcat/jdbc/pool/interceptor/SlowQueryReportJmx.java,getCompositeType,close,"protected static CompositeType getCompositeType() {
        if (SLOW_QUERY_TYPE==null) {
            try {
                SLOW_QUERY_TYPE = new CompositeType(
                        SlowQueryReportJmx.class.getName(),
                        ""Composite data type for query statistics"",
                        QueryStats.getFieldNames(),
                        QueryStats.getFieldDescriptions(),
                        QueryStats.getFieldTypes());
            }catch (OpenDataException x) {
                log.warn(""Unable to initialize composite data type for JMX stats and notifications."",x);
            }
        }
        return SLOW_QUERY_TYPE;
    }"
https://github.com/apache/tomcat/tree/ad9a49cb08bf004af97cad465bba45d21d112325//java/org/apache/tomcat/util/http/fileupload/FileUploadBase.java,getParsedHeaders,close,"protected FileItemHeaders getParsedHeaders(String headerPart) {
        final int len = headerPart.length();
        FileItemHeadersImpl headers = newFileItemHeaders();
        int start = 0;
        for (;;) {
            int end = parseEndOfLine(headerPart, start);
            if (start == end) {
                break;
            }
            String header = headerPart.substring(start, end);
            start = end + 2;
            while (start < len) {
                int nonWs = start;
                while (nonWs < len) {
                    char c = headerPart.charAt(nonWs);
                    if (c != ' '  &&  c != '\t') {
                        break;
                    }
                    ++nonWs;
                }
                if (nonWs == start) {
                    break;
                }
                // Continuation line found
                end = parseEndOfLine(headerPart, nonWs);
                header += "" "" + headerPart.substring(nonWs, end);
                start = end + 2;
            }
            parseHeaderLine(headers, header);
        }
        return headers;
    }"
https://github.com/apache/tomcat/tree/ad9a49cb08bf004af97cad465bba45d21d112325//java/org/apache/tomcat/util/http/fileupload/MultipartStream.java,readHeaders,open,"public String readHeaders()
    throws MalformedStreamException {
        int i = 0;
        byte b;
        // to support multi-byte characters
        ByteArrayOutputStream baos = new ByteArrayOutputStream();
        int size = 0;
        while (i < HEADER_SEPARATOR.length) {
            try {
                b = readByte();
            } catch (IOException e) {
                throw new MalformedStreamException(""Stream ended unexpectedly"");
            }
            if (++size > HEADER_PART_SIZE_MAX) {
                throw new MalformedStreamException(
                        ""Header section has more than "" + HEADER_PART_SIZE_MAX
                        + "" bytes (maybe it is not properly terminated)"");
            }
            if (b == HEADER_SEPARATOR[i]) {
                i++;
            } else {
                i = 0;
            }
            baos.write(b);
        }

        String headers = null;
        if (headerEncoding != null) {
            try {
                headers = baos.toString(headerEncoding);
            } catch (UnsupportedEncodingException e) {
                // Fall back to platform default if specified encoding is not
                // supported.
                headers = baos.toString();
            }
        } else {
            headers = baos.toString();
        }

        return headers;
    }"
